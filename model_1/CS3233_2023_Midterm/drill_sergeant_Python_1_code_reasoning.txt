 We are given that n can be up to 10^9, but m and q are up to 100,000 and 300,000 respectively.
 However, note that the line can have at most q (300,000) insertions? Actually, we do at most 300,000 operations and each insertion adds one cat. But removals also occur, so the size of the line at any time is at most 300,000.

 Steps:
 1. We store the dislike pairs in a set of tuples (min, max) for quick lookups. Since m is 100,000, we can do this.

 2. We maintain the current set of cats in the line. Since we need to find neighbors, we use a sorted set (like a balanced BST). In Python, we can use `sorted list` with bisect for O(n) insertions? But we need to do 300,000 operations and each insertion in a sorted list is O(n) worst-case. Alternatively, we can use a balanced BST structure? In Python, we can use the `sorted list` from the `sortedcontainers` module, but we cannot use external modules.

 Instead, we can use the built-in `bisect` module to maintain a sorted list. However, insertion and deletion in a sorted list take O(n) per operation, leading to O(q * n) worst-case which is 300,000 * 300,000 = 90e9 operations, which is too slow.

 Alternatively, we can use a balanced BST structure that supports O(log n) for insertion and deletion. In Python, we can use `SortedList` from the `sortedcontainers` module, but the problem does not allow external modules.

 We can use the built-in `list` with `bisect` for insertion and deletion? But deletion from a list is O(n). We need a better data structure.

 Actually, we don't need to maintain the entire list for the purpose of getting the neighbors? We can use a balanced BST from the standard library? The `set` in Python does not maintain order. We can use a balanced BST via the `sorted list` from `bisect` but then we have O(n) per insertion. Alternatively, we can use a balanced BST from `blist`? Again, external.

 We need to avoid TLE. How about we use the `sorted list` from the `bisect` module and accept that insertion and deletion are O(n) per operation? Then worst-case total operations is O(q * (q)) = 300,000 * 300,000 = 90e9 which is too slow in Python.

 Alternatively, we can use a balanced BST implemented as a skip list or use a Fenwick tree? But we don't need the entire array, we just need to maintain a set of active cats and quickly find the predecessor and successor.

 We can use the `sorted set` from the `sortedcontainers` module? But the problem states we must use standard libraries.

 Another idea: use a balanced BST in Python? We can use the `bisect` module to insert and delete in a list, but that is O(n). Alternatively, we can use a balanced BST with the `avl` or `bintrees`? But again, external.

 We must stick to standard libraries.

 However, note that we are only inserting and deleting at most 300,000 elements. The total number of elements in the set is at most 300,000. We can use a balanced BST implemented by hand? That's too heavy.

 Actually, we can use a `set` for membership and then use a balanced BST for the keys? But Python standard library has `bisect` for sorted lists. The worst-case total operations would be 300,000 insertions and 300,000 deletions, and each insertion in a sorted list (using `bisect.insort`) is O(n). So the total time would be O(q^2) = (300,000)^2 = 90e9 operations which is too slow in Python.

 We need a data structure that supports O(log n) insertion and deletion and O(1) or O(log n) for getting neighbors. 

 We can use a balanced BST from the `sorted list` of the `sortedcollections`? Not standard.

 Alternatively, we can use a Fenwick tree? But we don't need range queries, we need to maintain a set and find the predecessor and successor.

 We can use a balanced BST via the `SortedList` from the module `sortedcontainers` but the problem says "standard libraries only".

 Another idea: use two dictionaries (or sets) and a linked list? We can maintain a doubly linked list for the cats that are in the line? But we need to insert in sorted order and then find the neighbors in O(1) time. However, to insert in sorted order we need to find the position, which in a linked list is O(n). 

 Alternatively, we can use a balanced BST from the standard library? Actually, we can use the `bisect` module to maintain a sorted list and then use that to get the neighbors by index. But insertion and deletion are O(n). 

 However, note that q is 300,000. The worst-case total operations for a sorted list is O(q^2) which is 90e9. That is too high in Python.

 We need an efficient structure. 

 There is a data structure called "OrderedSet" that supports O(log n) insertions and deletions? We can use the `rbtree`? Not in standard.

 We can use the `sorted list` from a third-party module? The problem says: use standard libraries.

 So we have to use the built-in `bisect` with a list? Then worst-case 300,000 * 300,000 = 90e9 operations? That is too slow.

 Alternatively, we can use a balanced BST by using a segment tree? Or we can use the `set` and then use `bisect` on a list that we maintain? But updating the list for each insertion is O(n).

 We must find a better way.

 Insight: The operations are only on one element at a time. We can use a balanced BST from the standard library? Actually, in C++ we used `std::set`. In Python, we can simulate the BST with a balanced tree? Not standard.

 Another idea: use a skip list? We can implement one? But 300,000 operations is acceptable for a skip list with O(log n) per operation? The constant factors might be high in Python.

 Alternatively, we can use a Fenwick tree to maintain the positions? But we don't need the entire array, we just need to know the predecessor and successor.

 How about we maintain a dictionary that maps a cat to its neighbors? Specifically, we maintain:
   - For each cat in the line, we store: (prev, next) in a doubly linked list manner.
   - We also maintain two dictionaries: 
        left_neighbor = {}   # for a cat, the cat to the left (previous)
        right_neighbor = {}  # for a cat, the cat to the right (next)
   - Additionally, we maintain the head and tail of the linked list? But how do we insert a new cat in sorted order? We need to find the position.

 How to find the position? We can use a balanced BST to find the predecessor and successor? But we are building the linked list. Actually, we can use the sorted linked list and we know the keys (the cat ids). We can do:

   We maintain a sorted linked list. We also maintain a separate sorted list for the keys? But then we are back to the same problem.

 Alternatively, we can use a balanced BST implemented by hand? That's too heavy.

 Actually, we can use the `bisect` module on a sorted list to find the predecessor and successor in O(log n). Then we update the linked list in O(1). But then we also update the sorted list? Then the sorted list update is O(n). So we don't avoid the O(n) for the sorted list.

 But note: we only need the neighbors for the inserted element and the adjacent ones. We don't need the entire sorted list for anything else? Actually, we do: when we insert a cat, we need to know its immediate neighbors to update the linked list. We can use the linked list to store the entire chain? But to insert, we must know the neighbors by value? How do we find the neighbors without a sorted list?

 We can use a balanced BST? We are stuck.

 How about we use the `sorted list` for the entire set of cats in the line, but we do not update it by shifting all elements? Instead, we use the `bisect` module to get the index of the insertion point, then we update the linked list. The linked list update is O(1). Then we do:

   sorted_list = []   # we maintain this for the purpose of finding the insertion point? Actually, we can avoid storing the entire list? 

 But we need the entire sorted list for the `bisect` to work. However, we are going to do 300,000 operations, and each insertion in the sorted list (using `bisect.insort`) is O(n). Then total O(q^2) = 300,000^2 = 90e9 operations, which is too slow in Python.

 We need a data structure that supports O(log n) insertion and deletion and also allows us to get the predecessor and successor. 

 In Python, we can use a balanced BST via the `sorted list` from the `sortedcontainers` module, but we cannot use external modules.

 Alternative: we can use a balanced BST from the `bintrees`? Not standard.

 Another idea: we can use a Fenwick tree or segment tree to mark the present cats? Then we can do binary search on the Fenwick tree to find the predecessor and successor? But the Fenwick tree is over n=10^9? We cannot build an array of size 10^9.

 We can use a dynamic structure? We are only inserting and deleting at most 300,000 distinct cats. So we can use coordinate compression? But the cats are from 1 to 10^9, but we are only going to have at most 300,000 active.

 We can use a balanced BST that we build ourselves? We can use the `avl` tree? But we have to code it.

 However, the problem constraints (q up to 300,000) and the fact that we are in Python might require an efficient logarithmic structure. We can use a balanced BST implemented as a `treap` or `splay tree`? But coding a balanced BST in Python for 300,000 operations is acceptable? The constant factors might be high.

 Given the time, and that we must output Python code, and that we are allowed to use standard libraries only, we have to reconsider.

 Actually, the problem time limit is 3 seconds and we are in Python. The worst-case O(q^2) for sorted list with bisect might be 90e9 operations which is too slow.

 Therefore, we need a balanced BST. There is no standard one? Actually, Python does not have a built-in balanced BST for integers that supports predecessor and successor queries.

 But we can use the `sorted list` from the `bisect` module and accept O(n) per insertion? Then worst-case total operations is about O(q^2) which is 90e9. That is too slow.

 We need a better solution.

 Another idea: use a segment tree over the active cats? But we don't know the active cats in advance.

 How about we store the current set of cats in a balanced BST using the `sorted list` but update only the necessary parts? Actually, the `bisect` module only gives us the index, but insertion and deletion are O(n). 

 However, 300,000 operations: the worst-case total time is about the sum of the sizes of the list at the time of each insertion. For the i-th insertion, the size is i, so the total cost is O(q^2) = (300,000 * 300,000) / 2? That is about 45e9 operations, which in C++ might be borderline in 3 seconds? But in Python, it is too slow.

 Therefore, we need a faster data structure.

 We can use a balanced BST implemented with a `dict` and a tree structure? We can store for each node the left and right child? Then we can do:

   class Node:
        __slots__ = ('key', 'left', 'right', 'parent')

   Then we implement insert, delete, and then predecessor and successor.

 But we have to code the BST and then self-balance? AVL or Red-Black? That's a lot of code and error-prone.

 Alternatively, we can use a skip list? Skip lists are easier to implement. 

 How about we use a Fenwick tree to maintain the active indices? We can use coordinate compression for the active cats. Then we can use a Fenwick tree to mark the present cats. Then to find the predecessor of x: we can do a query for the last active cat <= x? This can be done with a Fenwick tree and binary search? That would be O(log n) per query. And insertion and deletion in Fenwick tree are O(log n). But n here is the number of active cats? Actually, we can compress the coordinates of the active cats. Since we have at most 300,000 active cats, we can compress the coordinates to 1..300000. However, the cats are identified by their height (which can be up to 10^9). But we only need to store the active ones.

 Steps for Fenwick tree approach:
   - We maintain a Fenwick tree (Binary Indexed Tree) that supports:
        point update: add or remove a marker at a position (we only store 0/1)
        query: prefix sums to find the k-th element? Actually, we need to find the predecessor and successor of a given value.

   But note: the cats are inserted by their value (height). We want to find the largest cat <= x (predecessor) and the smallest cat >= x (successor). We can use the Fenwick tree for the entire range [1, 10^9] but we cannot build an array of size 10^9.

   Instead, we can use a Fenwick tree over the active cats? But the active cats are not known in advance. We can use offline queries to compress the coordinates? The coordinates are the cat ids that ever appear in the operations? Actually, we know all the cats that will be inserted: they are the z_i in the operations. But note: removals remove cats that were inserted earlier, and we might reinsert? The problem says: for insertion, the cat is guaranteed not to be in the line, and for removal, the cat is guaranteed to be in the line. So each cat is inserted at most once and removed at most once. Therefore, the active cats are exactly the ones that are inserted and not yet removed.

   We can precollect all the cat ids that appear in the q operations? Then we have at most 300,000 distinct cats. Then we can compress these ids to 1..300000. But note: the cats have heights (which are their ids) and we also have dislike pairs that involve cats that might not be in the operations? But the dislike pairs are fixed and given at the beginning. However, the dislike pairs might involve cats that are never inserted. But that's okay because we only care about dislike pairs between two cats that are both in the line? Actually, the discontentment of a cat only depends on its adjacent cats in the line. And when we check for dislike, we only check pairs that are in the set of active cats? But the dislike set is fixed and we have stored it in a set of tuples (min, max) for the entire n.

   However, the Fenwick tree for the active cats: we need to map the cat id to an index in the compressed array. But the problem: the cats in the dislike pairs might be any from 1 to n, but the active cats are only the ones that have been inserted and not removed. We don't need to store the entire universe, only the active set. But the predecessor and successor are defined by the natural order of the cat ids (which are numbers). 

   How to find the predecessor of a cat x in the active set? We can maintain a balanced BST that we build ourselves? Actually, we can use the Fenwick tree for the active set, but we need to store the cat ids (the original values) and then do binary search on the Fenwick tree? 

   Alternatively, we can use a balanced BST implemented with a `sorted list` but updated by inserting and deleting in a balanced way? 

   Actually, there is a simpler solution: use a balanced BST from the `sorted list` but with the "SortedList" from a third-party module? The problem says "standard libraries".

 Given the constraints and the fact that we are in Python, we have two options:

   Option 1: Implement a balanced BST (like AVL or Treap) in Python. This is feasible for 300,000 operations.

   Option 2: Use the `bisect` module and a sorted list and hope that the test cases are not worst-case? But worst-case is O(q^2) which is 90e9.

   Option 3: Use a Fenwick tree with coordinate compression for the active cats? But the predecessor and successor queries would be O(log n) per query? Actually, with the Fenwick tree we can do:

        We maintain an array `active` for the compressed coordinates? But the order of the cats is by their natural number. We can maintain a sorted list of the active cats? Then we are back to the same: we need to update the sorted list which is O(n) per insertion.

 How about we use a balanced BST using the `sorted list` from a different perspective: we don't store the entire list in a flat list, but we use a balanced BST from a library? There is no standard.

 After careful thought, we decide to implement a simple balanced BST: a Treap. Why Treap? It is relatively easy to implement and has O(log n) expected time per operation.

 Steps for Treap:

   We will implement a Treap that supports:
        insert(key)
        delete(key)
        predecessor(key)
        successor(key)

   We also need to maintain the tree for the active cats.

   However, note that we do not need to traverse the entire tree. We only need to update the total discontentment by knowing the neighbors when inserting or deleting.

   But the problem: the insertion and removal operations change the line, and then we need to recalc the discontentment for the inserted cat and its new neighbors (which are the predecessor and successor) and also the old neighbors of the predecessor and successor (which become adjacent to the new cat) are no longer adjacent to each other.

   We can use the Treap to get the predecessor and successor of a cat in O(log n).

   Then our plan:

        Maintain a Treap (or any BST) that stores the keys (cat ids) of the cats currently in the line.

        Also maintain the total discontentment.

        We have a fixed set of dislike pairs stored in a set.

        For each operation:

            Insertion of cat z:
                If the line is empty, then insert z, and its discontentment is 3.
                Else:
                    Find the predecessor p = the largest cat < z in the line.
                    Find the successor s = the smallest cat > z in the line.

                    If p exists: then currently, p and s are adjacent? But when we insert z, then the adjacency p-s is broken, and we have p-z and z-s.

                    Steps:
                        1. Remove the discontentment of p and s (if they exist) from the total.
                        2. Insert z.
                        3. Recalculate the discontentment of p, z, and s (if they exist) and add them.

                    Also, note: if p and s were adjacent before, then after insertion they are not adjacent anymore? So we break the link between p and s? And we add links between p and z, and z and s.

            Removal of cat z:
                Find the predecessor p and successor s of z.
                Remove the discontentment of p, z, and s (if they exist).
                Remove z.
                Now p and s become adjacent? So recalc the discontentment of p and s and add them.

        How to recalc the discontentment for a cat? We need its current neighbors. How do we get the neighbors? We can store in the BST the ability to get the predecessor and successor of any node. But we already have the predecessor and successor for z at the time of insertion/removal. However, when we recalc the discontentment for p and s, we must get their neighbors (which might have changed). But note:

          For a cat x, its neighbors are:
              prev: the predecessor of x in the entire set? But we have the Treap so we can get the predecessor and successor of x in the entire set? However, we are storing the entire set. So we can do:

                prev = predecessor(x)   # but note: if x is the first element, no predecessor.
                next = successor(x)

          But we must be cautious: during insertion, we just inserted z and then we need to recalc p: the predecessor of p might still be the same as before? Actually, the only changes are the insertion of z which breaks the link between p and s. So the predecessor of p is unchanged, and the successor of p becomes z (if p is the predecessor of z). Similarly, the successor of s is unchanged, and the predecessor of s becomes z.

          Therefore, for p: 
               - its next neighbor changes from s to z.
          For s:
               - its prev neighbor changes from p to z.

          So we can recalc p and s using the new set.

        However, note: the discontentment of a cat depends only on its immediate neighbors. So we can recalc by:

            For a cat x, we get its current neighbors (using the Treap) and then compute the discontentment value.

        But we must do this for p, z, and s.

        Steps for insertion:

            p = predecessor(z)
            s = successor(z)

            // Remove the contributions of p and s (if they exist) because their neighbors are about to change.
            total -= get_dc(p)   // if p exists
            total -= get_dc(s)   // if s exists

            Insert z.

            // Now, the neighbors for p and s have changed: p now has a new next neighbor (z) and s now has a new prev neighbor (z). Also, z has neighbors p and s.

            // Recalculate p, z, and s.
            total += get_dc(p)   // if p exists
            total += get_dc(z)
            total += get_dc(s)   // if s exists

        Similarly for removal:

            p = predecessor(z)
            s = successor(z)

            total -= get_dc(p)   // if p exists
            total -= get_dc(z)
            total -= get_dc(s)   // if s exists

            Remove z.

            // Now p and s become adjacent? So their neighbors change: p's next becomes s, and s's prev becomes p.
            total += get_dc(p)   // if p exists
            total += get_dc(s)   // if s exists

        The function get_dc(x) does:
            p_prev = predecessor(x)   # the cat immediately to the left in the line (if exists)
            p_next = successor(x)     # the cat immediately to the right in the line (if exists)

            Then check the dislike pairs.

        But note: when we get the predecessor of x, we get the immediate one in the entire set? Yes, because we are storing the entire set.

        However, the Treap we implement should support:

            insert(key)
            delete(key)
            predecessor(key): returns the largest key < key, or None if not exists.
            successor(key): returns the smallest key > key, or None if not exists.

        And we must be able to call these functions for any key in the set.

        But note: when we call get_dc(x), we are calling predecessor(x) and successor(x) for a node that is in the set? Actually, we are calling for x which is in the set? Then the predecessor of x is the one immediately to the left, which we can get by the Treap.

        However, if x is the smallest, then predecessor(x) returns None? Similarly for the largest.

        The complexity: each get_dc(x) does two queries (predecessor and successor) which are O(log n) per query. So O(log n) per get_dc. Then per operation we do up to 5 get_dc calls? (In insertion: we remove p and s, then add p, z, s -> 2 removals and 3 additions, but actually we recalc each one once). Actually, we do:

            Before insertion: 
                get_dc(p) and get_dc(s) -> 2 calls
            After insertion:
                get_dc(p), get_dc(z), get_dc(s) -> 3 calls

            Total: 5 calls per insertion.

            Removal: 
                get_dc(p), get_dc(z), get_dc(s) -> 3 calls
            After removal:
                get_dc(p), get_dc(s) -> 2 calls
            Total: 5 calls per removal.

        And each call is O(log n). Then total operations: 5 * q * O(log q) = 5 * 300,000 * log2(300,000) ≈ 5 * 300,000 * 19 = 28.5e6, which is acceptable in Python.

        Also, the Treap operations (insert, delete, pred, succ) are O(log n) per call. We do:

            Insertion: 
                pred(z) and succ(z) -> 2 calls
                insert(z) -> 1 call
                then in get_dc: for p, z, s: each requires a pred and succ? Actually, in get_dc for a node x, we do:

                    p_prev = predecessor(x)   # in the entire set? But we have the Treap. We can implement a function that for a given key (which is in the set) returns its predecessor and successor? Actually, the predecessor and successor we need are the immediate neighbors in the set? But note: the Treap's predecessor function for a key that is in the set: 
                         If we call our own predecessor function on the key, it returns the next smallest element that is in the set? But that is the immediate left neighbor.

            However, our Treap's predecessor function for a key that is in the set: 
                The predecessor of x is the largest element in the set that is less than x.

            Similarly for successor.

            How to implement predecessor for a key that is in the set? 
                We can do: 
                    node = find(x)
                    then the predecessor is the maximum in the left subtree? But no, it could be from an ancestor.

            Actually, we can implement a general function that finds the predecessor of a key (whether the key is in the set or not) and then for a key that is in the set, the predecessor is the previous node in sorted order? That is what we want.

            But note: our Treap should support predecessor and successor for any key (whether present or not). Actually, we don't need to support for any key: for get_dc, we only call on keys that are in the set? Actually, no: when we call get_dc for a cat x that is in the set, we want the immediate neighbors. So we can use:

                left = the largest element less than x -> predecessor(x) in the set.
                right = the smallest element greater than x -> successor(x) in the set.

            We can implement these by:

                predecessor(key): returns the largest key in the set that is < key.
                successor(key): returns the smallest key in the set that is > key.

            But note: we can also store parent pointers and then do in-order traversal? 

            Alternatively, we can do:

                To find the predecessor of a key that is in the set: 
                    We can start from the root and traverse? 

            Actually, we can implement the Treap without parent pointers. There is a standard method to find the predecessor for a given key (whether the key is in the set or not) in O(log n). Similarly for successor.

        Therefore, we will implement a Treap that supports:
            insert(key)
            delete(key)
            predecessor(key)   // for any key, returns the largest key in the set < key, or None if not exists.
            successor(key)     // for any key, returns the smallest key in the set > key, or None if not exists.

        We do not need to store any value other than the key.

        Implementation of Treap:

            Each node: (key, priority, left, right)

            Operations:
                split(t, key) -> (left_tree, right_tree): left_tree has keys <= key, right_tree has keys > key.
                merge(left_tree, right_tree) -> t

            To insert(key, priority):
                (left, right) = split(t, key-1)   // we want to put key in the right place? Actually, we split at key: but we want to avoid duplicates? The problem: each cat is inserted once. So we can assume no duplicates.

                Then we create a new node for key.
                Then t = merge( merge(left, new_node), right )

            But wait, we split at key-1? Then left has keys <= key-1, and right has keys >= key. Then we want to insert the new node as a single node in the middle? Actually, we can split at key-1, then merge the left with the new node, then merge with right.

            However, we must avoid duplicates. We can check if the key is already in the set? But the problem guarantees for insertion: the cat is not in the line.

            Similarly, for deletion: 
                We can split the tree at key-1 to get left and a tree (temp) that has keys>=key.
                Then split temp at key to get (mid, right), where mid should have only the node with key (if it exists). Then we merge left and right.

            But we don't store duplicates.

            Predecessor(key): 
                We can split the tree at key-1: 
                    (left, right) = split(t, key-1)
                Then the predecessor is the maximum key in left. Then we merge the tree back? But we don't want to split the entire tree for a query? We can do without splitting by a recursive function.

            Alternatively, we can traverse the tree:

                function predecessor(root, key):
                    if root is None: return None
                    if root.key >= key:
                        return predecessor(root.left, key)
                    else:
                        res = predecessor(root.right, key)
                        if res is None:
                            return root.key
                        else:
                            return res

            But we are not storing parent pointers. We can do iterative:

                def predecessor(key):
                    node = root
                    candidate = None
                    while node:
                        if node.key < key:
                            candidate = node.key
                            node = node.right
                        else:
                            node = node.left
                    return candidate

            Similarly for successor:

                def successor(key):
                    node = root
                    candidate = None
                    while node:
                        if node.key > key:
                            candidate = node.key
                            node = node.left
                        else:
                            node = node.right
                    return candidate

            This is O(h) which is O(log n) on average.

        However, we are storing a Treap, which is a BST by key and heap by priority. But the above iterative method works for any BST.

        Therefore, we can implement the BST operations (insert, delete) using Treap, and then for predecessor and successor we use the iterative method.

        But note: the iterative method does not use the heap property. It just uses the BST property. And our Treap maintains the BST property.

        Steps:

            We will implement the Treap with:

                class Node:
                    __slots__ = ('key', 'priority', 'left', 'right')
                    def __init__(self, key):
                        import random
                        self.key = key
                        self.priority = random.random()
                        self.left = None
                        self.right = None

            Then we implement:

                split(node, key): 
                    if node is None: return (None, None)
                    if key < node.key:
                        l, r = split(node.left, key)
                        node.left = r
                        return (l, node)
                    else:
                        l, r = split(node.right, key)
                        node.right = l
                        return (node, r)

                But careful: we want to split by key: left tree: keys <= key, right tree: keys > key? 
                    Actually, we can do:

                    if node.key <= key:
                        l, r = split(node.right, key)
                        node.right = l
                        return (node, r)
                    else:
                        l, r = split(node.left, key)
                        node.left = r
                        return (l, node)

                But the standard split for Treap: we are splitting the tree by a pivot key: left_tree: keys <= pivot, right_tree: keys > pivot.

            Then:

                merge(left, right):
                    if left is None: return right
                    if right is None: return left
                    if left.priority > right.priority:
                        left.right = merge(left.right, right)
                        return left
                    else:
                        right.left = merge(left, right.left)
                        return right

            Insert(key):
                We split the tree at key-1? Actually, we want to insert the key. We can split at key: then we get left (keys<=key) and right (keys>key). Then we create a node for key, then merge left with the new node, then merge the result with right.

                But note: we are inserting a new key that is not present. So:

                    left, right = split(root, key)   # we want to split so that left contains keys <= key, but then we are inserting a duplicate? We want to split so that left has keys <= key, but then we can split at key-1 to get left (keys<=key-1) and right (keys>=key). Then we can merge left with the new node, then merge with right.

                Actually, we can split at key-1:

                    left, temp = split(root, key-1)
                    then merge( merge(left, new_node), temp )

                But we don't have a split that uses a pivot value? Our split uses a pivot key. How do we split at key-1? We can do:

                    left, temp = split(root, key-1)   # then left: keys<=key-1, temp: keys>=key

                Then we create a new node for key, then root = merge( merge(left, new_node), temp )

            Delete(key):
                We split at key-1: left, temp = split(root, key-1)
                Then we split temp at key: mid, right = split(temp, key)   # now mid should contain keys in [key, key] (if present) and right: keys>key.
                Then we merge left and right.

            But note: we want to remove the node with key exactly equal to key.

            However, we don't need to actually remove the node? We can do:

                left, temp = split(root, key)
                then left1, mid = split(left, key-1)   # left1: keys<=key-1, mid: keys in [key, key] (if any) -> but we want to remove one occurrence.

                Actually, we can do:

                    left, right = split(root, key)
                    left_left, left_mid = split(left, key-1)   # then left_mid has keys>=key? Actually, we want to remove the node with key.

                Alternatively, we can do:

                    left, right = split(root, key-1)   # left: keys<=key-1, right: keys>=key
                    then mid, right = split(right, key)   # mid: keys in [key, key] (because the next split at key: then the left part of that split is keys<=key, which is exactly the node with key? and then the rest) -> but we want to remove the node with key.

                Then we merge left and right.

            Actually, we can do:

                left, right = split(root, key)   # left: keys<=key, right: keys>key.
                then left1, to_remove = split(left, key-1)   # left1: keys<=key-1, to_remove: keys in [key, key] (if any) -> but then we discard to_remove and merge left1 and right.

            But if there is a node with key, then to_remove is that node? And we merge left1 and right.

        However, the problem: we are storing distinct keys. So we can do:

            left, right = split(root, key-1)   # left: keys<=key-1, right: keys>=key
            mid, right = split(right, key)   # mid: keys in [key, key] (so only the node with key) and right: keys>key
            Then we ignore mid and merge left and right.

        But the split function we have splits by a pivot key: 
            split(node, pivot) returns (l, r) where l has keys <= pivot, r has keys > pivot.

        So:

            Step 1: split the tree at key-1: 
                left: keys <= key-1
                temp: keys > key-1 -> which is keys>=key

            Step 2: split temp at key: 
                mid: keys <= key -> which is the node with key (if present) and any other key that is <= key? But we have distinct keys and the next keys are >= key, so the only key in [key, key] is the node with key. Then the rest of temp is keys>key.

            Then we merge left and right (which is the second part of the second split).

        Therefore:

            def delete(key):
                global root
                left, temp = split(root, key-1)
                mid, right = split(temp, key)
                root = merge(left, right)

        But note: if the key is not present, then mid will be None? Then we still merge left and right? That is safe.

        However, the problem guarantees that for removal, the cat is currently in the line.

        Similarly for insertion: the cat is not currently in the line.

        We will implement:

            root = None   # the root of the Treap

            def insert(key):
                nonlocal root
                left, right = split(root, key-1)
                new_node = Node(key)
                mid = new_node
                root = merge(merge(left, mid), right)

            But wait, we split at key-1: then we get left (keys<=key-1) and right (keys>key-1). Then we create the new node. Then we merge left with the new node: we get a tree. Then we merge that tree with right.

            Alternatively, we can do:

                left, right = split(root, key-1)
                new_node = Node(key)
                root = merge(merge(left, new_node), right)

        This should work.

        But the merge function: we merge two trees. We must use the priority for merge.

        We have:

            merge(left, new_node) -> returns a tree that is left + new_node, and then merge that with right.

        However, the new_node has a random priority. This is a standard Treap insertion.

        Alternatively, we can use the recursive insertion? 

        We choose to implement the standard split and merge.

        Steps:

            We will implement:

                split(node, key): 
                    if node is None: return (None, None)
                    if node.key <= key:
                        l, r = split(node.right, key)
                        node.right = l
                        return (node, r)
                    else:
                        l, r = split(node.left, key)
                        node.left = r
                        return (l, node)

                But note: the above returns (tree with keys <= key, tree with keys > key). 

            Then:

                merge(left, right):
                    if left is None: return right
                    if right is None: return left
                    if left.priority > right.priority:
                        left.right = merge(left.right, right)
                        return left
                    else:
                        right.left = merge(left, right.left)
                        return right

        Then insert(key):

            left, right = split(root, key)   # but then we want to put the new node at the position? Actually, we want to split at key-1? 

            Let me think: we want to insert a key. The new key is not present. We want to split the tree into two parts: 
                part1: keys <= key-1
                part2: keys > key-1   (which is keys>=key)

            Then we create a new node for key. Then we merge part1 with the new node, then merge that with part2.

            So:

                left, right = split(root, key-1)
                new_node = Node(key)
                root = merge(merge(left, new_node), right)

        But what if we split at key? Then we get:
            left: keys <= key
            right: keys > key

            Then we can split left at key-1? to get the part that is <=key-1 and the part that is [key, key]? But we don't have the node with key.

            Alternatively, we can do:

                left, right = split(root, key)   # left: keys<=key, right: keys>key
                then we merge left with new_node, then merge with right? But then we have two trees: left and right, and we put the new_node in the middle? Actually, the new_node has key, which is <=key? So we can merge left and new_node: then we have a tree that has keys<=key. Then we merge that with right? But then the new_node is to the left of everything in right? That is correct.

            However, we can simply do:

                left, right = split(root, key)
                root = merge(merge(left, new_node), right)

            But what if there is a key equal to key? We are guaranteed distinct.

        Actually, both methods work. We'll do:

            left, right = split(root, key)   # we split by key: then left has keys<=key, but we are going to insert a key that is not present, so we can do:

            But note: our split condition: 
                if node.key <= key: then we go to the right subtree to split? 

            We can do:

                left, right = split(root, key)   # left: keys<=key, right: keys>key.
                Then we merge left with new_node: 
                    left_new = merge(left, new_node)   # but then we merge two trees: left (which has keys<=key) and new_node (which is key) -> then the entire left_new has keys<=key? Actually, we should merge the new_node as the last element in left? But the merge function is a standard merge that does not assume that the new_node is the largest? 

            Alternatively, we can do:

                left, right = split(root, key-1)
                then merge( merge(left, new_node), right)

            This is more straightforward.

        Therefore, we choose to split at key-1.

        Implementation of split for key-1: we pass the value key-1.

        But note: the keys are integers.

        Summary of the Treap operations:

            split(node, pivot): returns (l, r) where l: keys<=pivot, r: keys>pivot.

            merge(l, r): merges two trees.

            insert(key):
                l, r = split(root, key-1)
                new_node = Node(key)
                root = merge(merge(l, new_node), r)

            delete(key):
                l, r = split(root, key-1)
                m, r = split(r, key)   # now m: keys<=key (which is only the key we want to remove, because r had keys>key-1 and then we split r at key: so m: keys in (key-1, key] -> but since keys are integers, m: keys in [key, key] -> only the node with key) and then r: keys>key.
                # But note: the split at key-1: then we split r (which is keys>key-1) at key: then the left part of that split (m) is keys<=key? So it includes the key and any key between (key-1, key]? But we only have integers, so only key. Then we ignore m and set root = merge(l, r)

        But wait: the second split: we split r (which has keys>key-1) at key: 
            Then we get m: keys in the set that are in (key-1, key] -> which is keys<=key and >key-1 -> so only the key.
            Then r = the rest of r (keys>key).

        So then we merge l (which is keys<=key-1) and r (keys>key) -> that is the entire set without key.

        Then we do:

            root = merge(l, r)

        And we don't use m.

        But we should free m? We don't care because we are in Python.

        Then we implement:

            predecessor(key): 
                # returns the largest key in the set that is < key, or None if not exists.
                # We can do iterative:

                cur = root
                candidate = None
                while cur:
                    if cur.key < key:
                        candidate = cur.key
                        cur = cur.right
                    else:
                        cur = cur.left
                return candidate

            successor(key):
                cur = root
                candidate = None
                while cur:
                    if cur.key > key:
                        candidate = cur.key
                        cur = cur.left
                    else:
                        cur = cur.right
                return candidate

        However, note: the iterative method for predecessor and successor does not require the key to be in the set? It works for any key.

        But in our get_dc function, we call for a key that is in the set? Then we want the immediate neighbors. For a cat x that is in the set, we want:

            left neighbor = the largest key in the set that is < x. But note: it might not be the immediate left? Actually, the iterative method returns the immediate predecessor? 

            For example: set = {1, 5, 10}, then for x=5: 
                predecessor(5): 
                    cur=root (say 5): 
                        5<5? no, so go left -> to 1.
                    then at 1: 1<5 -> candidate=1, then go right? (if there is a right child? 1's right is 5? But 5 is not <5? So then we break? 

            Actually, the iterative method for the entire tree:

                We start at root=5: 
                    if 5<5? no -> then we go left to 1.
                at 1: 1<5 -> candidate=1, then we go right? but 1's right is None? so we break? and return 1.

            That is the immediate predecessor.

            Similarly, for the entire set: the iterative method returns the immediate predecessor in the set.

        Therefore, we are good.

        We must be cautious: the tree is a Treap, which is a BST by key.

        We'll code the Treap with split and merge, and then the iterative pred and succ.

        Steps for the whole solution:

            Pre-store the dislike pairs in a set of tuples (min, max).

            Initialize:
                total_discontent = 0
                root = None   # for the Treap

            We have a function get_dc(x): 
                p_prev = predecessor(x)   # in the entire set (if exists, else None)
                p_next = successor(x)     # in the entire set (if exists, else None)

                Then:
                    if p_prev is not None and p_next is not None:
                        d_prev = (min(x, p_prev), max(x, p_prev)) in dislikeSet
                        d_next = (min(x, p_next), max(x, p_next)) in dislikeSet
                        ... then return the value.

                    else if p_prev is not None:
                        d_prev = ... 
                        then return 323 if d_prev else 3

                    else if p_next is not None:
                        d_next = ...
                        then return 32 if d_next else 3

                    else:
                        return 3

            Then process each query:

                If insertion (d_i==1, z_i):

                    # Step 1: get the current neighbors of z (if they were in the set) -> but they are not in the set yet? 
                    # But we can get the predecessor and successor of z in the current set (without z) by the Treap.

                    p = predecessor(z_i)   # the largest key < z_i
                    s = successor(z_i)      # the smallest key > z_i

                    # But note: in the current set (without z_i), p and s are adjacent? Not necessarily, but if we insert z_i, then z_i will be between p and s? Only if there is no cat between p and s? Actually, in a sorted set, the predecessor and successor are the immediate neighbors? So if we insert z_i, then it breaks the adjacency between p and s (if both exist) and becomes adjacent to p and s.

                    # Therefore, we need to remove the contributions of p and s (if they exist) because their neighbors will change.

                    if p is not None:
                        total_discontent -= get_dc(p)
                    if s is not None:
                        total_discontent -= get_dc(s)

                    # Now insert z_i into the Treap.
                    insert(z_i)

                    # Now update: 
                    #   the new cat z_i will be adjacent to p and s.
                    #   and the neighbors of p and s have changed.

                    # Recalculate the discontentment of p, z_i, and s.

                    # But note: after insertion, the neighbors for p: 
                    #   its next neighbor becomes z_i (if p is the predecessor of z_i, then the next of p was s? but now it is z_i) -> so we must recalc p.
                    #   similarly, the previous neighbor of s becomes z_i.

                    # Also, the cat z_i has neighbors p and s.

                    # So:

                    dc_p = get_dc(p) if p is not None else 0
                    dc_z = get_dc(z_i)
                    dc_s = get_dc(s) if s is not None else 0

                    total_discontent += dc_p + dc_z + dc_s

                If removal (d_i==2, z_i):

                    # First, get the current neighbors of z_i: 
                    p = predecessor(z_i)   # the immediate left neighbor in the line (if exists)
                    s = successor(z_i)      # the immediate right neighbor (if exists)

                    # Then we remove the contributions of p, z_i, and s (because their neighbors will change after removal).

                    # But note: currently, the neighbors for p: 
                    #   p's next is z_i (and then s) -> after removal, p's next becomes s.
                    #   similarly, s's previous becomes p.

                    # So we remove:
                    if p is not None:
                        total_discontent -= get_dc(p)
                    total_discontent -= get_dc(z_i)
                    if s is not None:
                        total_discontent -= get_dc(s)

                    # Then we remove z_i from the Treap.
                    delete(z_i)

                    # Then we recalc p and s: because now they become adjacent.

                    if p is not None:
                        total_discontent += get_dc(p)
                    if s is not None:
                        total_discontent += get_dc(s)

            Then output the total_discontent.

        However, note: the function get_dc(x) uses the current Treap. So during insertion, after we insert z_i, then when we call get_dc(p), it will see the new neighbor (z_i) for p? Yes.

        Similarly, during removal, after we remove z_i, then get_dc(p) will not see z_i as a neighbor? It will see the next neighbor as s? If s exists.

        Therefore, we must be cautious: the order of updates to the Treap and the calls to get_dc.

        For insertion:
            We remove the contributions of p and s (without z_i in the set) -> that is correct: because we are about to change their neighbors by inserting z_i.
            Then we insert z_i.
            Then we recalc p, z_i, and s (with the new set) -> that is correct.

        For removal:
            We remove the contributions of p, z_i, and s (with z_i still in the set) -> that is correct: because we are about to remove z_i which changes the neighbors of p and s.
            Then we remove z_i.
            Then we recalc p and s (without z_i) -> that is correct.

        We must be cautious: the get_dc function for a cat that is not in the set? But we only call get_dc for p and s that are in the set? 

            For insertion: p and s are from the set (if they exist) and z_i is inserted and then we call get_dc for it.

            For removal: p and s are from the set (if they exist) and z_i is still in the set when we call get_dc for it (before removal).

        Therefore, we must design the Treap so that the predecessor and successor functions work only for keys that are in the set? Actually, no: the predecessor and successor functions work for any key. And the get_dc function for a cat x that is in the set: we call predecessor(x) and successor(x) which return the immediate neighbors in the current set.

        This should be correct.

        But note: the get_dc function for a cat that is not in the set? We don't call it. 

        For insertion: 
            Before insertion, we call get_dc(p) and get_dc(s) when z_i is not inserted? That is the state without z_i: so the neighbors of p and s are as they were (without z_i). But we want the state before the insertion? That is correct.

        However, for insertion: 
            After insertion, when we call get_dc(p), we are passing a cat that is in the set? Yes. And we are using the Treap that now has z_i? So the predecessor and successor functions for p will include z_i? And that is what we want: because after insertion, p's neighbor is now z_i (if p is the immediate predecessor) and not the old successor (if there was one between p and z_i? But we are sure that p is the immediate predecessor of z_i? and after insertion, the immediate next of p is z_i? 

        How do we know that? 
            We found p as the predecessor of z_i (in the set without z_i) and s as the successor of z_i (in the set without z_i). Then we inserted z_i. Then the immediate neighbors of p: 
                Before insertion: the next neighbor of p was s? Not necessarily: there might be no cat between p and s? Actually, the predecessor of z_i is the largest cat < z_i, and the successor of z_i is the smallest cat > z_i. Then there is no cat between p and z_i, and between z_i and s? Therefore, after insertion, the immediate neighbors of p: 
                    its next neighbor becomes z_i (if p is the immediate predecessor of z_i) -> which it is.

        Similarly, the immediate neighbors of s: its previous neighbor becomes z_i.

        Therefore, the plan is correct.

        Let's test with the sample: 
            "1 1": insert cat 1.
                p = predecessor(1) = None
                s = successor(1) = None
                Then insert 1.
                Then recalc: 
                    p: None -> 0
                    z: get_dc(1): no neighbors -> 3
                    s: None -> 0
                total = 3 -> output 3.

            Then "1 3": insert cat 3.
                p = predecessor(3) = 1
                s = successor(3) = None
                Remove the contribution of p=1: get_dc(1) -> currently, 1 has no neighbors? But wait, we have only cat1 in the set. Then we remove 1's contribution: 3.
                Then insert 3.
                Then recalc:
                    p=1: now in the set, what are the neighbors? 
                        1: next is 3? 
                        so get_dc(1): 
                            p_prev = None
                            p_next = 3
                            check dislike: (1,3) is in the set? Yes, from the input: (1,3) is a dislike pair.
                            so 1: 32? -> wait, the rule: 
                                if it dislikes the cat directly behind? The cat behind is the next? 
                                The rule: 
                                    $32$, if cat recruit $i$ dislikes the cat directly behind them (and not the cat directly in front of them).

                                But the cat behind is the one with larger height? and the line is sorted by increasing height: front is smallest, back is largest.

                                So for cat1: 
                                    directly behind (next) is 3? Then if cat1 dislikes 3? Then it should be 32.

                            So get_dc(1)=32.

                    z=3: 
                        p_prev=1, p_next=None
                        so if 3 dislikes 1? The dislike pair (1,3) is symmetric? The problem says "dislike each other". So if (1,3) is stored, then 3 dislikes 1? 
                        Then for 3: 
                            the cat directly in front is 1? (the one with smaller height) -> front is 1, behind is none? 
                            So: if it dislikes the cat in front? then 323? 
                            But the rule: 
                                $323$, if cat recruit $i$ dislikes the cat directly in front of them (and not the cat directly behind them).

                            So 323.

                    s=None: 0.

                total = 32+323 = 355.

            Output 355.

            Then "1 5": insert cat5.
                p = predecessor(5)=3
                s = successor(5)=None
                Remove p=3: get_dc(3) = 323 (from above: because it has a front cat 1 and no behind? But now we are going to insert 5? So currently (before inserting 5) the set is {1,3}. Then for cat3: 
                    front: 1, behind: none -> so 323? 
                So remove 323.

                Then insert 5.
                Then recalc:
                    p=3: now the neighbors of 3: 
                        front: 1, behind: 5? 
                        Check dislikes: 
                            3 and 1: dislike? (1,3) -> yes.
                            3 and 5: dislike? (3,5) -> yes.
                        So 3: 3233.

                    z=5: 
                        neighbors: front=3, behind=none -> dislikes 3? (3,5) is yes -> 323.

                    s=None: 0.

                total = 355 - 323 + 3233 + 323 = 355 + 3233 = 3588? 
                But the sample output is 3588.

            Then "1 7": insert 7.
                p = predecessor(7)=5
                s = None
                Remove p=5: get_dc(5) = 323 (because currently: set {1,3,5}, and 5 has front=3? and no behind. Dislike 3? (3,5) is yes -> 323.
                Then insert 7.
                Then recalc:
                    p=5: 
                        neighbors: front=3, behind=7.
                        dislikes: (3,5) -> yes, (5,7) -> yes -> 3233.
                    z=7: 
                        front=5 -> dislike? (5,7) -> yes -> 323.
                total = 3588 - 323 + 3233 + 323 = 3588 + 3233 = 6821? 
                But sample output is 6821.

            Then "1 2": insert 2.
                p = predecessor(2)=1
                s = successor(2)=3
                Remove p=1: get_dc(1)=32 (because in the set {1,3,5,7}, 1 has next=3? and we have (1,3) -> so 32? 
                    But wait, after inserting 3,5,7, then the set is {1,3,5,7}. Then when we insert 2, the neighbors of 1: 
                        Before insertion: 
                            1: next is 3? (because 2 is not there) -> so 32.
                Remove s=3: get_dc(3)=3233? 
                Then total remove: 32 + 3233 = 3265.

                Then insert 2.
                Then recalc:
                    p=1: 
                        neighbors: next is 2? 
                        Check: (1,2): is it in the dislike set? The input: 
                            10 4
                            1 3
                            3 5
                            5 7
                            7 9
                        So (1,2) is not in the set. 
                        So get_dc(1): 3 (because only next is 2, but no dislike) -> 3? Actually, rule: 
                            if it dislikes the cat behind? (2) -> no, so 3.

                    z=2:
                        neighbors: prev=1, next=3.
                        Check: (1,2): no -> 3? 
                        (2,3): the input doesn't have (2,3) -> so 3.
                    s=3:
                        neighbors: prev=2, next=5.
                        Check: (2,3): no -> then for (3,5): yes -> but wait, the rule: 
                            It dislikes the cat in front? The front is 2? -> no.
                            It dislikes the cat behind? 5 -> yes (because (3,5) is in the set) -> so 32.

                Then total add: 3 + 3 + 32 = 38.

                Then total = 6821 - 3265 + 38 = 3594? 
                The sample output is 3594.

            Then "1 8": insert 8.
                p = predecessor(8)=7
                s = None
                Remove p=7: get_dc(7)=323 (because in the set without 8: 7 has front=5, and (5,7) is yes -> 323.
                Then insert 8.
                Then recalc:
                    p=7: 
                        neighbors: front=5, behind=8.
                        Check: (5,7): yes, (7,8): not in the set -> so 323? (because only front) -> 323.
                    z=8: 
                        neighbors: front=7 -> check: (7,8): no -> so 3? 
                Then total = 3594 - 323 + 323 + 3 = 3594+3=3597.

            Then "1 9": insert 9.
                p = predecessor(9)=8
                s = None
                Remove p=8: get_dc(8)=3 (front=7, no behind, and (7,8) not in set -> 3)
                Then insert 9.
                Then recalc:
                    p=8: 
                        neighbors: front=7, behind=9.
                        Check: (7,8): no, (8,9): no? -> so 3.
                    z=9: 
                        neighbors: front=8, behind? none -> but note: there is a dislike pair (7,9) in the set? 
                        But the input: 
                            dislike pairs: 1-3, 3-5, 5-7, 7-9.
                        So (7,9) is in the set? 
                        But for cat9: 
                            the cat directly in front is 8? not 7. 
                            So (9,8) is not in the set? and (9,7) is not adjacent? 
                        So 3.

                total = 3597 - 3 + 3 + 3 = 3600.

            Then "1 4": insert 4.
                p = predecessor(4)=3
                s = successor(4)=5
                Remove p=3: 
                    currently, the set without 4: {1,2,3,5,7,8,9}. 
                    What is get_dc(3)? 
                        neighbors: front=2, behind=5.
                        Check: (2,3): no, (3,5): yes -> so 32? 
                Remove s=5: 
                    get_dc(5): 
                        neighbors: front=3, behind=7.
                        Check: (3,5): yes, (5,7): yes -> 3233.
                total remove = 32+3233 = 3265.

                Then insert 4.
                Then recalc:
                    p=3: 
                        neighbors: front=2, behind=4.
                        Check: (2,3): no, (3,4): no -> so 3.
                    z=4: 
                        neighbors: front=3, behind=5.
                        Check: (3,4): no, (4,5): no -> 3.
                    s=5: 
                        neighbors: front=4, behind=7.
                        Check: (4,5): no, (5,7): yes -> so 32? (because only behind) -> 32.

                total add = 3+3+32 = 38.
                total = 3600 - 3265 + 38 = 373.

            Then "2 8": remove 8.
                Get neighbors of 8: 
                    p = predecessor(8)=7
                    s = successor(8)=9
                Remove: 
                    p=7: get_dc(7): 
                        neighbors: front=5, behind=8.
                        Check: (5,7): yes, (7,8): no? -> 323? 
                    z=8: get_dc(8): 
                        neighbors: front=7, behind=9.
                        Check: (7,8): no, (8,9): no -> 3.
                    s=9: get_dc(9): 
                        neighbors: front=8, behind? none -> (7,9) is in the set? but not adjacent -> so 3? 
                So remove: 323+3+3 = 329.

                Then remove 8.

                Then recalc:
                    p=7 and s=9: now they are adjacent? 
                    So for 7: 
                        neighbors: front=5, behind=9.
                        Check: (5,7): yes, (7,9): yes -> 3233.
                    for 9: 
                        neighbors: front=7 -> (7,9) is yes -> 323.
                Then add: 3233+323 = 3556? 

                total = 373 - 329 + 3556 = 3600? 

            But the sample output is 3600.

            Then "1 6": insert 6 -> but wait, the next is "2 1", then "2 2", then "2 9". 

            Actually, the sample input has 13 queries.

            We'll stop here.

        Therefore, we will code the Treap with split and merge and the iterative pred and succ.

        However, note: the predecessor and successor functions for the entire set we need for get_dc? But we are storing the entire set in the Treap. And the iterative method is O(h) and h is O(log n) on average.

        We also have the split and merge that are O(h).

        The total operations: 
            For insertion: 
                split (twice) and merge (twice): each O(h) -> total O(log n)
                then 5 get_dc calls: each does 2 O(h) operations (pred and succ) -> 10 O(h) operations? 
                So total O(12 * log n) per insertion.

            Similarly for removal: O(12 * log n) per removal.

        With n = size of the set (at most 300,000) then log n is about 19. Then 12*19 = 228 per operation, and 300,000 operations -> 300000*228 = 68.4e6, which is acceptable in C++ but in Python we must be cautious.

        But 68.4e6 operations in Python might be borderline in PyPy/C++ but in CP Python we might need optimization.

        Alternatively, we note that the get_dc function for a cat x only requires two dislike checks? So the heavy part is the predecessor and successor queries? 

        We can store for each cat in the set its immediate neighbors? 

        How about we maintain a linked list structure? 

            We maintain:
                left_neighbor: dict mapping cat -> the cat to the left (or None)
                right_neighbor: dict mapping cat -> the cat to the right (or None)

            Then when we insert a cat z:
                We use the Treap to find the predecessor p and successor s? 
                Then we set:
                    left_neighbor[z] = p
                    right_neighbor[z] = s
                    If p exists: right_neighbor[p] = z
                    If s exists: left_neighbor[s] = z

            Then when we remove z:
                p = left_neighbor[z]
                s = right_neighbor[z]
                If p exists: right_neighbor[p] = s
                If s exists: left_neighbor[s] = p

            Then in get_dc(x), we can get the neighbors in O(1) by the dictionaries.

            Then we avoid the predecessor and successor queries in get_dc? 

            Then the cost per insertion: 
                two predecessor/successor queries (which are O(log n)) 
                and then updating the linked list: O(1)
                and then the get_dc calls: O(1) per call (because we have the neighbors from the dictionary)

            Then total per insertion: 
                pred: O(log n)
                succ: O(log n)
                then 2*O(1) for updating the linked list
                then 3 get_dc calls: each O(1) -> 3*O(1)

            Similarly for removal: 
                get the neighbors from the linked list: O(1)
                then update the linked list: O(1)
                then no need to call pred/succ for the neighbors? 

            But wait: in insertion, we remove the contributions of p and s (which we get from the Treap's pred/succ) and then after insertion we recalc p, z, and s. But after updating the linked list, the neighbors of p and s change? So we must recalc.

            However, the get_dc for p and s: we have the linked list so we can get their neighbors from the dictionaries. 

            Then we don't need the Treap for get_dc? 

            Actually, we only need the Treap for the initial predecessor and successor of z during insertion.

            Then we maintain the linked list to have O(1) access to neighbors.

            This will speed up the get_dc from O(log n) to O(1). 

            Then the total cost per insertion: 
                Two Treap queries (pred and succ): O(log n) each -> O(2*log n)
                Then update the linked list: O(1)
                Then 3 get_dc: 3*O(1) = O(1)

            Similarly, per removal: 
                We get p and s from the linked list: O(1)
                Then update the linked list: O(1)
                Then 3 get_dc calls (before removal) and 2 get_dc calls (after removal) for p and s: 5*O(1) = O(1)

            And the Treap insert/delete: O(log n)

            Total per insertion: O(log n) + O(1) = O(log n)
            per removal: O(log n) + O(1) = O(log n)

            Then the entire q operations: O(q * log n) = 300000 * 19 = 5.7e6, which is acceptable.

        Therefore, we choose to maintain:

            left_neighbor = {}   # for a cat, the cat immediately to the left (smaller) in the line, or None if none.
            right_neighbor = {}   # for a cat, the cat immediately to the right (larger) in the line, or None if none.

            And we also maintain the Treap for the entire set to get the initial predecessor and successor for the new cat.

            Steps:

                Insertion(z):
                    p = treap.predecessor(z)   # O(log n)
                    s = treap.successor(z)      # O(log n)

                    # update the linked list for the new cat z:
                    left_neighbor[z] = p
                    right_neighbor[z] = s
                    if p: 
                        right_neighbor[p] = z
                    if s:
                        left_neighbor[s] = z

                    # update the Treap: insert(z)

                    # Now, the cats p and s (if exist) have changed neighbors, and we have a new cat z.

                    # We recalc the discontentment for p, z, s.

                Removal(z):
                    p = left_neighbor[z]
                    s = right_neighbor[z]

                    # update the linked list:
                    if p: 
                        right_neighbor[p] = s
                    if s:
                        left_neighbor[s] = p

                    # remove z from the Treap: delete(z)

                    # Now, the cats p and s have changed neighbors.

            Then get_dc(x) becomes:

                p_prev = left_neighbor.get(x, None)
                p_next = right_neighbor.get(x, None)

                ... then the same as before.

        This avoids calling the Treap for get_dc.

        We must initialize the linked list dictionaries.

        And note: when the set is empty, then we don't have p and s.

        We'll code accordingly.

        We'll implement the Treap with the iterative pred and succ for the entire tree? But we only use the Treap for the initial pred and succ of z during insertion. And we also use the Treap to maintain the set for the next insertions? 

        The Treap must support:
            insert, delete, predecessor, successor (for a key not in the set) -> which we have.

        We'll code the Treap as described.

        Let's code accordingly.

        Due to the complexity of the Treap, we hope it is efficient.

        Note: the predecessor and successor functions for the entire tree (iterative) are O(h) and the tree is a Treap so the height is O(log n) on average.

        We use iterative pred and succ.

        We'll code without parent pointers.

        Steps for the iterative functions:

            def iterative_predecessor(key):
                cur = root
                candidate = None
                while cur:
                    if cur.key < key:
                        candidate = cur.key
                        cur = cur.right
                    else:
                        cur = cur.left
                return candidate

            def iterative_successor(key):
                cur = root
                candidate = None
                while cur:
                    if cur.key > key:
                        candidate = cur.key
                        cur = cur.left
                    else:
                        cur = cur.right
                return candidate

        But note: we are not using the parent, and we are not storing the entire tree in a parented way.

        We'll implement the Treap with split and merge for insert and delete.

        Due to time, we hope the constants are low.

        Let's code accordingly.

        We'll use a class Node.

        We must be cautious: the Treap may be heavy to code? But we only have 300,000 operations.

        We'll try.

        Alternatively, we can use the sorted list from the bisect module for the entire set? Then the predecessor and successor for a new cat z: we can use 
            pos = bisect.bisect_left(sorted_list, z)
            p = sorted_list[pos-1] if pos-1>=0 else None
            s = sorted_list[pos] if pos < len(sorted_list) else None   # but wait, bisect_left gives the first index >= z, but z is not in the list? So the element at pos is the successor? 
            But then we insert z, and we update the linked list.

        But then the sorted list insertion is O(n). And we do 300,000 of them: worst-case 300000^2 = 90e9, which is too slow.

        Therefore, we stick to the Treap.

        We'll code the Treap.

        Steps for the entire code:

            Read n, m, and the dislike pairs.

            Build a set for the dislike pairs: store tuples (min, max)

            Read q.

            Initialize:
                total_discontent = 0
                root = None   # for the Treap
                left_neighbor = {}
                right_neighbor = {}

            We'll implement the Treap: split, merge, insert, delete, and the iterative pred and succ.

            Then for each query:

                if d_i == 1:
                    z = z_i
                    p = iterative_predecessor(z)   # returns None if not found
                    s = iterative_successor(z)

                    # Remove the discontentment of p and s (if they exist) from the total.
                    if p is not None:
                        total_discontent -= get_dc(p)   # which uses left_neighbor and right_neighbor
                    if s is not None:
                        total_discontent -= get_dc(s)

                    # Update the linked list for z, p, s.
                    left_neighbor[z] = p
                    right_neighbor[z] = s
                    if p is not None:
                        # break the link between p and s? and connect p and z.
                        right_neighbor[p] = z
                    if s is not None:
                        left_neighbor[s] = z

                    # Insert z into the Treap.
                    insert_into_treap(z)

                    # Recalculate the discontentment for p, z, and s.
                    new_val = 0
                    if p is not None:
                        new_val += get_dc(p)
                    if s is not None:
                        new_val += get_dc(s)
                    new_val += get_dc(z)
                    total_discontent += new_val

                else: # d_i == 2
                    z = z_i
                    p = left_neighbor.get(z, None)
                    s = right_neighbor.get(z, None)

                    # Before removal, remove the discontentment of p, z, s.
                    val_remove = 0
                    if p is not None:
                        val_remove += get_dc(p)
                    if s is not None:
                        val_remove += get_dc(s)
                    val_remove += get_dc(z)
                    total_discontent -= val_remove

                    # Update the linked list: remove z, and connect p and s.
                    if p is not None:
                        right_neighbor[p] = s
                    if s is not None:
                        left_neighbor[s] = p
                    # Remove z from the linked list dictionaries?
                    # We can remove z from the dictionaries, but not necessary? But we will not use z again until reinsertion? The problem: it is guaranteed that for insertion the cat is not in the line, and for removal it is in the line. And a cat is inserted at most once and then removed at most once? But we may reinsert a cat that was removed? The problem does not say. 

                    # The input: 
                    #   "It is guaranteed that cat recruit z_i is not currently in the line." for insertion.
                    #   "It is guaranteed that cat recruit z_i is currently in the line." for removal.

                    # So a cat might be inserted, removed, and then inserted again? 

                    # Therefore, we should remove it from the linked list dictionaries? Or we can overwrite when we reinsert. 

                    # We choose to not remove, and when we reinsert we will overwrite.

                    # Remove z from the Treap.
                    delete_from_treap(z)

                    # Now, after removal, we update the discontentment for p and s.
                    new_val = 0
                    if p is not None:
                        new_val += get_dc(p)
                    if s is not None:
                        new_val += get_dc(s)
                    total_discontent += new_val

            Then output total_discontent.

        Note: when a cat is reinserted, we will reset its left_neighbor and right_neighbor.

        We must be cautious: the linked list and the Treap are maintained independently? The Treap is only for the initial pred and succ queries for a new insertion.

        We'll code accordingly.

        Due to the length, we hope we can complete.

        Let's code the Treap and the entire solution.

        We'll use a random priority.

        We'll seed the random? But not necessary.

        We'll create a class Node.

        Note: the Treap operations (split and merge) are recursive? and the stack depth is O(log n). 300,000 nodes: log2(300000)=19, so we are safe.

        But worst-case recursion depth: 19, which is safe.

        We'll implement:

            def split(node, key):
                if node is None:
                    return (None, None)
                if node.key <= key:
                    l, r = split(node.right, key)
                    node.right = l
                    return (node, r)
                else:
                    l, r = split(node.left, key)
                    node.left = r
                    return (l, node)

            def merge(left, right):
                if left is None: 
                    return right
                if right is None:
                    return left
                if left.priority > right.priority:
                    left.right = merge(left.right, right)
                    return left
                else:
                    right.left = merge(left, right.left)
                    return right

            Then:

            def insert_into_treap(key):
                nonlocal root
                l, r = split(root, key-1)
                new_node = Node(key)
                root = merge(merge(l, new_node), r)

            def delete_from_treap(key):
                nonlocal root
                l, r = split(root, key-1)
                m, r = split(r, key)
                root = merge(l, r)

            But wait, the second split: 
                we split r (which is keys>key-1) at key: then we get m (keys<=key) and r2 (keys>key). 
                Then we merge l and r2.

            But we don't merge m.

        We'll also implement the iterative_predecessor and iterative_successor.

        We must be cautious: the iterative functions work on the entire tree.

        We'll now code.

        Note: We are not using a class for the Treap, so we use global root? Or we can use a class for the Treap? 

        Given time, we'll use global root.

        Alternatively, we can create a Treap class.

        But to keep it simple, we use global root.

        However, we have to update root in the functions.

        We'll do:

            root = None

            def split(node, key): ...  (recursive)

            def merge(left, right): ... (recursive)

            def insert(key):
                global root
                l, r = split(root, key-1)
                new_node = Node(key)
                root = merge(merge(l, new_node), r)

            def delete(key):
                global root
                l, r = split(root, key-1)
                m, r = split(r, key)
                root = merge(l, r)

            def iterative_predecessor(key):
                global root
                cur = root
                candidate = None
                while cur:
                    if cur.key < key:
                        candidate = cur.key
                        cur = cur.right
                    else:
                        cur = cur.left
                return candidate

            def iterative_successor(key):
                global root
                cur = root
                candidate = None
                while cur:
                    if cur.key > key:
                        candidate = cur.key
                        cur = cur.left
                    else:
                        cur = cur.right
                return candidate

        But note: the iterative_successor: 
            We want the smallest key > key.

            Example: 
                We have root=5, and we call for key=4: 
                    5>4 -> candidate=5, then we go left? to the left child of 5, which might be 3? Then 3<4 -> we go right? to 4? then 4==4 -> go right? then we break? 
                Actually, the algorithm for successor (iterative) for a key that is not in the set is:

                    candidate = None
                    cur = root
                    while cur:
                        if cur.key > key:
                            candidate = cur.key   # remember this candidate
                            cur = cur.left        # try to find a smaller one that is still > key
                        else:
                            cur = cur.right

                This returns the smallest key > key.

        This is correct.

        We'll code accordingly.

        Let's hope.

        Due to the sample, we can test.

        We'll output the code.

        Note: The problem constraints: q up to 300,000. The Treap is expected O(log n) per operation.

        We'll hope the constants are low.

        We'll run the sample.

        But we are in Python, and 300,000 * 12 * 20 = 72e6, which might be borderline in PyPy but in Python we might TLE. We must hope that the constants are small.

        Alternatively, we can use an iterative version of split and merge? But they are recursive.

        We'll try the recursive version. The recursion depth is about 20, so we are safe.

        Let's code.

        We'll use:

            import random

        And for the Node:

            class Node:
                __slots__ = ('key', 'priority', 'left', 'right')
                def __init__(self, key):
                    self.key = key
                    self.priority = random.random()
                    self.left = None
                    self.right = None

        We'll do.

        Due to the complexity, we hope.

        Let's code accordingly.

        Note: the split and merge functions are standard.

        We'll now write the code.

        IMPORTANT: We must not use recursion for split and merge if the tree is large? But the depth is only O(log n) so the recursion stack is O(log n) which is about 20, so it is safe.

        We'll write the solution.

        We'll also note: the get_dc function:

            def get_dc(x):
                p_prev = left_neighbor.get(x, None)
                p_next = right_neighbor.get(x, None)

                if p_prev is not None and p_next is not None:
                    # Check dislike: (min(x, p_prev), max(x, p_prev)) in dislike_set
                    # and (min(x, p_next), max(x, p_next)) in dislike_set
                    a = (min(x, p_prev), max(x, p_prev))
                    b = (min(x, p_next), max(x, p_next))
                    d_prev = a in dislike_set
                    d_next = b in dislike_set
                    if d_prev and d_next:
                        return 3233
                    elif d_prev:
                        return 323
                    elif d_next:
                        return 32
                    else:
                        return 3
                elif p_prev is not None:
                    a = (min(x, p_prev), max(x, p_prev))
                    d_prev = a in dislike_set
                    if d_prev:
                        return 323
                    else:
                        return 3
                elif p_next is not None:
                    b = (min(x, p_next), max(x, p_next))
                    d_next = b in dislike_set
                    if d_next:
                        return 32
                    else:
                        return 3
                else:
                    return 3

        We store the dislike_set as a set of tuples.

        Now, we output the entire code.

        We hope it fits in the time.

        Note: We use sys.stdin for speed.

        Let's code.

        IMPORTANT: The dislike_set stores tuples (x, y) with x<y.

        We are guaranteed that the input gives x_i < y_i.

        So we store the pair as (x_i, y_i).

        Then for two cats a and b, we form the tuple (min(a,b), max(a,b)) to check.

        This is O(1) per check.

        We'll run the sample.

        We'll do the first few steps.

        Due to the length, we hope.

        Let's hope.

        We'll write the code accordingly.

        Note: for a cat that is not in the linked list dictionaries, we use .get and return None.

        We assume that for a cat that has not been inserted, we don't have an entry? So we use .get.

        For insertion: we create the entry for z.

        For removal: we leave the entries? They might be reused? But if we reinsert, we overwrite.

        We don't remove the entries from left_neighbor and right_neighbor.

        This is acceptable.

        Now, the complete code.

        We hope.