 We are given a random permutation of length n (1<=n<=100000). We need to count the number of subsequences that have the same longest increasing subsequence (LIS) length as the entire permutation.

 Steps:
 1. Compute f(i): length of LIS ending at i.
    - We can use a Fenwick tree (Binary Indexed Tree) or segment tree. We process left to right.
    - Since the array is a permutation, we can compress the indices (but the values are 1..n so we can use the value as index).

 2. Compute g(i): length of LIS starting at i.
    - Process right to left. Note: for g(i), we consider decreasing indices and we are looking for elements greater than a[i].

 3. Let L = max(f(i)) [the LIS of the entire sequence].
    Then, an element i is critical if f(i) + g(i) - 1 = L.

 4. The critical elements form the set F. The non-critical elements can be chosen arbitrarily (each has 2 choices: present or not).

 5. We need to count the number of subsets of F that have an increasing subsequence of length L (which is the same as the entire sequence). 
    However, note: any subset of F that does not contain an increasing subsequence of length L would not meet the condition. 
    But the entire set F has an increasing subsequence of length L. We are to count all subsets of F that have an increasing subsequence of length L.

    Actually, the problem is to count all subsequences (of the entire array) that have LIS = L. 
    Note: such a subsequence must contain an increasing subsequence of length L. It must include at least one critical element from each level? 

    Alternate approach: 
        Let G = non-critical elements. Then any subsequence of the entire array is formed by:
            choosing a subset of G (2^(|G|) ways) and a subset of F.
        We require that the subsequence has an increasing subsequence of length L. 
        Since the non-critical elements cannot extend the LIS beyond L (because they are not critical), the LIS of the subsequence is determined by the chosen subset of F.

        Therefore, the condition is that the chosen subset of F must have an increasing subsequence of length L.

        Hence, the answer = (number of subsets of F that have LIS = L) * (2^(|G|).

    But note: the empty set of F has LIS=0, which is not L. We want exactly L.

    However, there is a known combinatorial method: 
        The number of subsets of F that have an increasing subsequence of length L is = (2^(|F|) - (number of subsets of F that do NOT contain any increasing subsequence of length L)).

    But note: the entire set F has an increasing subsequence of length L, and we want the subsets that also have that. Actually, we want the subsets that have at least one increasing subsequence of length L.

    However, we can use the following: 
        The set F is the set of all elements that appear in some LIS. Moreover, the structure of F is such that it is partitioned into L levels (by f(i)=1,2,...,L). 
        In each level, the elements are in decreasing order (by value) as we move forward in the sequence.

        A subset of F has an increasing subsequence of length L if and only if it contains an increasing sequence of length L that traverses the levels. 

        This condition is equivalent to: for each level i (from 1 to L), we choose at least one element, and the elements chosen in level i+1 are all less than the elements chosen in level i? Actually, no: the condition is that we can pick one element from each level such that they form an increasing sequence. 

        However, there is a theorem: the set F is a disjoint union of antichains? Actually, it is the opposite: the set F is the union of the levels, and the levels are such that any increasing sequence must pick at most one element per level. Therefore, an increasing sequence of length L must pick exactly one element from each level and the values must be increasing.

        Therefore, the subset has an increasing subsequence of length L if and only if it contains at least one element from each level and the elements from consecutive levels can be arranged in increasing order.

        But note: it is known that the condition for having an increasing subsequence of length L is equivalent to having a system of distinct representatives for the levels that is increasing. 

        However, counting the subsets that have an increasing subsequence of length L is difficult.

    Insight: 
        Instead, we count the subsets of F that do not have any increasing subsequence of length L. Then subtract from 2^(|F|).

        How to count the subsets of F that do not have an increasing subsequence of length L?
        This is the same as: the length of the longest increasing subsequence in the subset is at most L-1.

        We can use a DP that goes level by level (the levels are defined by f(i)=1,...,L) and we maintain the smallest value of the chosen element in the current level (or the last level we picked). 

        We use the following state: 
            dp[i][v] = number of ways to choose a subset from the first i levels (levels 1 to i) such that the smallest value chosen in the last non-empty level (level i) is v. 

        Transition: 
            For level i+1, we choose a non-empty subset from level i+1 such that every element in the subset is <= v (if we have a last non-empty level) OR if we haven't chosen anything (then no constraint). 

        However, note: we can skip a level. The constraint is only that when we pick an element in a level, then the next non-empty level must have all elements <= the smallest value in the current level? 

        Actually, the condition to avoid an increasing subsequence of length L is that we cannot pick one element from each level that is increasing. To avoid that, we break at some level: the idea is that we pick at most one element per level and we require that the sequence of picked elements (if we pick one per consecutive non-empty level) is decreasing? 

        Actually, Dilworth's theorem tells us that the size of the largest antichain is the minimum number of chains needed to cover the poset. But here we have a different structure.

        Known: The set F has the property that the longest increasing subsequence is exactly L, and the levels are the antichain decomposition by the length of the longest increasing subsequence ending at the element.

        To avoid an increasing subsequence of length L, we must not have an increasing subsequence that goes through all L levels. 

        The condition for a subset S of F: 
            For each level i, let S_i = S âˆ© level_i.
            Then, the increasing subsequence condition is broken if for some consecutive levels, the elements are increasing? Actually, we require that there is no chain of length L.

        We can use: 
            dp[level][v] = number of ways to choose a subset from levels 1 to level, and the last non-empty level is 'level' and the smallest element chosen in that level is v.

        Transition: 
            We can skip level i, or we can choose a non-empty subset from level i such that if the last non-empty level was j (with smallest value w), then the entire subset in level i has values <= w. 

        We do:

            Let levels[1..L] be the levels, and for each level i, the elements are sorted in decreasing order (so we know the available elements).

            We start with state for level0: state0 = 1 (no non-empty level so far) and then we process levels 1 to L.

            For level i:
                For the current state (which is a distribution over the last non-empty level's smallest value, or state0 for no non-empty level), we have two options:
                  Option 1: skip level i -> state remains.
                  Option 2: choose a non-empty subset of level i -> then the last non-empty level becomes level i, and the state becomes the smallest value in the chosen subset.

                For Option 2, the constraint is: if we are in state0 (no last non-empty level), then we can choose any non-empty subset and then the state becomes the minimum value of the chosen subset.
                If we are in state w (from a previous level j, j < i), then we must choose a subset of level i such that all elements are <= w, and then the new state is the minimum value in the chosen subset.

            How to compute the number of ways to choose a non-empty subset from level i that has minimum value = v and also satisfies the constraint (if w is present: all elements<=w)? 

                Let the level i have elements: [x0, x1, ..., x_{k-1}] sorted in decreasing order (x0 > x1 > ... > x_{k-1}).

                To have minimum value = v, we must choose v and we can choose any subset of the elements that are greater than v (and also, if w is present, they must be <= w). 

                Without constraint (state0): 
                    The elements that are greater than v are the ones that come before v in the list (because the list is sorted decreasingly). Let the index of v in the list be pos (so v = x_pos). Then the number of elements greater than v is pos. 
                    The number of ways: 2^(pos) [we can choose any subset of these pos elements].

                With constraint w (w>=v): 
                    But note: we require that every element in the chosen subset is <= w. 
                    The chosen subset must be contained in the set of elements in level i that are in the range [v, w]. 
                    How many elements are greater than v and also <= w? 
                        They are the elements in the level i that are in the range (v, w]. 
                    And note: these elements must appear before v in the list? Actually, the list is sorted decreasingly, so the elements greater than v are the ones at indices [0, pos-1]. But we only allow those that are <= w.

                    So the count = the number of elements in the list at indices in [0, pos-1] that are <= w.

                    Then the number of ways = 2^(count).

            Then, for a fixed state w (which is the last non-empty level's smallest value) and a fixed v in level i, the number of ways is 2^(count) if v<=w, and 0 if v>w.

        We then aggregate over v and w.

        However, the number of states w is O(n) and the number of v in a level is O(|level_i|), and the total work per level is O(|level_i| * (#states)). The total states can be O(n) per level, and the total levels is L (which is about O(sqrt(n)) for random permutation, but worst-case O(n)). Then worst-case total work is O(n^2) which is 10e10 for n=100000.

        We need to optimize.

        Optimization: 
            For a level i, we can precompute the following:

            Let A = list of elements in the level (sorted decreasingly).

            We want for each v in A, and for each state w (which is a value from 1 to n, and we have a dp array indexed by w), to compute:

                If w >= v: 
                    count = number of elements in A that are in the range (v, w] and at indices < pos (where v is at pos) -> but note: the elements in A that are in (v, w] and are greater than v are the ones that are > v and <= w. But in the decreasing list, the elements that are > v are the ones from index0 to index(pos-1). So we need the count of these that are <= w.

            How to do this fast? 

            We can precompute the entire list A and then create an array for the entire level. Then, for each state w, we can precompute an array for the level for every v: 
                ways(v) = 2^(count)   for v<=w, and 0 otherwise.

            Then the contribution for state w is: 
                next_state[v] += dp_prev[w] * ways(v)   for every v.

            But the work per w is O(|A|), and the total states w that are non-zero might be many.

            Alternatively, we can iterate v in A and for each v, we want to sum over w>=v: dp_prev[w] * 2^(count(w, v))

            And count(w, v) = the number of elements in A in (v, w] that are at indices < pos(v).

            But note: the set A is fixed. Let T be the set of elements in A. Then, for a fixed v, the count(w, v) is:
                if w < v: 0
                if w>=v: then it is the number of elements in T that are in (v, w] and also are in the prefix of A (from the start until the position of v).

            We can precompute for the entire level an array for each w: the number of elements in T in the prefix of A (until the position of v) that are in (v, w] ... but this is per v.

            We can do: 
                Let F(v, w) = count of elements in A[0:pos] that are in (v, w].

            Then the term for a fixed v is: 
                term = 2^(F(v, w)) for w>=v, and 0 for w<v.

            Then the contribution to next_state[v] is: 
                next_state[v] = sum_{w>=v} dp_prev[w] * 2^(F(v, w))

            But F(v, w) = F(v, min(w, max_value_in_prefix)) ... 

            However, note: F(v, w) = min( F(v, w), |prefix| ) and we can write:

                F(v, w) = (# of elements in the prefix that are in (v, w]) = (# of elements in the prefix that are <= w) - (# of elements in the prefix that are <= v)

            But the prefix includes v and the elements > v. The elements in the prefix that are <= v: only v? because the prefix has elements greater than v and then v. But wait, the prefix [0:pos] includes v? no, v is at pos, and the prefix [0:pos] is [0:pos) (if we consider the element at pos is not included) or [0:pos] including v? 

            Actually, the prefix [0:pos] (exclusive of pos) is the elements strictly greater than v. Then the elements in the prefix [0:pos] that are in (v, w] are the elements in the prefix [0:pos] that are in [v+1, w].

            And the count = (number of elements in the prefix [0:pos] that are <= w) - (number of elements in the prefix [0:pos] that are <= v) = (number of elements in the prefix [0:pos] that are in [1, w]) - (number of elements in the prefix [0:pos] that are in [1, v]) 

            But the prefix [0:pos] has only values > v, so the second term is 0. 

            Therefore, F(v, w) = count = number of elements in the prefix [0:pos] that are in [v+1, w] = number of elements in the prefix [0:pos] that are <= w.

            So we can precompute for the entire level an array for each element in the prefix: we don't need per v, but per v we have a different prefix (the prefix ending at the position of v).

            Let for each v, let P_v = the list of elements in the level that are at indices < pos(v) (which are greater than v). Then, for a fixed w, the count is the number of elements in P_v that are <= w.

            We can precompute a global array for the entire level: but the prefix is different for each v.

        This is very complex.

    Instead, we use the following known solution for this problem (which is common in programming contests):

        Let F be the set of critical elements. 
        We want to count the subsets of F that have an increasing subsequence of length L. 
        But note: it is easier to count the subsets that do NOT have an increasing subsequence of length L.

        And then the answer = 2^(|F|) - (number of subsets of F that do not have an increasing subsequence of length L).

        The number of subsets of F that do not have an increasing subsequence of length L is the same as the number of subsets that have a longest increasing subsequence < L, i.e., <= L-1.

        And this can be counted by a DP that goes over the levels and uses a Fenwick tree. We describe below:

        Steps:

          Let levels[1..L] = lists of critical elements by f(i)=k, and within a level, sort by the value in decreasing order (or by index increasing).

          We will count the number of ways to choose a subset of F that does not contain an increasing subsequence of length L. This is equivalent to: the subset does not contain a chain of length L. 

          We use a DP: 
             dp[i] = a Fenwick tree (or array) that for a value v, stores the number of ways to choose a subset from levels 1..i such that the largest value in the last level (level i) is v. 
          But wait, we want to avoid an increasing chain of length L, but the structure is that the increasing chain must be of length exactly L and through all levels.

          Actually, we can use a more efficient method:

             Let dp[i][v] = the number of ways to choose a subset from the first i levels such that the last chosen element (in the last non-empty level) is v. 

          But then the transition: 
             for level i+1, we can choose any element u in level i+1 such that u < v, and then we can also choose any subset of the elements in level i+1 that are greater than u? 

          This is messy.

    Known solution in literature:

        We can use the following: 
          Let's denote by dp[i] an array indexed by the value in the level i. 
          The recurrence: 
             dp[i][v] = sum_{u in level_{i-1} and u > v} dp[i-1][u] 
                      + 1   [choose only this element]

          But this does not account for choosing more than one element in a level.

        After research, a known approach is to use the following:

          The set F is the set of all elements that appear in some LIS. 
          The levels are the decomposition by the position in the LIS (by the value of f(i)).
          Within a level, the elements are antichain (no two are increasing). 

          The condition for a subset to have an increasing subsequence of length L is that it contains at least one element from each level and that the elements from level i to level i+1 are increasing.

          But we want to count the subsets that do NOT have an increasing subsequence of length L.

          We can use: 
             total_subsets = 2^(|F|)
             invalid_subsets = count the subsets that avoid at least one level OR that have a break in the increasing chain.

          However, it is complex to use inclusion-exclusion over levels.

    After reading the sample inputs and knowing the intended solution for the random permutation:

        We consider the following solution from the editorial guidelines:

          valid_subsets_F = the number of subsets of F that do NOT contain an increasing subsequence of length L.

          Then, the answer = (2^(n) - 2^(|G|) * valid_subsets_F) % MOD.

        How to compute valid_subsets_F?

          We use a DP over the levels. Let's denote:

            Let level[i] = sorted list of values in level i (sorted in increasing order? but then the condition for the next level is to be less than the chosen element in the current level? Actually, we sorted in decreasing order in the level so that as we move in the level the values decrease).

          We design:

            Let dp[0] = 1   (base: no level)
            Then for level i from 1 to L:
                next_dp = [0] * (max_value+1)   # but we will use Fenwick tree over values.

                For the new level, we will for each state in the current dp (which represents the minimum value in the last non-empty level) and then for each possible choice in the current level, we update.

            Specifically, the state after level i is the minimum value in the chosen subset of level i. Why minimum? Because then the next level (i+1) must have values <= this minimum (to avoid forming an increasing chain of length L by taking one from level i and one from level i+1).

            Steps for level i:

                Let the level i have values sorted in decreasing order: [v0, v1, ..., v_{k-1}], v0>v1>...>v_{k-1}.

                For a state s (which is the minimum value in the last non-empty level, or 0 for the state with no non-empty level) from the previous levels (levels 1 to i-1), and for the level i, we can skip or choose a non-empty subset.

                If we skip, then the state remains.

                If we choose a non-empty subset, then the new state will be the minimum value in the chosen subset from level i. Additionally, the chosen subset must satisfy: if the state s is not 0, then the entire subset must be <= s.

                For a fixed new minimum value = v in level i (which is the smallest in the chosen subset), the number of ways to choose the subset is:
                    If the state from the previous level is 0: then we can choose any subset as long as we include v and any subset of the values greater than v (which are the ones that come before v in the list) -> 2^(count_before_v), where count_before_v = the number of elements in the level i that are greater than v and appear before v in the list (which are the ones with index < the index of v).

                    If the state from the previous level is s (s>=1), then we require that the entire chosen subset is <= s. And then the number of ways is: 2^(count_before_v_in_range), where count_before_v_in_range = the number of elements in the level i that are greater than v and <= s.

                Then, the recurrence for the new state is:

                  next_dp[v] = next_dp[v] + (ways) * (dp_old[s])

                We want to aggregate over s.

            We can use a Fen tree for the states s and also for the level i's elements to count the available ones.

            Specifically, for level i:

                Let A = sorted (in increasing order) the values in the level i.

                Precompute an array cnt_prefix such that for any value x, cnt_prefix[x] = number of elements in level i that are <= x.

                Also, for a value v in level i, the number of elements in the level i that are > v and <= s (for a given s) is: 
                    if s < v: 0.
                    else: = (number of elements in level i that are in the range (v, s]) = cnt_prefix[s] - cnt_prefix[v].

                But note: the list in level i is sorted in decreasing order, and the elements greater than v are the ones before v in that list. However, the count by value does not depend on the order.

                However, wait: the count of elements in the level i that are in (v, s] is independent of the order? yes.

                But the number of ways for the state0: 
                    ways0 = 2^(count of elements in level i that are > v) = 2^( (total_in_level - 1 - (number of elements <= v in level i) + ???)

                Actually, the number of elements in level i that are > v is: total_in_level - (number of elements <= v in level i) 
                because the level i has distinct values.

                And the number of elements in level i that are > v and also <= s is: 
                    = max(0, cnt_prefix[min(s, n)] - cnt_prefix[v])   [but note: cnt_prefix[v] includes v, so the count of elements <= v is cnt_prefix[v], then the count in (v, s] is cnt_prefix[s] - cnt_prefix[v]].

                Therefore, for a given state s (s>=1) and v<=s:
                    ways = 2^(cnt_prefix[s] - cnt_prefix[v])

                For state0:
                    ways0 = 2^(total_in_level - cnt_prefix[v])

                Then, the recurrence for a fixed v is:

                  next_dp[v] = 
                     dp_old[0] * (2^(total_in_level - cnt_prefix[v])) 
                     + (2^(-cnt_prefix[v]) * (sum_{s>=v} dp_old[s] * 2^(cnt_prefix[s])) 

                We can precompute for the current level i:

                  Let F(s) = dp_old[s] * 2^(cnt_prefix[s])   for s from 1 to n.

                Then, we build a Fenwick tree over F(s) for s in [1, n].

                Then for each v in level i:

                  term1 = dp_old[0] * pow(2, total_in_level - cnt_prefix[v], MOD) 
                  term2 = (2^(-cnt_prefix[v]) * (Fen_tree.query(v, n))   [Fen_tree.query(v, n) = sum_{s=v}^{n} F(s)]

                Then next_dp[v] = term1 + term2.

            And then the skip branch: the state0 remains as dp_old[0] and the states s>=1 remain as dp_old[s] (because we skip the level).

            Then, after processing level i, the new state0 = dp_old[0]   (from skip)
            and the new states for s>=1 = (skip branch: dp_old[s]) + (non-empty branch: next_dp[v] for each v that becomes state s? note: we are storing by v, so we will have an array for v in level i, and then we add that to the state indexed by v).

            But note: the state after the level i is indexed by the new value v (the minimum in the level i). We then forget the previous state's value? 

            The state is defined as the minimum value in the last non-empty level. So after level i, if we choose a subset in level i, the state becomes v (the minimum in level i). The previous state is not carried as a value, but we aggregated the contributions.

            Therefore, the new state array after level i is:

                new_state0 = dp_old[0]   [skip branch for the level i: and if we were in state0, we remain in state0]
                new_state = [0]*(n+1)   # for s in [1, n]
                for s in range(1, n+1):
                    new_state[s] = dp_old[s]   # from skip branch (if we were in state s and we skip, we remain in state s)
                for v in level_i_values:
                    new_state[v] = (new_state[v] + next_dp[v]) % MOD   # from non-empty branch

            And then we set for the next level:

                dp0 = new_state0
                dp = new_state   (for s from 1 to n)

            After processing all levels (1..L), the total valid_subsets_F = dp0 + sum_{s} dp[s]

        6. Finally, the answer = (2^n - (2^(|G|) * valid_subsets_F) % MOD.

    Implementation details:

        We need to compute:
          f(i): using a Fenwick tree for the LIS ending at i.
          g(i): similarly by reversing the array and looking for decreasing (which is increasing in the reversed array) or we can do a Fenwick tree for the LIS starting at i by scanning from right to left.

        Steps for g(i):
            We can do: 
                g = [1]*n
                create a Fenwick tree for the right part: we process from right to left, and we want for an element a[i], to query the maximum g(j) for j>i and a[j] > a[i]. 
                We can use a Fenwick tree that is keyed by the values, but then we note: we want to query the range [a[i]+1, n] for the maximum g value.

            Actually, we can do:

                We'll use a Fenwick tree that supports range maximum queries? But typically Fenwick tree does range sum or range maximum. We did for f(i) a range maximum query for [1, a[i]-1]? 

                For g(i): 
                   for i from n-1 down to 0:
                      query = query the range [a[i]+1, n] for the maximum g value.
                      g[i] = query + 1
                      then update the tree at position a[i] with g[i].

            We can use a Fenwick tree for range maximum queries. But note: the array is a permutation, so we can use a segment tree or Fenwick tree for range maximum.

        However, the problem says the permutation is random, so the L is about 2*sqrt(n) (around 600 for n=100000). 

        We also need to be careful with the indices.

    Let's code accordingly.

    Steps:

        MOD = 1000003233

        Step 1: Read n and the permutation a.

        Step 2: Compute f and g arrays.

            For f:
                f = [1]*n
                # We'll use a Fenwick tree (1-indexed) for range maximum queries over values from 1 to n.
                fenw = [0]*(n+1)   # fenw[i] for value i.

                We need:
                  update(i, value): set fenw[i] = max(fenw[i], value)
                  query(i): maximum value in [1, i]

                But for f[i], we want the maximum f[j] for j with a[j] < a[i] (and j < i). So we query the range [1, a[i]-1].

                We traverse i from 0 to n-1.

                However, we need the coordinate: the values are from 1 to n, so we can use the value as index.

                But note: we want the maximum value in the prefix of the array for values less than a[i]. 

                We do:

                  for i in range(n):
                     val = a[i]
                     q = query(val-1)   # returns the maximum f in the range [1, val-1]
                     f[i] = q+1
                     update(val, f[i])

                Similarly for g, we traverse from n-1 to 0, and we want the maximum g in the range [val+1, n]. 

                We can do a Fenwick tree for range maximum for the suffix. But note: we can also reverse the values: 
                    Let b[i] = n+1 - a[i], then an increasing sequence in a is a decreasing sequence in b.

                Alternatively, we can define a Fenwick tree that queries the range [val+1, n] for the maximum.

                Or we can use a Fenwick tree that is reversed: we store for values from 1 to n, and we update at position val with g[i], and then query the range [val+1, n].

                But Fenwick tree for maximum query typically doesn't support arbitrary range updates. We can do:

                  We maintain a Fenwick tree for the suffix? 

                Actually, we can do:

                  We create an array tree[1..n] for the Fenwick tree.

                  update(i, val): set tree at position i to max(tree[i], val), and then propagate: 
                      while i <= n:
                          tree[i] = max(tree[i], val)
                          i += i & -i

                  query(i): maximum in [i, n]? 
                      Not standard: the standard Fenwick tree is for [1, i]. 

                We can also re-index: let c[i] = n+1 - a[i]. Then the range [a[i]+1, n] becomes [1, c[i]-1] in the reversed array.

                Then we can do for g:

                  c = [n+1 - a[i] for i in range(n)]
                  Then, for i from n-1 downto 0:
                      q = query(c[i]-1)   # in the Fenwick tree for the array c, which is the maximum g in the range of c values [1, c[i]-1] (which corresponds to a values [a[i]+1, n])
                      g[i] = q+1
                      update(c[i], g[i])

                But note: the Fenwick tree for the reversed array c is the same as for a, just the values are reversed.

            Alternatively, we can do a standard Fenwick tree for the suffix by building a Fenwick tree that is for the array indexed by the original values, but we update from high values to low values? 

            We'll do the re-indexing for g.

        Step 3: 
            L = max(f)  # the LIS length

            F = []
            for i in range(n):
                if f[i] + g[i] - 1 == L:
                    F.append(i)

            |G| = n - len(F)

        Step 4: Group the critical elements by level = f[i]. We have levels[1..L] = lists of the values a[i] for which f[i]=k.

            For k in 1..L:
                levels[k] = [ a[i] for i in F if f[i]==k ]

            Then, sort each level in decreasing order (so that the largest value comes first).

        Step 5: Precompute powers of 2 up to n.

            pow2 = [1]*(n+1)
            for i in range(1, n+1):
                pow2[i] = (pow2[i-1]*2) % MOD

        Step 6: 
            dp0 = 1   # state0: no non-empty level so far
            dp = [0]*(n+1)   # dp[v] for v in [1, n]: the state is the minimum value in the last non-empty level = v.

            We'll also need modular inverses for powers of 2? for the factor 2^(-cnt) in the recurrence.

            Precompute an array for modular inverses of powers of 2? 
                inv2 = pow(2, MOD-2, MOD)   # but we need for exponents up to n.

            Alternatively, we can precompute an array for the modular inverses of 2^k for k up to n.

            Let inv2_pow = [1]*(n+1)
            inv2 = pow(2, MOD-2, MOD)
            inv2_pow[0] = 1
            for i in range(1, n+1):
                inv2_pow[i] = (inv2_pow[i-1] * inv2) % MOD

            But note: 2^(-k) = (2^k)^(-1) mod MOD. So we can also compute:
                two_k = pow(2, k, MOD)
                then 2^(-k) = pow(two_k, MOD-2, MOD)

            But we are going to do it for many k (cnt_prefix[v] for v in the level), and we can precompute an array for 2^(-k) for k in [0, n].

            Let inv_pow2 = [1]*(n+1)
            base = 1
            for i in range(1, n+1):
                base = (base * 2) % MOD
            # then we have 2^n. But we want 2^(-k) = pow(2, -k, MOD) which is pow(2, MOD-1-k % (MOD-1)? ) -> we can do:

            Actually, we can do:
                inv_pow2[0] = 1
                for i in range(1, n+1):
                    inv_pow2[i] = (inv_pow2[i-1] * inv2) % MOD

            But note: 2^(-k) = (2^(-1))^k.

        Step 7: For level k from 1 to L:

            Let level = levels[k]
            total_in_level = len(level)

            If total_in_level==0: then skip this level? but then the state remains. Actually, we continue.

            Precompute an array for the level: the prefix counts for values from 1 to n.

                cnt_prefix = [0]*(n+1)   # for values from 1 to n: the number of elements in the level that are <= x.

                for val in level:
                    cnt_prefix[val] = 1   # mark

                # Then do a prefix sum:
                for i in range(1, n+1):
                    cnt_prefix[i] += cnt_prefix[i-1]

                But note: we are going to use for a value x: the number of elements in the level that are <= x = cnt_prefix[x]

            Build an array F_positive for the current dp (for positive states, i.e., states s in [1, n]):

                F_positive = [0]*(n+1)
                for s in range(1, n+1):
                    # if dp[s] is nonzero, then
                    #   count_s = cnt_prefix[s]   # the number of elements in the current level that are <= s? 
                    #   But wait: we are building cnt_prefix for the current level. We defined it above.
                    F_positive[s] = dp[s] * pow2[cnt_prefix[s]] % MOD

            Build a Fenwick tree for F_positive over the indices 1..n for range [v, n] queries.

            Then, next_dp_level = [0]*(n+1)   # for the non-empty branch: for each v in the level, we will assign state = v.

            For each value v in level:

                # For state0:
                term0 = dp0 * pow2[total_in_level - cnt_prefix[v]] % MOD

                # For positive states: 
                #   We want to sum_{s from v to n} F_positive[s] 
                s_sum = fenw_query(fenw_tree, v, n)   # fenw_tree is built on F_positive, for indices 1..n.

                #   Then term_positive = s_sum * inv_pow2[cnt_prefix[v]] % MOD   # because we multiply by 2^(-cnt_prefix[v])

                term_positive = s_sum * inv_pow2[cnt_prefix[v]] % MOD

                next_dp_level[v] = (term0 + term_positive) % MOD

            Then, update the states for the next level:

                new_dp0 = dp0   # from skip branch: we skipped the level, so state0 remains.

                new_dp = [0]*(n+1)
                for s in range(1, n+1):
                    new_dp[s] = dp[s]   # from skip branch: the state s remains.

                # add the non-empty branch: we have next_dp_level[v] for each v in the level, so we add that to new_dp[v] for v in the level.
                for v in level:
                    new_dp[v] = (new_dp[v] + next_dp_level[v]) % MOD

                # Then set for next level:
                dp0 = new_dp0
                dp = new_dp

        Step 8: 
            valid_subsets_F = (dp0 + sum(dp)) % MOD   # the number of subsets of F that do not contain an increasing subsequence of length L.

            total = pow2[n]   # total number of subsequences
            non_critical_power = pow2[n - len(F)]
            result = (total - non_critical_power * valid_subsets_F) % MOD
            if result < 0: result += MOD

        Step 9: Output result.

    Note: We need a Fenwick tree for range sum (not maximum) for the F_positive array.

    We'll implement a Fenwick tree for range sums.

    However, note: the level might be processed L times (L up to 600 in random permutation, but worst-case L=n, which is 100000). And in each level, we iterate over the values in the level (which is |level|) and build a Fenwick tree for the entire array of size n. 
        Building a Fenwick tree: O(n). 
        Then total work: O(L * n) = 100000 * 100000 = 10e9, which is too much in Python.

    We need to optimize the building of the Fenwick tree.

        We are building a Fenwick tree for F_positive, which is an array of length n. 
        But note: F_positive has only non-zero values at the indices that were in the state. And the state might be sparse? 

        Actually, the state is defined on the entire range [1, n]. But initially, the state is sparse: only the values that appeared in the level and the states carried from the previous levels.

        However, we are building an array of size n+1 and then building a Fenwick tree in O(n). The total levels is L, so worst-case O(L*n) = 100000 * 100000 = 10e9.

    We must note: the permutation is random, so L is about 2*sqrt(n) ~ 632. Then 632 * 100000 = 63.2e6, which is acceptable in C++ but might be borderline in Python.

    But we have to be careful: we also iterate over each value in the level: the total size of all levels is |F|, which is at most n. So the inner loop over v in the level: the sum over levels is O(|F|) = O(n). 

    However, the building of the Fenwick tree is O(n) per level. And the total levels L is O(sqrt(n)) in random permutations, so total work O(sqrt(n)*n) = O(n^(3/2)) = 100000 * 316 = 31.6e6, which is acceptable.

    But worst-case (non-random) L can be n, then O(n^2) = 10e9, which is too slow.

    The problem states: the permutation is random. So we assume L is about 2*sqrt(n).

    We'll proceed.

    Implementation of Fenwick tree for range sum (standard):

        fenw = [0]*(n+1)
        def fenw_update(i, delta):  # add delta at position i (i from 1 to n)
            while i <= n:
                fenw[i] = (fenw[i] + delta) % MOD
                i += i & -i

        def fenw_query(i): # prefix sum [1, i]
            s = 0
            while i:
                s = (s + fenw[i]) % MOD
                i -= i & -i
            return s

        Then, to get the sum over [v, n]:
            = fenw_query(n) - fenw_query(v-1)

        But note: we want [v, n] = prefix_sum(n) - prefix_sum(v-1)

    However, we can build the Fenwick tree once per level? 

        Steps for a level for the positive states:

            We have an array F_positive of size n+1 (indexed from 1 to n).

            We initialize fenw = [0]*(n+1)
            Then for each s from 1 to n:
                if F_positive[s] != 0:
                    fenw_update(s, F_positive[s])

            Then for a query [v, n]: 
                = fenw_query(n) - fenw_query(v-1)

        But note: we are going to do many queries (one per value in the level). The total size of the level over all levels is |F|, so at most n. 

        The total work per level: O(n) to build the Fenwick tree and O(|level| * log n) for the queries.

        Then the total over all levels: O(L * n + |F| * log n) = O(sqrt(n)*n + n * log n) = O(n^(3/2)) which is acceptable for n=100000 (about 316 * 100000 = 31.6e6) and the n log n term is 100000 * 17 = 1.7e6.

    Let's code accordingly.

    However, note: we also have to update for the next level: we are not updating the Fenwick tree after building, so we can do a simple prefix sum array? 

        We can compute an array for F_positive and then compute a suffix sum array? 
            suffix_sum[i] = F_positive[i] + F_positive[i+1] + ... + F_positive[n]

        Then for a query [v, n]: we can do suffix_sum[v] (if we have built a suffix sum array).

        How to build suffix_sum: 
            suffix_sum = [0]*(n+2)
            for i in range(n,0,-1):
                suffix_sum[i] = (suffix_sum[i+1] + F_positive[i]) % MOD

        Then the query for [v, n] is suffix_sum[v].

        This is O(n) per level.

        Then total work: O(L * n) = O(n^(3/2)) which is 31.6e6 for n=100000.

    We choose the suffix sum array for simplicity.

    Steps per level for the positive states:

        Build an array F_positive for s in [1, n]: 
            F_positive[s] = dp[s] * pow2[cnt_prefix[s]] % MOD   [if we have a state s, otherwise 0]

        Then build suffix_sum = [0]*(n+2)
            suffix_sum[n+1] = 0
            for s in range(n,0,-1):
                suffix_sum[s] = (suffix_sum[s+1] + F_positive[s]) % MOD

        Then for each v in the level, the query for [v, n] is suffix_sum[v].

    This is O(n) per level.

    We note: the entire level processing then is O(n) per level and the total levels L is about 2*sqrt(n), so 2*sqrt(100000) ~ 632, and 632 * 100000 = 63.2e6, which might be borderline in Python in 1 second? 

    But the problem says 1 second and n=100000, and we are in Pyton. We hope that PyPy or fast Python can handle 63e6 operations.

    Alternatively, we can optimize by not iterating the entire n for building F_positive? 

        The state dp[s] is nonzero only for s that are in the previous levels. The number of such s is at most the total number of critical elements? but we are storing an array of size n.

        Actually, we are storing an array of size n for dp. The total memory is O(n) and we are doing a loop of n per level.

        We cannot avoid the O(n) per level if we store the entire array.

    We hope that in practice, the random permutation gives L=632 and 632 * 100000 = 63.2e6 is acceptable in Pyton in 1 second.

    Let's try to code.

    We also note: the level is stored as a list of values. The size of the level can vary.

    Steps:

        for k in range(1, L+1):
            level = levels[k]
            total_in_level = len(level)

            # Precompute cnt_prefix for the entire level for values 1..n
            cnt_prefix_arr = [0]*(n+1)   # for values 1..n: we only care about the level
            for val in level:
                if val <= n:   # val is between 1 and n
                    cnt_prefix_arr[val] = 1
            for i in range(1, n+1):
                cnt_prefix_arr[i] += cnt_prefix_arr[i-1]   # now cnt_prefix_arr[i] = number of elements in the level that are <= i

            # Build F_positive array for s from 1 to n: 
            F_positive = [0]*(n+1)
            for s in range(1, n+1):
                # number of elements in the current level that are <= s = cnt_prefix_arr[s]
                F_positive[s] = dp[s] * pow2[cnt_prefix_arr[s]] % MOD

            # Build suffix_sum for F_positive: 
            suffix_sum = [0]*(n+2)
            for s in range(n,0,-1):
                suffix_sum[s] = (suffix_sum[s+1] + F_positive[s]) % MOD

            # For each v in the level:
            next_dp_level = [0]*(n+1)   # we only care about indices 1..n, but we will update for v in level.
            for v in level:
                # term0: from state0
                term0 = dp0 * pow2[total_in_level - cnt_prefix_arr[v]] % MOD
                # term_positive: from positive states
                if v > n: 
                    term_positive = 0
                else:
                    # the number of elements in the level that are <= v = cnt_prefix_arr[v]
                    term_positive = suffix_sum[v] * inv_pow2[cnt_prefix_arr[v]] % MOD
                next_dp_level[v] = (term0 + term_positive) % MOD

            # Update for skip and non-empty branch:
            new_dp0 = dp0   # skip: state0 remains
            new_dp = [0]*(n+1)
            # skip branch: carry over the previous state (for states>=1)
            for s in range(1, n+1):
                new_dp[s] = dp[s]   # skip: the state s remains

            # non-empty branch: add next_dp_level[v] for each v in the level
            for v in level:
                new_dp[v] = (new_dp[v] + next_dp_level[v]) % MOD

            # Then set dp0 = new_dp0, dp = new_dp

        Then after all levels, valid_subsets_F = (dp0 + sum(new_dp)) % MOD   [but note: after the last level, we have new_dp0 and new_dp]

    But note: the state0 is stored in dp0, and the states s>=1 are in new_dp. So valid_subsets_F = (dp0 + sum(new_dp)) % MOD.

    Step 8: 
        non_critical = n - len(F)
        total_subsets = pow2[n]
        result = (total_subsets - pow2[non_critical] * valid_subsets_F) % MOD
        if result < 0: result += MOD

    Print result.

    Let's test with the sample: n=4, a = [4,1,3,2]

        Step 2: Compute f and g.
            a = [4,1,3,2]
            f: 
                i=0: a[0]=4 -> query [1,3]: 0 -> f[0]=1
                i=1: a[1]=1 -> query [1,0] -> 0 -> f[1]=1
                i=2: a[2]=3 -> query [1,2]: max(f[1] which is 1) -> f[2]=2
                i=3: a[3]=2 -> query [1,1]: max(f[1] which is 1) -> f[3]=2
            Then L = max(f)=2.

            For g: 
                We reverse the array and also consider the values: 
                    we can do: 
                        g[3] = 1
                        g[2]: a[2]=3, query in [4] (if we do by value: we want values>3) -> 0? then g[2]=1 -> but then f[2]+g[2]-1 = 2+1-1=2 = L -> critical.
                Alternatively, we do with reversed array:

                    Let b = [2,3,1,4] -> and we want g for the original array: 
                        g[3] = 1
                        g[2]: a[2]=3 -> we want elements after index2: a[3]=2 (which is not greater) -> so g[2]=1? 
                        g[1]: a[1]=1 -> elements after: [3,2] -> the increasing subsequence starting at 1: [1,3] or [1,2] -> so g[1]=2.
                        g[0]: a[0]=4 -> nothing after, so g[0]=1.

                Actually, we can compute g by going backwards:

                    We'll use a Fenwick tree for the suffix for values from 1 to n.

                    i=3: a[3]=2 -> g[3]=1
                    i=2: a[2]=3 -> query values [4] (if any) -> 0 -> g[2]=1
                    i=1: a[1]=1 -> query [2,4]: we see a[2]=3 -> g[2]=1, a[3]=2 -> g[3]=1, and a[0]=4 -> not in the range [2,4]? 
                        Actually, we haven't processed a[0] yet? we go backwards: 
                        i=3: a[3]=2 -> update at 2: g[3]=1
                        i=2: a[2]=3 -> query [4,4] is empty, [3+1, n] = [4,4] -> so 0 -> g[2]=1 -> update at 3: 1
                        i=1: a[1]=1 -> query [2,4]: we have at 2:1, at 3:1 -> the maximum is 1 -> g[1]=1+1=2
                        i=0: a[0]=4 -> query [5,4] is empty -> g[0]=1

                Then:
                    f = [1,1,2,2]
                    g = [1,2,1,1]
                    Then critical if f[i]+g[i]-1 = 2.
                    i0: 1+1-1=1 -> not
                    i1: 1+2-1=2 -> critical
                    i2: 2+1-1=2 -> critical
                    i3: 2+1-1=2 -> critical

                So F = [1,2,3] -> indices 1,2,3 (0-indexed indices: 1,2,3) -> the values: 
                    a[1]=1, a[2]=3, a[3]=2.

            Then levels:
                level1: f[i]=1: i=1 -> value=1
                level2: f[i]=2: i=2 and i=3 -> values: 3 and 2 -> sort level2 in decreasing order: [3,2]

            |G| = 4-3 = 1.

            Precomputation: 
                pow2 = [1,2,4,8,16]

                We need inv_pow2 for exponents up to 4? 
                    inv_pow2[0]=1, inv_pow2[1]= (1/2) mod MOD, ...

            Step: 
                Start: 
                    dp0 = 1
                    dp = [0]*(n+1)   # for s in [1..4] (n=4)

                Level1: 
                    level = [1]  (sorted in decreasing order? but one element -> [1])
                    total_in_level = 1
                    Build cnt_prefix_arr for the level for values 1..4:
                         cnt_prefix_arr[1] = 1, then [0,1,1,1,1] after prefix?
                         Actually, we do:
                            cnt_prefix_arr = [0,0,0,0,0] -> then set index1=1.
                            then do prefix: 
                                i=0:0, i=1:1, i=2:1, i=3:1, i=4:1.

                    Then build F_positive for s in [1,4]:
                         F_positive[s] = dp[s] * 2^(cnt_prefix_arr[s]) 
                         dp = [0,0,0,0,0] -> so F_positive = [0,0,0,0,0]

                    suffix_sum = [0,0,0,0,0,0]

                    For v=1 in level1:
                         term0 = dp0 * pow2[total_in_level - cnt_prefix_arr[1]] = 1 * pow2[1-1] = 1 * 1 = 1
                         term_positive = suffix_sum[1] * inv_pow2[cnt_prefix_arr[1]] = 0 * ... = 0
                         next_dp_level[1] = 1

                    Then update:
                         new_dp0 = dp0 = 1
                         new_dp = dp (which is [0,0,0,0,0]) -> then we add at index1: 1 -> new_dp[1]=1.

                Level2:
                    level = [3,2]  -> values 3,2 (sorted in decreasing order: [3,2])
                    total_in_level = 2
                    Build cnt_prefix_arr for the level:
                         Mark: at 3:1, at 2:1 -> then prefix:
                            [0,0,1,2,2]   (for indices0:0, index1:0, index2:1, index3:1+1=2, index4:2)

                    Build F_positive for s in [1,4]:
                         F_positive[s] = dp[s] * 2^(cnt_prefix_arr[s]) 
                         dp = [0,1,0,0,0] (only dp[1]=1, others 0)
                         Then:
                            s=1: F_positive[1] = 1 * 2^(cnt_prefix_arr[1]) = 1 * 2^0 = 1? (since cnt_prefix_arr[1]=0) -> 1
                            s=2: 0 * 2^1 = 0
                            s=3: 0 * 2^2 = 0
                            s=4: 0 * 2^2 = 0
                         So F_positive = [0, 1,0,0,0]

                    Build suffix_sum: 
                         s=4:0, s=3:0, s=2:0, s=1:1, s=5:0 -> so suffix_sum[1]= (1+0+0+0)=1, suffix_sum[2]=0, suffix_sum[3]=0, suffix_sum[4]=0.

                    Now, for each v in level: [3,2]

                    For v=3:
                         term0 = dp0 (which is 1) * pow2[2 - cnt_prefix_arr[3]] = 1 * 2^(2-2) = 1
                         term_positive = suffix_sum[3] * inv_pow2[cnt_prefix_arr[3]] = 0 * ... = 0
                         next_dp_level[3] = 1

                    For v=2:
                         term0 = 1 * pow2[2 - cnt_prefix_arr[2]] = 1 * 2^(2-1) = 2
                         term_positive = suffix_sum[2] * inv_pow2[cnt_prefix_arr[2]] = 0 * ... = 0
                         next_dp_level[2] = 2

                    Then update:
                         new_dp0 = 1 (from skip: state0 remains)
                         new_dp = [0,0,0,0,0]   initially from skip of the previous states? 
                                 But skip: we carry the previous states: so we start with the previous state: dp = [0,1,0,0,0] -> so new_dp = [0,1,0,0,0] initially.
                         Then we add: 
                             at v=3: new_dp[3] += 1 -> new_dp[3]=1
                             at v=2: new_dp[2] += 2 -> new_dp[2]=2

                    So after level2: 
                         dp0 = 1
                         dp = [0,1,2,1,0]   # for indices 0,1,2,3,4? we only use 1..4: index1=1, index2=2, index3=1.

                Then valid_subsets_F = dp0 + sum(dp[1:5]) = 1 + (1+2+1) = 5.

                Then non_critical = 1, so non_critical_power = 2^1 = 2.
                total_subsets = 2^4 = 16.
                result = 16 - 2*5 = 6.

                Output: 6 -> matches.

        Therefore, we code accordingly.

    Note: In the sample, the critical elements are indices 1,2,3 -> values 1,3,2.

    However, note: the level1: [1] -> we got state1=1.
    level2: [3,2] -> then for v=3: 
        term0 = 1 * 2^(2-2) = 1
        term_positive = 0 -> so 1
    for v=2: 
        term0 = 1 * 2^(2-1) = 2
        term_positive = 0 -> so 2.

    Then the new state: 
        state0 becomes 1 (from skip branch: the previous state0=1 remains)
        state1: from skip branch: the previous state1=1 remains.
        state2: from skip branch: 0, then we add 2 -> 2.
        state3: from skip branch: 0, then we add 1 -> 1.

    Then valid_subsets_F = 1 (state0) + 1 (state1) + 2 (state2) + 1 (state3) = 5.

    We are done.

    Let's run the second sample: 
        "10
         2 4 8 7 3 9 5 6 1 10"

        We know the answer is 84.

        We will not compute by hand.

    We'll code accordingly.

    Note: We must be cautious of the indices: the array a is 0-indexed.

    Implementation:

        Steps for f and g using two Fenwick trees (for the forward and backward) for range maximum queries? 
            But note: for f we did a Fenwick tree for the maximum in [1, a[i]-1] and for g we did a Fenwick tree for the maximum in [a[i]+1, n] by reindexing.

        However, in our sample we did not use the reindexing for g. Let's do for g without reindexing:

            We'll build a Fenwick tree that supports range maximum queries for [a[i]+1, n]? 
            But we did a Fenwick tree for the maximum in a suffix? 

            Alternatively, we can do:

                We'll create a Fenwick tree for the maximum that covers the entire range [1, n] and we update from right to left.

                For g: 
                    g = [1]*n
                    # We'll create a Fenwick tree (for maximum) for the values, initially zeros.
                    # We traverse from n-1 downto 0:
                    #   for a[i], we want the maximum g[j] for j>i and a[j] > a[i] -> in the range [a[i]+1, n]
                    #   query = query_range(a[i]+1, n)
                    #   g[i] = query+1
                    #   then update the tree at a[i] to g[i]

            How to do range maximum query with Fenwick tree? 
                We can use a Fenwick tree that supports point updates and range maximum queries? 
                But Fenwick tree for range maximum is not standard. We can use a segment tree.

            Given time, we use a segment tree for g? or we reindex.

        We choose to reindex for g to convert the range [a[i]+1, n] to [1, n - a[i]] in the reversed array.

        Steps for g:

            Let c[i] = n+1 - a[i]   # so the largest a[i] becomes 1, the smallest becomes n.
            Then an increasing sequence in a is a decreasing sequence in c.

            We want g[i] = length of LIS starting at i in the original array.

            We can compute h[i] = length of the longest decreasing subsequence in the array c from index i to the end? 
            But note: the LIS in a from i is the LDS in c from i? 
                In a: we want increasing: a[i] < a[j] 
                In c: c[i] = n+1 - a[i], so a[i] < a[j]  <=> c[i] > c[j].
                Therefore, the LIS in a is the LDS in c.

            But we want the longest increasing subsequence starting at i in a = longest decreasing subsequence starting at i in c.

            However, we can compute the longest non-increasing subsequence in c? but decreasing means strictly decreasing? 

            Actually, we can do:

                Let d[i] = the longest non-increasing subsequence in c starting at i? 
                But note: in a, we require strictly increasing, which is strictly decreasing in c.

            We can do the same as for f: for g in a, we can compute in the array c from right to left: 
                We want the maximum d[j] for j>i and c[j] < c[i]? because strictly decreasing: c[i] > c[j] and we want non-increasing? 

            Actually, we want strictly decreasing: c[i] > c[j]. 

            So we can compute:

                for i from n-1 down to 0:
                    we want the maximum g[j] for j>i and c[j] < c[i]   (because c is the reversed array: if a[i] < a[j] then c[i] > c[j], but we are in the array c: we want j>i and c[j] < c[i] to form a decreasing sequence in c, which corresponds to an increasing sequence in a).

            Then g[i] = max_{j>i and c[j] < c[i]} g[j] + 1.

            But note: we can use a Fenwick tree for the range [1, c[i]-1] for the maximum.

        We do:

            Build an array c = [n+1 - a[i] for i in range(n)]

            Then for g in the original array = we compute an array h for the array c: 
                h = [1]*n
                Use a Fenwick tree for the maximum for the values of c? which are from 1 to n.

                for i in range(n-1, -1, -1):
                    q = query(c[i]-1)   # the maximum h[j] for j>i (that have been updated) and with c[j] in [1, c[i]-1] (which gives c[j] < c[i])
                    h[i] = q+1
                    update(c[i], h[i])

            Then g[i] = h[i]

        But note: the g we computed is for the array c? but it corresponds to the LDS in c? and that is the LIS in a? starting at i? 

        Yes.

        Therefore, we compute f and g using two Fenwick trees for range maximum.

        However, we did for f in the forward direction for a. For g, we use the reversed array c and then do a backward pass.

    We'll implement two Fenwick trees for range maximum. But note: the Fenwick tree for range maximum has O(log n) per update and query.

    Implementation of Fenwick tree for maximum (not sum):

        We initialize the tree with zeros.

        def update(i, val):
            while i <= n:
                tree[i] = max(tree[i], val)
                i += i & -i

        def query(i):   # returns the maximum in [1, i]
            res = 0
            while i:
                res = max(res, tree[i])
                i -= i & -i
            return res

        For the forward f: 
            tree = [0]*(n+1)
            for i in range(n):
                val = a[i]
                q = query(val-1)   # max in [1, val-1]
                f[i] = q+1
                update(val, f[i])

        For the backward g (using the array c):

            tree = [0]*(n+1)
            h = [0]*n
            for i in range(n-1, -1, -1):
                q = query(c[i]-1)   # in the array c: we are querying [1, c[i]-1] for the maximum h[j] for j>i (which have been updated)
                h[i] = q+1
                update(c[i], h[i])
            g = h

        Then L = max(f)

    Let's test with the sample: a = [4,1,3,2] -> n=4
        c = [4+1 - x for x in a] = [1,4,2,3]

        Compute g (for the array a) using c:

            i=3: c[3]=3 -> query [1,2]: what j>3? none -> q=0 -> h[3]=1, update at 3:1.
            i=2: c[2]=2 -> query [1,1]: 0 -> h[2]=1, update at 2:1.
            i=1: c[1]=4 -> query [1,3]: the maximum of the values at positions 2 and 3: which are 1 and 1 -> q=1 -> h[1]=2, update at 4:2.
            i=0: c[0]=1 -> query [1,0] ->0 -> h[0]=1.

            Then g = [1,2,1,1] -> matches.

    We'll code accordingly.

    Note: we must clear the Fenwick tree for g.

    Steps summary:

        n = int(input)
        a = list of n integers

        # Compute f
        fenw_f = [0]*(n+1)
        f = [1]*n
        for i in range(n):
            val = a[i]
            # query [1, val-1]
            q = 0
            idx = val-1
            if idx>=1:
                q = fenw_query_max(fenw_f, idx)
            f[i] = q+1
            fenw_update_max(fenw_f, val, f[i])

        # Compute c for the reversed array for g
        c = [n+1 - x for x in a]

        # Compute g (using array c, but we call it h for the array c, then g=h)
        fenw_g = [0]*(n+1)
        h = [1]*n
        # traverse from last to first
        for i in range(n-1, -1, -1):
            val = c[i]
            q = 0
            idx = val-1
            if idx>=1:
                q = fenw_query_max(fenw_g, idx)
            h[i] = q+1
            fenw_update_max(fenw_g, val, h[i])
        g = h

        Then L = max(f)

        F = [ i for i in range(n) if f[i]+g[i]-1 == L ]

        ... then the rest.

    We need to implement fenw_query_max and fenw_update_max.

    Note: the Fenwick tree for maximum is as described.

    However, the update: 
        def fenw_update_max(fenw, i, val):
            while i <= n:
                if val > fenw[i]:
                    fenw[i] = val
                i += i & -i

        def fenw_query_max(fenw, i):  # maximum in [1, i]
            res = 0
            while i:
                if fenw[i] > res:
                    res = fenw[i]
                i -= i & -i
            return res

    But note: the tree is 1-indexed.

    Let's test with the sample for f for a=[4,1,3,2] (n=4)

        i=0: a[0]=4 -> query val-1=3: 
            initially fenw_f = [0,0,0,0,0] (index0 unused, 1..4)
            query(3): 
                i=3: binary: 11 -> so we look at index3:0 -> res=0, then i=3-1=2? 
                Actually, we do:
                    i=3 (binary 11): check fenw_f[3] -> 0 -> res=0, then i = 3 - 1 = 2? -> no: the algorithm: 
                    i=3: res = max(res, fenw_f[3]) = 0
                    i = 3 - (3 & -3) = 3-1=2
                    then i=2: fenw_f[2]=0 -> res=0
                    i=2-2=0 -> stop.
            f[0]=1
            update at 4: 
                i=4: update fenw_f[4] = max(0,1)=1 -> then i=4+4 -> 8>4, stop.

        i=1: a[1]=1 -> query(0) -> skip, so q=0 -> f[1]=1
            update at 1: 
                i=1: set fenw_f[1]=1, then i=1+1=2: set fenw_f[2]=max(0,1)=1, then i=2+2=4: set fenw_f[4]=max(1,1)=1 -> then i=4+4=8 stop.

        i=2: a[2]=3 -> query(2): 
            i=2: fenw_f[2]=1 -> res=1, then i=0 -> so q=1 -> f[2]=2
            update at 3: 
                i=3: set to 2, then i=3+1=4: set fenw_f[4]=max(1,2)=2, then i=4+4=8 stop.

        i=3: a[3]=2 -> query(1): 
            i=1: fenw_f[1]=1 -> res=1, then i=0 -> f[3]=2
            update at 2: 
                i=2: set fenw_f[2]=max(1,2)=2, then i=2+2=4: set fenw_f[4]=max(2,2)=2.

        Then f = [1,1,2,2] -> correct.

    We'll code.

    We note: the Fenwick tree for g (using array c) is similar.

    However, the array c is computed from a: c = [n+1 - a_i]

    Finally, we hope that the entire solution runs within the time limit for n=100000 in Python.

    Let's code accordingly.

    Note: We must not forget to take modulo at the end? 
        But the numbers in the Fenwick tree for f and g are small (at most n, and n=100000) so no modulo.

    For the dynamic programming part, we use modulo 1000003233.

    We'll write the code accordingly.

    Due to the length, we structure the code with functions.

    We hope it runs in 1 second for n=100000 in Pyton.

    If it is too slow, we can try to optimize by using arrays instead of lists for the Fenwick trees? or we use a segment tree for the range maximum that is more efficient? 
        But the Fenwick tree is O(log n) per operation.

    Total operations for f and g: O(n log n).

    For the levels: 
        We have L levels, and for each level we do O(n) to build the cnt_prefix_arr and F_positive and suffix_sum.
        Total O(L * n) and L is about 2*sqrt(n) for random permutation, which is 632 for n=100000 -> 63.2e6, which is acceptable in Pyton if we optimize the inner loops.

    Let's try.

    We'll run on the second sample: n=10, a = [2,4,8,7,3,9,5,6,1,10] -> answer=84.

    We hope it passes.

    Note: There is a possibility of TLE in Pyton for 63.2e6 operations, so we try to optimize by using local variables and avoiding function calls in the inner loops.

    We'll write without function calls for the Fenwick trees in the DP part (we use arrays and list comprehensions).

    But the DP part for the levels is only about 63.2e6 for n=100000, which in Pyton might be borderline in Pyton (in C++ it would be 0.3 seconds, in Pyton maybe 10 seconds?) 

    We hope that the judge's Pyton is fast or we might need PyPy.

    Alternatively, we can try to optimize by not iterating the entire n in the inner loop? 

        For F_positive: we only need to consider the states that are nonzero? 
            The state array dp has at most O(|F_prev|) nonzeros, where |F_prev| is the number of critical elements in the previous levels.

        We can store the state as a dictionary? 

        But then building the suffix_sum would be difficult.

    We'll try the straightforward array and hope that the constant factor is low.

    We note: the levels are small in the beginning and grow? 

    But worst-case, we do 100000 per level and 632 levels -> 63.2e6.

    We run and hope.

    If it is too slow, we can use PyPy or C++.

    But the problem requires Python.

    We write the code and hope.

    Let's code.

    IMPORTANT: The problem states the permutation is random. So the L is about 2*sqrt(n). We assume that.

    Steps:

        MOD = 1000003233

        n = int(input().strip())
        a = list(map(int, input().split()))

        # Fenwick tree for maximum for the forward f:
        size = n
        fenw_f = [0] * (size+1)

        def fenw_update_max(fenw, n, i, val):
            while i <= n:
                if val > fenw[i]:
                    fenw[i] = val
                i += i & -i

        def fenw_query_max(fenw, i):
            res = 0
            while i:
                if fenw[i] > res:
                    res = fenw[i]
                i -= i & -i
            return res

        # Compute f
        f_arr = [1] * n
        for i in range(n):
            val = a[i]
            # query [1, val-1]
            if val > 1:
                q = fenw_query_max(fenw_f, val-1)
            else:
                q = 0
            f_arr[i] = q+1
            fenw_update_max(fenw_f, size, val, f_arr[i])

        # Compute c: n+1 - a[i]
        c = [size+1 - x for x in a]

        # Compute g: using array c, backward
        fenw_g = [0] * (size+1)
        g_arr = [1] * n
        # traverse from last to first
        for i in range(n-1, -1, -1):
            val = c[i]
            if val > 1:
                q = fenw_query_max(fenw_g, val-1)
            else:
                q = 0
            g_arr[i] = q+1
            fenw_update_max(fenw_g, size, val, g_arr[i])

        L = max(f_arr) if n>0 else 0

        # Build F: indices i such that f_arr[i] + g_arr[i] - 1 == L
        F_indices = []
        for i in range(n):
            if f_arr[i] + g_arr[i] - 1 == L:
                F_indices.append(i)

        total_critical = len(F_indices)
        non_critical = n - total_critical

        # Group by level = f_arr[i]
        levels = [[] for _ in range(L+1)]   # levels[0] unused, levels[1] to levels[L]
        for i in F_indices:
            lev = f_arr[i]
            if lev <= L:
                levels[lev].append(a[i])

        # Sort each level in decreasing order
        for k in range(1, L+1):
            levels[k].sort(reverse=True)   # largest first

        # Precompute pow2 and inv_pow2 arrays for exponents 0..n
        pow2 = [1] * (n+1)
        for i in range(1, n+1):
            pow2[i] = (pow2[i-1] * 2) % MOD

        # Precompute modular inverses for powers of 2: inv_pow2[i] = (2^(-i)) % MOD
        # We can compute: 
        inv2 = pow(2, MOD-2, MOD)
        inv_pow2 = [1] * (n+1)
        for i in range(1, n+1):
            inv_pow2[i] = (inv_pow2[i-1] * inv2) % MOD

        # Initialize DP:
        dp0 = 1   # state0: no non-empty level
        # dp: array of size (n+1) for states from 1 to n: dp[v] = number of ways that the last non-empty level has minimum value = v.
        dp = [0] * (n+1)   # 1-indexed: we use indices 1..n.

        # If L==0 then we skip the level loop.
        for k in range(1, L+1):
            level_vals = levels[k]
            total_in_level = len(level_vals)

            # If the level is empty, then skip.
            if total_in_level == 0:
                # We still need to carry the state? 
                # Skip: state0 remains, and states s remain.
                # So no change.
                continue

            # Precompute cnt_prefix_arr for the current level: for values 1 to n.
            cnt_prefix_arr = [0] * (n+1)   # 1-indexed: indices 1..n
            for val in level_vals:
                if 1<= val <=n:
                    cnt_prefix_arr[val] = 1
            # Do prefix sum: 
            for i in range(1, n+1):
                cnt_prefix_arr[i] = (cnt_prefix_arr[i] + cnt_prefix_arr[i-1])   # now cnt_prefix_arr[i] is the number of elements in the level that are in [1, i]

            # Build F_positive: for s from 1 to n: F_positive[s] = dp[s] * pow2[ cnt_prefix_arr[s] ] % MOD
            F_positive = [0] * (n+1)
            for s in range(1, n+1):
                # Only if dp[s] is nonzero, but we do all s.
                F_positive[s] = dp[s] * pow2[cnt_prefix_arr[s]] % MOD

            # Build suffix_sum for F_positive: 
            #   suffix_sum[i] = F_positive[i] + F_positive[i+1] + ... + F_positive[n]
            suffix_sum = [0] * (n+2)   # suffix_sum[n+1]=0, suffix_sum[1..n] = the suffix sum
            for s in range(n,0,-1):
                suffix_sum[s] = (suffix_sum[s+1] + F_positive[s]) % MOD

            # next_dp_level: for the non-empty branch, for each v in the level, the new state will be v.
            next_dp_level = [0] * (n+1)   # 1-indexed, for v in [1, n]

            for v in level_vals:
                if v<1 or v>n:
                    continue
                # term0: from state0
                #   number of elements in the level that are > v: = total_in_level - cnt_prefix_arr[v]
                term0 = dp0 * pow2[total_in_level - cnt_prefix_arr[v]] % MOD

                # term_positive: from states s (s>=v) 
                #   = (suffix_sum[v] * inv_pow2[ cnt_prefix_arr[v] ]) % MOD
                term_positive = suffix_sum[v] * inv_pow2[cnt_prefix_arr[v]] % MOD

                next_dp_level[v] = (term0 + term_positive) % MOD

            # Update for the next level: 
            #   skip branch: state0 and states s remain.
            #   non-empty branch: we have new states: next_dp_level[v] for each v in the level.

            # The new state0 is the skip branch for the previous state0: remains.
            new_dp0 = dp0   # skip branch for state0

            # new_dp: 
            #   skip branch: the previous states s (so we copy dp)
            #   non-empty branch: we add next_dp_level at the index v.
            new_dp = [0] * (n+1)
            for s in range(1, n+1):
                new_dp[s] = dp[s]   # skip branch: state s remains.

            for v in level_vals:
                if v<1 or v>n:
                    continue
                new_dp[v] = (new_dp[v] + next_dp_level[v]) % MOD

            dp0 = new_dp0
            dp = new_dp

        # After all levels, the total valid_subsets_F = (dp0 + sum(dp)) % MOD
        total_valid = dp0
        for i in range(1, n+1):
            total_valid = (total_valid + dp[i]) % MOD

        # The number of subsequences that are indistinguishable from a: 
        #   = total_subsets - (2^(non_critical) * total_valid
        total_subsets = pow2[n]
        non_critical_power = pow2[non_critical]
        result = (total_subsets - non_critical_power * total_valid) % MOD
        if result < 0:
            result += MOD

        print(result)

    Let's run the sample n=4, a=[4,1,3,2] -> we got 6.

    We hope.

    Note: We must be cautious: the levels are indexed from 1 to L, and if L=0 we skip the loop.

    We'll run the sample n=0? but n>=1.

    We test with the sample provided: 
        Sample Input #1: 4\n4 1 3 2 -> output 6.
        Sample Input #2: 10\n2 4 8 7 3 9 5 6 1 10 -> output 84.

    We hope it passes.

    Due to the complexity, we hope that the random permutation has L=O(sqrt(n)) and the constant factors are acceptable.

    We output the code.

    IMPORTANT: We must clear the Fenwick trees for f and g after using them? We are reinitializing.

    We write the code accordingly.

    Note: The Fenwick tree for the forward f and backward g are only used in the beginning.

    We'll submit.