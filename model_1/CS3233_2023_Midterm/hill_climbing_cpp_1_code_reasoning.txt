 Okay, let's break down the problem:

 We are given C test cases. For each test case:
   n, m: number of vertices and edges.
   an array a[1..m] of maximum edges for each color (colors 1 to m).
   m edges.

 Conditions for valid coloring:
   1. For color c, we use at most a_c edges.
   2. For each color c, the edges of that color form a connected subgraph (meaning the subgraph induced by the edges of color c is connected).

 We can leave edges uncolored (color 0). We need at least ceil(n/2) colored edges.

 Additional note: the total sum of a_i over i from 1 to m is at most m.

 Important: The constraints say that the sum of n and m over all test cases does not exceed 300,000? Actually, note: 
   "The sum of n and m over all test cases does not exceed 300 000"

 But wait: the sample input has 4 test cases, and the first has n=5, m=4 -> 9; second: n=6, m=11 -> 17; third: same as second -> 17; fourth: n=5, m=10 -> 15. Total 9+17+17+15 = 58, which is <= 300,000? Actually, the problem states: "the sum of n and m over all test cases does not exceed 300 000". So we can have up to 300,000 in total for n and m? Actually, it says "the sum of n and m" (meaning per test case? or over all test cases?) -> the problem says: "The sum of n and m over all test cases does not exceed 300 000". 

 However, note: the constraints for n and m individually: 
   n: 2..300000, m: n-1..300000, and the total over test cases: the sum of (n + m) for all test cases <= 300000.

 But 300000 is the total for n and m? That doesn't match the sample (which had 58). Actually, the problem says: "the sum of n and m over all test cases does not exceed 300 000". So if we let T = total of (n_i + m_i) for all test cases i, then T <= 300000.

 However, note: the sample has 4 test cases: 
   Case1: n1=5, m1=4 -> 9
   Case2: n2=6, m2=11 -> 17
   Case3: n3=6, m3=11 -> 17
   Case4: n4=5, m4=10 -> 15
   Total: 9+17+17+15 = 58.

 So we can have at most 300000 in total for (n+m) over test cases. Since C (number of test cases) is at most 300000, but the total n+m is 300000, then the maximum number of test cases is bounded by 300000, but note that each test case has at least n>=2 and m>=n-1, so the minimum n+m per test case is 2 + 1 = 3. Therefore, the maximum number of test cases is 300000/3 = 100000. Actually, worst-case if each test case has n+m=1? but that's not possible. Actually, the problem says: the total of n and m over test cases is <= 300000. So we can have up to 300000 total? That is, the entire input has at most 300000 in the sum of n and m? Then the total m (edges) and n (vertices) across test cases is bounded by 300000? Actually, the problem says: "the sum of n and m over all test cases does not exceed 300 000". So:

   total = (n1 + m1) + (n2 + m2) + ... <= 300000.

 Therefore, we can have at most 300000 total (n+m). This is critical because we cannot iterate over each test case with O(n) or O(m) without considering the total.

 Approach:

 We need to color at least ceil(n/2) edges. However, note that we have m colors, each with capacity a_i. The total capacity is sum_i a_i <= m (as given). 

 Conditions for the coloring:
   For each color c: the edges with that color form a connected subgraph.

 How can we achieve that?

 Observation:
   The constraints on the colors are independent. However, note that an edge can only be assigned one color.

 Another idea: we are allowed to leave edges uncolored. We only require that the colored edges for each color form a connected subgraph.

 Important: The entire graph is connected, but we are not forced to color the entire graph.

 How about using a spanning tree? But note: the requirement for each color is that the edges of that color form a connected subgraph. However, if we use a color for multiple connected components, that would break the condition.

 Therefore, for each color, the set of edges we assign must form a connected subgraph. Moreover, note that if we assign a color to a set of edges, then the entire set must be connected.

 How can we assign colors? 

 Let k = ceil(n/2). We need at least k colored edges.

 Also note: the capacities a_c: we can only use a_c edges for color c.

 Since the total capacity is at most m, we cannot color more than m edges? Actually, note: we are coloring at least k edges, and k can be as large as (n+1)//2. But n<=300000, so k <= 150000.5 -> at most 150001.

 However, m can be up to 300000, and the total capacity is only m (which is the same as the total number of edges). So we have capacity for at most m edges? Actually, the total capacity is the sum of a_i, which is <= m. Therefore, we cannot color more than m edges? But we need at least ceil(n/2) which might be less than m.

 But note: we are not forced to use the entire capacity.

 However, we must assign colors without exceeding the capacity per color.

 How about:

 Step 1: Check if the total capacity is at least k? Actually, the total capacity is <= m, and k <= n/2 <= 150000, and m can be up to 300000, so it is possible that total capacity is less than k? Then we output "No".

 But note: the problem says: the total capacity is <= m. So if k (which is ceil(n/2)) is greater than the total capacity, then we cannot color k edges -> "No".

 Therefore, a necessary condition: 
   If sum_{c=1}^{m} a_c < ceil(n/2), then output "No".

 But is it sufficient? Not necessarily, because we also have the connectivity constraint per color.

 How to assign colors? 

 Idea: 
   We note that if we are to color at least k edges, and the graph is connected, we can try to use a spanning tree? Actually, the entire graph is connected, but we don't require the entire colored set to be connected (only per color).

 However, the colors are independent. We can use each color to form a connected subgraph. How about we break the graph into connected components per color? Actually, we are free to assign.

 Alternatively, we can use a greedy approach:

   We want to cover at least k edges. We are going to assign colors to edges. The constraint per color is that the edges must form a connected subgraph and the count per color c is at most a_c.

 How about we try to form one large connected component? Actually, we are not forced to have all colored edges connected together (they can be in different colors, and each color forms a connected component by itself).

 However, note: the condition requires per color connected, not overall.

 Important: The problem does not require the entire set of colored edges to be connected. They can be in multiple connected components (each of a single color).

 Therefore, we can assign colors arbitrarily to edges as long as for each color, the edges of that color form one connected component (they can be non-overlapping with other colors).

 How to assign? 

 We can try the following:

   Since the total capacity is at least k, we can assign k edges arbitrarily? But we must form connected components per color.

   How about we start by choosing a spanning tree? Actually, we can use a spanning tree to get a connected graph, but we are going to break it into multiple connected components per color? That might not be straightforward.

 Alternate Insight:

   We note that if we can form a spanning tree (which has n-1 edges) and we want to color at least k = ceil(n/2) edges, then we can color k edges of the spanning tree arbitrarily? But we have the constraint per color: connected.

   Actually, if we assign a color to a set of edges that form a connected subgraph, then we can assign the entire set arbitrarily as long as the set is connected.

   How about we use one color for an entire connected subtree? 

   But note: we are not forced to use one color per connected component? Actually, we can use multiple colors arbitrarily as long as each color's set is connected.

   However, an edge can only have one color.

   We can think: we want to assign k edges to colors such that for each color c, the edges of color c form a connected subgraph.

   We can use the following strategy:

     Step 1: Find a spanning tree T of the graph (using any tree). Then, we know that the tree has n-1 edges.

     Step 2: We note that we can always form a connected subgraph by taking a subtree (which is connected). 

     But how to assign colors? We need to break the tree (or the entire graph) into connected subtrees? Actually, we are not limited to the tree: we can also use non-tree edges? But note: the problem does not require we use the tree.

     However, the graph is connected, so we can use any set of edges that form a connected subgraph for a color.

   But note: we are allowed to use non-tree edges as well.

   How about we try to use a DFS tree? We can then assign colors to entire branches? 

   However, the constraints on the capacities a_c: they are arbitrary.

   Another idea: we can use the colors with large capacities to cover large connected components.

   But note: the condition per color is that the set of edges must be connected. So we can assign one color to a connected set of edges, but we cannot assign a color to two disconnected sets.

   How about we partition the edges of the graph (or at least k edges) into connected components? Actually, we can have multiple colors, each forming one connected component.

   Then the problem reduces to: we want to cover at least k edges by selecting several connected subgraphs, and we assign each connected subgraph to a distinct color? But note: a color can only be used for one connected component? Actually, yes: because the condition for a color is that all the edges of that color form one connected component. So each color corresponds to one connected component.

   Therefore, we can break the set of colored edges into several connected components (each assigned to a distinct color). But note: one color cannot be split into two components.

   So we are going to cover k edges by one or more connected components. And we assign each connected component to one color. The size of the connected component assigned to color c must be at most a_c.

   Then the problem becomes:

      Can we cover at least k edges by a set of connected subgraphs (each being a connected component) such that the size (number of edges) of the i-th component is at most the capacity of the color we assign to it?

   How to assign the colors? We can choose which color to assign to which component arbitrarily? Actually, we can assign the colors arbitrarily to the components as long as the size of the component assigned to color c is <= a_c.

   Therefore, we can do:

      Let S = the set of connected components we choose (each component is connected). Then we require:

          total_edges = sum_{components} (size_i) >= k.

          and for each color c, we can assign a component of size s_i to it only if s_i <= a_c.

      Then we have to check: if we have a set of components (which we can choose arbitrarily) that together cover at least k edges and such that we can assign each component to a distinct color (with capacity at least the size of the component) without exceeding the capacity.

      How to do that?

        We note: we can combine edges arbitrarily? Actually, we are free to choose the connected components arbitrarily? But the entire set of colored edges might not form a connected graph? It can be disconnected? Then we can choose any set of connected subgraphs? However, note: an edge can only be colored once, so the components must be edge-disjoint.

        So we are to choose edge-disjoint connected subgraphs (each connected) such that the total number of edges is at least k, and such that we can assign each component to a color: meaning we have a color for each component (so we need at least as many colors as the number of components) and the size of the component must be <= the capacity of the color we assign.

        But note: we are not forced to use all colors? And we can assign the same color to multiple components? Actually, no: because the condition for a color is that all edges of that color form one connected component. So if we assign two different connected components to the same color, then the set of edges of that color would be disconnected (since the components are disjoint) -> invalid.

        Therefore, we must assign each component to a distinct color.

        Conditions:

          Let t be the number of components we choose. Then we require:

            - The total number of edges covered (sum of the sizes of the components) is at least k.

            - We have at least t colors (but note: we have m colors, so t <= m) and we can assign each component to a color such that the size of the component i is <= a_{color_i}.

          Moreover, we can choose the components arbitrarily as long as they are edge-disjoint and connected.

        How to check? 

          We want to know: is there a set of edge-disjoint connected subgraphs (which together form a forest? actually, they are arbitrary) that cover at least k edges and such that if we let s_1, s_2, ..., s_t be the sizes of the components, then we can assign each s_i to a color j such that s_i <= a_j, and the colors are distinct.

        We can also note: we are free to choose the components arbitrarily? Actually, the entire graph is connected, but we can break it arbitrarily? However, the components must be connected and edge-disjoint.

        How about we try to use as many components as possible? Actually, the condition on the capacities: we have a set of capacities a_1, a_2, ..., a_m (with zeros included). We want to cover at least k edges. We can form components arbitrarily? 

        But note: the entire graph is connected. However, we can take a connected component without having to take the entire graph? Actually, we can choose any set of edges that form a connected subgraph? Then we can choose as many as we want? But the components must be disjoint.

        How to maximize the total edges? Actually, we can take the entire graph? But then we have one component of size m. Then we require that there exists a color c such that a_c >= m. Then we assign that color to the entire graph. Then we have colored m edges -> which is >= ceil(n/2) (since m>=n-1 and ceil(n/2) <= n/2+0.5, and n>=2: for n>=2, n-1 >= ceil(n/2) for n>=3? for n=2: ceil(2/2)=1, n-1=1 -> yes. For n=3: ceil(3/2)=2, n-1=2 -> yes. For n=4: ceil(4/2)=2, n-1=3 -> 3>=2 -> yes. So the entire graph would be a candidate? But we don't require to cover the entire graph, only k edges.

        But the problem: we are constrained by the capacities. We might not have a color that can take the entire graph? Then we have to break it.

        How about we break the graph into many small components? 

        Actually, the minimal size of a connected component is 1 (a single edge). So we can always break the graph into single edges? Then we have m components, each of size 1.

        Then we require: we have at least k components? Actually, we have m components (if we break every edge). Then we can assign each edge to a distinct color? But we have m colors? Actually, we have m colors (from 1 to m). But note: the capacities: we can assign an edge to color c only if a_c>=1. 

        So if we break the graph into single edges, then we require that there are at least k colors with a_c>=1? Actually, we can assign each edge to a distinct color. Then we can color k edges if we have at least k colors with a_c>=1? Actually, we don't need distinct colors for each edge? Actually, we cannot assign two edges to the same color if they are disconnected? But if we break into single edges, each edge is a connected component by itself. Then we can assign two edges to the same color? That would form two disconnected components for that color -> invalid.

        Therefore, we must assign each component to a distinct color. So if we break into single edges, we need as many distinct colors as the number of edges we color.

        Therefore: if we break the graph into t single edges, then we can color t edges only if we have t distinct colors such that each color c assigned to an edge has a_c>=1. But we can also break the graph into larger components.

        How to maximize the total edges? Actually, we can take as many as we want? We are only constrained by the capacities? But we cannot exceed the capacity of the color we assign to a component.

        The problem then reduces to:

          We can form any set of edge-disjoint connected subgraphs. Let the sizes of the components we choose be s_1, s_2, ..., s_t. Then we require:

             sum_i s_i >= k.

          and we can assign these components to distinct colors if we have a set of distinct colors (from the available m colors) such that for each component i, there is a color j (not used for another component) with a_j >= s_i.

        How to check for the existence of such an assignment? 

          We note: we can assign the components arbitrarily to the colors. So we want to know: if we have a set of sizes S = {s_1, s_2, ..., s_t}, and a set of capacities A = {a_1, a_2, ..., a_m} (with zeros), can we assign each s_i to a distinct a_j such that s_i <= a_j?

          This is a matching problem: we can sort the components by size in descending order and the capacities in descending order, and then for the largest component, we assign the smallest capacity that is at least the size? Actually, we can use a greedy matching: 

             sort S in descending order: s_1 >= s_2 >= ... >= s_t
             sort A in descending order: A_1 >= A_2 >= ... >= A_m

          Then we try to assign: for i=1 to t: we need a capacity >= s_i. We can traverse the capacities from largest to smallest? Actually, we can do:

             j = 0
             for each component size s (from largest to smallest):
                 while j < m and A[j] < s: j++   (skip capacities that are too small)
                 if j >= m: then we cannot assign.
                 else: assign this component to A[j] and then j++.

          But note: we have m capacities, and we are only using t of them.

        Therefore, the problem becomes: can we form a set of edge-disjoint connected subgraphs (with total edges >= k) and such that the set of sizes of the components can be matched to the capacities (via the greedy matching above)?

        But note: we can choose the components arbitrarily? How to form the components? 

          We are constrained by the graph: we can only choose connected subgraphs that are edge-disjoint.

        How to form a set of components that covers as many edges as possible? Actually, we can cover all edges? But we don't have to. We only need at least k.

        But note: we want to maximize the chance of matching: we want the set of sizes to be as small as possible? Actually, we want to cover at least k edges, and we want the set of sizes to be as small as possible per component? Or as large as possible? Actually, the matching condition: we have a set of capacities. We want to use the capacities efficiently: we don't want to use a large capacity for a small component.

        However, the matching algorithm above: we match the largest component to the largest capacity that is at least the size? Actually, we can use a greedy matching by sorting the components in descending order and the capacities in descending order and then match the i-th largest component to the i-th largest capacity that is at least the component size? Actually, the greedy matching: we match the largest component to the smallest capacity that is at least its size? Actually, the greedy algorithm for matching in descending order of components:

          Sort components: s1 >= s2 >= ... >= st
          Sort capacities: A1 >= A2 >= ... >= Am

          Then we traverse the capacities and assign the largest capacity that we haven't used to the largest component? Actually, we can do:

             j = 0
             for i in range(t):
                 if A_i >= s_i? Actually, we want to assign the largest component to a capacity that is at least as big. The greedy matching by sorting both in descending order and then checking that for every i: A_i >= s_i.

          Why? Because if we have:

             s_1 <= A_1
             s_2 <= A_2
             ... 
             s_t <= A_t

          then we can assign the largest component to the largest capacity, the second largest to the second largest, etc. This is necessary and sufficient? Actually, it is sufficient: because we can assign arbitrarily. And it is necessary: because if for some i, s_i > A_i, then we cannot assign the i-th largest component to any of the remaining capacities? Actually, we have the capacities sorted in descending order, so the i-th largest capacity is A_i. Then if s_i > A_i, then the remaining capacities (from i to m) are all <= A_i, so they are less than s_i -> no capacity can cover the i-th component.

          Therefore, the necessary and sufficient condition is: if we let t = number of components, and we sort the component sizes in descending order: s[0..t-1] and the capacities in descending order: A[0..m-1], then we require that for every i from 0 to t-1: s_i <= A_i.

        But note: we are free to choose the set of components arbitrarily? And we can choose which edges to include? Then we can choose the set of components to minimize the maximum component size? Or to make the set of sizes as small as possible? Actually, we are constrained: we must cover at least k edges.

        Therefore, we can try to form a set of components such that the condition above holds: after sorting the component sizes in descending order, we have s_i <= A_i for every i (where A is the capacities sorted in descending order, and we only consider the largest t capacities? Actually, we are going to use the t largest capacities? Actually, the condition above uses the first t capacities (the largest t) of the array A.

        But note: we have m capacities. We are going to use t of them. We can choose which t capacities to use? Actually, we must use distinct capacities, but the condition above uses the largest t capacities? Why? Because if we have a set of capacities and we are going to choose t of them to cover the components, the best we can do is to use the largest t capacities? Actually, we want to assign the largest component to the largest capacity? Then the next largest to the next largest? Then the condition is that the i-th largest capacity must be at least the i-th largest component.

        Therefore, we can do:

          Step 1: Sort the capacities in descending order: A[0] >= A[1] >= ... >= A[m-1].

          Step 2: We want to choose a set of edge-disjoint connected subgraphs (each connected) that cover at least k edges, and let t be the number of components and s_1, s_2, ... s_t be the sizes (number of edges in each). Then we require that there exists a set of sizes (nonnegative integers) such that:

            sum_i s_i >= k

            and if we sort the s_i in descending order: s'_1 >= s'_2 >= ... >= s'_t, then we have for every i from 0 to t-1: s'_i <= A[i] (the i-th largest capacity).

        How to form the set of components? We want to maximize the chance of satisfying the condition? Actually, we want to know if there exists any set of components satisfying the two conditions.

        How about we try to minimize the maximum component size? Actually, the condition is easier to satisfy if the components are as small as possible? But then we have more components? And the condition for the descending order: the first few components must be <= the largest capacities. 

        Alternatively, we can try to form the components to be as large as possible? Actually, we want to cover k edges. We can do:

          We are going to form one component that is as large as possible? But then we require a capacity at least as large as that component. Then the next, etc.

        However, note: we are constrained by the graph: we cannot arbitrarily assign edges to components? We have to form connected and edge-disjoint subgraphs.

        How to form the components optimally? 

          Actually, there is a known result: we can always form a set of components that satisfies:

             s_1, s_2, ... s_t (sorted descending) such that for each i, s_i <= A[i] (if we let A be the capacities sorted descending) and the total edges >= k.

          How? 

          We can break the graph arbitrarily? The entire graph is connected. We can use a DFS tree? Then we can break the tree into subtrees? 

          Actually, we can use the following decomposition:

             We can break the graph into connected components by arbitrarily removing edges? But we want to cover as many edges as possible? 

          Alternatively, we can use the following greedy:

             Step 1: Start with the entire graph? Then we remove edges to break it? Actually, we can do:

                 We want to form components that are as large as possible but not exceeding the capacities? Actually, we are constrained by the capacities: we can only form a component of size at most A[0] for the largest capacity? Then we can break the graph into components of size at most A[0]? 

          But note: we also have to cover at least k edges.

          How about we try to form components by starting with the entire graph and then breaking it? 

          Actually, we can use a DFS tree and then break the DFS tree into subtrees? 

          Known fact: In a tree, we can break the tree into connected components of size (number of edges) at most X, and the number of components we get is at least ceil(total_edges / X). Actually, we can break a tree of n-1 edges into components of at most X edges? How?

          Algorithm for breaking a tree:

            We traverse the tree (postorder) and when the current subtree has at least X edges, we break it off. Then we get:

                 number of components <= ceil((n-1)/X)

            But actually, we can break arbitrarily? We want to cover all edges? Actually, we can break the tree into components of at most X edges? And the number of components is at most (n-1)/X? Actually, we can do:

                 We do a DFS: when returning, if the current subtree (from a child) has accumulated edge count >= X, then we break that entire subtree as a component? Actually, the edge count: a subtree of k nodes has k-1 edges.

            Then we can break the tree into components of at most X edges? 

          But note: we are not limited to the tree? We can include non-tree edges? Actually, we want connected components? We can choose any set of edges? Then we can also include non-tree edges? Then we can form a connected component that is a block of the graph? 

          Actually, we are free to choose any set of edges that form a connected subgraph? Then we can form a connected subgraph of any size (as long as it is connected). 

          However, the problem is: we are constrained by the capacities: the largest capacity is A[0]. Then we can form one component of size up to A[0]? Then the next of size up to A[1], etc.

          Then the problem becomes: 

            We have capacities A[0] >= A[1] >= ... >= A[m-1] (with the zeros included? Actually, we can ignore zeros because they cannot cover any component). Let A' be the capacities that are at least 1, sorted descending.

            Then we want to cover at least k edges by a set of edge-disjoint connected subgraphs such that the i-th largest component has size at most A'[i] (if we consider the largest t capacities, then the components must be at most the capacity in descending order).

          How to do it? 

            We can try to form the largest component first: we take a connected subgraph of size = min(entire_graph, A'[0])? But we cannot take more than the entire graph. Then we remove those edges, and then form the next largest component in the remaining graph? Then we require the entire graph remains connected? Actually, no: we are removing edges arbitrarily. After removing the first component, the graph might become disconnected? Then we can take a connected component from one of the connected pieces? 

            Then the algorithm:

               Sort capacities in descending order, and remove zeros? Actually, we can ignore capacities that are zero because we cannot assign any edge to them.

               Let A_sorted = sorted(capacities, reverse=True) and then remove zeros? Actually, we don't need to remove zeros: if a capacity is zero, we skip it? Actually, we can only use capacities that are at least 1.

            Then:

               total_edges_covered = 0
               t = 0
               We start with the entire graph.

               For i from 0 to m-1 (but we break when total_edges_covered >= k) and we traverse the capacities in descending order (largest first):

                  Let c = A_sorted[i] (if c==0, skip)
                  Then we choose a connected subgraph from the remaining graph (which is connected? not necessarily) that has size = min(c, the number of edges in the remaining graph) and that is connected? Actually, we can choose any connected subgraph? How to maximize the edges? We can take an entire connected component of the remaining graph? But we can also take a subset? 

                  Actually, we can always take a spanning tree of a connected component? Then we can take min(c, |E_component|) edges? But we are not limited to trees: we can take cycles? Actually, we can take any connected set of edges? 

                  How to extract a connected subgraph of a connected component? We can take a spanning tree? Then the maximum number of edges we can take from a connected component (with v vertices) is (v-1) if we take a tree? But we can also take more? Actually, the entire component? 

                  Actually, we are not limited to trees. We can take any connected set of edges? Then the maximum number of edges we can take from a connected component is the entire number of edges in that component? 

                  However, we want to take as many edges as possible? But we are constrained by c: we can take at most c edges.

                  Therefore, we can take min(c, |E_component|) edges? But we must form a connected subgraph? How? 

                  Actually, we can take a spanning tree of the connected component? Then we get at most (v-1) edges? But we want to take min(c, |E_component|). But note: we are not forced to take a tree. We can take a connected subgraph that is not a tree? 

                  However, we can take an entire connected component? But if the component has more than c edges, we cannot take the entire component? Then we must take a connected subgraph of at most c edges? 

                  How to take the maximum number of edges? We can take a connected subgraph of size exactly min(c, |E_component|) by:

                     If the entire component has <= c edges: take all.
                     Else: we have to take a connected subgraph with exactly c edges? 

                  But note: we are free to choose any connected subgraph? Then we can take any connected set of c edges? Actually, it might not be possible: for example, a star: we have one center and many leaves. Then we can take any set of edges? Actually, we can take any set of edges that form a connected subgraph. In a star, if we take c edges, we get the center and c leaves? That forms a connected graph.

                  However, in general, we can always take a spanning tree? Then we get v-1 edges? But we might have more edges? How to take more than a tree? 

                  Actually, we can use a greedy: start with one vertex and then add edges one by one? But we want to maximize the number of edges? Then we can take all edges incident to the connected set? 

                  But note: we are constrained by the connectivity. We can do:

                      Start with one vertex. Then we add edges incident to the current set? Then we can add an edge if it is incident to the current set? Then we can add any edge that is incident to the current set? Then we can keep adding until we have c edges? 

                  However, the graph is not necessarily having edges incident to the current set? Actually, the graph is connected? But we are working on a connected component? Then we can always add an edge incident to the current set? 

                  But what if the entire component has many edges? Then we can take up to the entire component? 

                  Actually, we can always take min(c, |E_component|) edges? And it is connected? 

                  Why? Because we can start from any vertex and then add edges incident to the current set. We can always add an edge that is incident to the current set (since the component is connected) until we have taken min(c, |E_component|) edges? But note: we might not be able to take exactly min(c, |E_component|) edges? Actually, we can: we can do BFS-like: we start with one vertex, then add an edge incident to that vertex, then we have two vertices and one edge. Then we can add any edge incident to either of the two, etc. This is the greedy algorithm for building a connected subgraph. And we can add up to the entire set of edges? Actually, no: because the greedy algorithm by edges might not be able to take non-tree edges arbitrarily? But we can: we can take any edge as long as it is incident to the current set? 

                  Actually, the set of edges we take forms a connected subgraph? And we can take any edge that is incident to the current set? Then we can take as many edges as we want? As long as we don't exceed c? 

                  Therefore, we can take min(c, |E_component|) edges from the connected component.

            Algorithm per test case:

               Step 1: Precompute k = ceil(n/2.0)

               Step 2: Read the capacities and sort them in descending order.

               Step 3: If the total capacity (sum of a_i) < k, output "No".

               Step 4: Otherwise, we want to form components. We start with the entire graph (which has m edges). We will remove edges as we assign them to components.

               Step 5: Let's consider the entire graph is one connected component initially.

               Step 6: We sort the capacities in descending order and ignore zeros? Actually, we can skip capacities that are 0.

               Step 7: We traverse the capacities in descending order (largest first). For a capacity c:

                    We want to extract a connected subgraph of size = min(c, |E_current_component|) from the largest remaining connected component? Actually, we maintain a set of connected components (initially one component: the entire graph). Then we take the largest component (by number of edges) and we extract min(c, |E_component|) edges from it? 

                    How to extract? We take a connected subgraph of min(c, |E_component|) edges? Then we remove these edges from the component? Then the component breaks into several pieces? Actually, when we remove a set of edges from a connected component, it breaks into several connected components. But we take a connected subgraph? Then we remove the edges of that subgraph, and the rest may be disconnected? 

                    Therefore, we break the largest component (say with E edges) into two parts:

                         Component1: the chosen connected subgraph of size s = min(c, E) -> we then assign this to the current color? and then we remove these edges.

                         The remaining graph: we break the rest? Actually, the rest might become disconnected. We then add the new connected components (from the remaining part) to our set of components.

               Step 8: We count the total edges we have covered. We stop when we have covered at least k? Actually, we can stop early? But we must use the capacities in descending order? Actually, we are going to use one capacity per step.

               Step 9: After processing all capacities that are at least 1 (or until we have covered k), we check: if we have covered at least k edges? Then we output "Yes" and then we output the coloring? 

               But note: the problem requires that if "Yes", we output the coloring for each edge.

          However, the constraints: the total n+m over test cases <= 300000. But note: the total n and m over test cases is 300000? Then the total m (edges) is at most 300000? Then we can simulate the entire process? 

          But the entire graph has m edges. We are breaking the graph into components by repeatedly taking the largest component and then extracting min(c, |E_component|) edges? Then we break the component? 

          How to simulate? 

            We maintain a set of connected components. Each component is a graph (with vertices and edges). How to store? We cannot store the entire graph for each component? 

          Alternatively, we can simulate without actually storing the entire graph? We can use a global graph and then use DSU to track connectivity? Actually, we are removing edges? Then we are disconnecting? 

          Actually, we are doing the reverse: we start with the entire graph and then remove edges? Then we can use DSU to track the connected components? But we are removing edges? DSU is for adding edges? 

          We can use a DFS to extract a connected subgraph? But we are removing edges arbitrarily.

          Alternatively, we can use a greedy algorithm that doesn't actually simulate the removal? 

          Actually, we can use a simpler approach:

             We know that the condition is: the sorted capacities (descending) A_sorted must satisfy: 
                 for all i (starting from 0) such that the i-th largest capacity A_sorted[i] is at least the size of the i-th largest component we would form? 

             But we don't know the sizes of the components we form? 

          Known result: the necessary and sufficient condition is that the total capacity is at least k and the condition on the component sizes matching the capacities? 

          But how to avoid simulation? 

          There is an insight:

             We can always break the graph into components that are as small as single edges? Then the condition is: we need at least k colors with capacity>=1? But we have the array of capacities: so if we sort the capacities in descending order, then the k-th largest capacity must be at least 1? 

             Actually, we can do better: we can break the graph into components of size at least 1 and at most the capacity available? 

          However, we want to cover k edges. And we want to minimize the "bottleneck" in the matching: we want the largest component we form to be as small as possible? Actually, we want to form components that are as large as possible? Because then we use fewer components? And then we use the largest capacities? 

          How about we try to form as many edges as possible using the largest capacities first? 

          Actually, we can use the following greedy:

             total_edges_covered = 0
             Sort capacities in descending order (ignore zeros) -> let A = sorted(capacities, reverse=True) and remove zeros? Actually, we can keep zeros but skip them.

             Then, we traverse the capacities from largest to smallest:

                 We want to form a component of size = min(c, the number of edges remaining in the graph) but we cannot exceed the capacity c? 

                 However, we must form a connected component? How do we know if we can form a connected component of size c from the entire graph? Actually, we can if the entire graph has at least c edges? But we also have to consider connectivity: the entire graph might be connected? But after removing edges, it becomes disconnected? 

          Actually, we can form a connected component of size up to the entire graph? So we can always form a component of size min(c, m) as long as the graph is connected? But the graph is initially connected. However, after removing edges, the graph may become disconnected? Then we can only form a component from one connected piece? 

          Therefore, we must simulate on the graph? 

          Considering the constraints: the total n+m over test cases is 300000. How many test cases? 

          Let T = total (n_i + m_i) over test cases i <= 300000.

          Then we can simulate each test case? But worst-case, one test case: n+m = 300000? Then we have one test case? Actually, the problem says the sum over test cases of n and m is 300000. So the entire input has at most 300000 for n and m? Then the maximum number of test cases C is at most 300000? But the total n+m is 300000, so the maximum number of test cases is 300000? Actually, no: because each test case has at least n>=2 and m>=n-1, so n+m>= n + (n-1) = 2n-1 >= 3 (for n=2). Therefore, the maximum number of test cases is 300000/3 = 100000. But 300000 is the total of n+m? So we can have up to 100000 test cases? 

          However, the sample input has 4 test cases and total n+m=9+17+17+15=58.

          Therefore, we can have up to 100000 test cases? But the total n+m is 300000, so we can have 100000 test cases each with n+m=3? 

          How to simulate the graph decomposition for each test case? 

          We need an efficient way to extract a connected subgraph of size c from a graph? And then remove those edges? 

          We can represent the graph as an adjacency list? And we mark edges as removed? Then we can do BFS/DFS to extract a connected subgraph? But we want to extract exactly min(c, |E_component|) edges? 

          Algorithm for extraction:

            We maintain for each connected component: a list of edges? Actually, we maintain a set of edges for each component? We also maintain the size (number of edges) of the component.

            We use a global array for edges: initially all edges are in the graph.

            We also maintain a global array of components: initially one component containing all edges.

            Then for each capacity c (in descending order) and while we haven't covered k edges:

                Take the largest component (by edge count) from the set of components.

                Let s = min(c, component.edge_count)

                Then we want to extract a connected subgraph of s edges from this component? 

                How to extract? 

                    We can do:

                      Start from an arbitrary vertex in the component? 

                      Then do a BFS that collects edges? We want to collect s edges? 

                      But note: we cannot cross to vertices that are not in the component? Actually, we are within one connected component.

                      Algorithm for extraction from a component:

                         We maintain a set of vertices that are in the current extracted subgraph? Initially, pick one vertex.

                         We maintain a set of candidate edges: the edges incident to the current set that are in the component.

                         We use a priority queue? Actually, we can do a BFS by edges: 

                            Let's have a queue of edges? 

                         Alternatively, we can do:

                            We maintain a set S of vertices that are in the extracted component, initially {v0} (an arbitrary vertex).

                            We maintain a set of edges E_selected.

                            We maintain a queue (or stack) of edges that are incident to S and not yet taken? Actually, we can iterate over the adjacency list.

                         But note: the total work per test case might be O(m)? And the total m over test cases is bounded by the total m in the input? But the total m over test cases is at most 300000? 

                         However, we have to do this for each capacity? The number of capacities we use is at most the number of non-zero capacities? But the total capacity sum is at most m, so the number of non-zero capacities is at most m? And the total m over test cases is 300000? 

                         Therefore, worst-case, we might do up to 300000 extractions, each on a component that initially has 300000 edges? Then the total work could be 300000 * 300000 -> 90e9, too slow.

          We need a more efficient method.

          Alternatively, we can avoid simulation by a greedy matching without actually decomposing the graph? 

          Known result: the necessary and sufficient conditions are:

             1. total_capacity >= k
             2. Let t be the number of components we would have to use. Let s_1, s_2, ... s_t be the sizes of the components sorted in descending order. Then we require that for every i, s_i <= A_sorted[i] (where A_sorted is the capacities sorted in descending order).

          But how to compute the sizes s_i? We don't know the decomposition.

          Actually, we can use the following: 

             We can always decompose the graph into components such that the size of the i-th largest component is at most the i-th largest capacity? 

          How? 

             We can use the capacities to guide the decomposition: 

                 Sort the capacities in descending order.

                 Let A_sorted[0] be the largest capacity.

                 We want to form a component of size at most A_sorted[0]. How? 

                    We can take a connected subgraph of size min(A_sorted[0], m) from the entire graph? 

                 Then we remove that component, and then we repeat with the next largest capacity on the remaining graph.

          Then the total edges covered is the sum of the sizes of the components.

          And the condition for matching is naturally satisfied: the largest capacity A_sorted[0] >= the largest component size, then next, etc.

          Then the only issue is: can we cover at least k edges? 

          We can simulate until we have covered at least k edges? 

          But note: we might run out of capacities? If we use all capacities and haven't covered k, then we output "No".

          However, the total capacity is at least k? But we are using the capacities in descending order, and we use each capacity to cover a component of size up to the capacity. Then the total edges covered is at least the sum of the capacities? Not exactly: because we might not be able to use a capacity fully? 

          Example: capacity=3, but the largest component only has 2 edges? Then we cover 2 edges with this capacity.

          Then the total edges covered = sum_i (min(A_sorted[i], |E_i|)), where |E_i| is the number of edges in the largest component at step i.

          This might be less than the total capacity, but is it at least the total capacity of the capacities we've used? Not necessarily.

          But note: we are covering as many as we can: we use the largest capacity available to take the largest component available? 

          Then we cover as many edges as possible? 

          Therefore, the algorithm per test case:

             k = ceil(n/2)

             total_capacity = sum(a_i)
             if total_capacity < k:
                 output "No"

             Sort the capacities in descending order.

             We then filter out capacities that are 0.

             Let components = [ the entire graph ]   (represented by the set of edges? But we only care about the edge count? Actually, we need to extract a connected subgraph)

             total_edges_covered = 0
             ans_coloring = vector of m zeros (for the edges)

             For i from 0 to len(capacities)-1:
                 if total_edges_covered >= k: break

                 c = capacities[i]   (which is the next largest capacity)
                 if c==0: break

                 if there is no component: break   (no edges left)

                 Find the largest component (by edge count) from the set of components. Let comp = that component, with edge_count = E.

                 s = min(c, E)

                 // Now extract a connected subgraph of s edges from comp.
                 How to extract? 

                 We can do a BFS starting from any vertex in comp, and we collect edges until we have s edges. We then assign these edges to color = the color index corresponding to this capacity? But note: the problem: the i-th edge in the input has an index? 

                 However, we are not storing the edge indices? 

                 We must output for each edge (given by input order) the color.

                 Therefore, we must store the edge index for each edge.

                 Implementation:

                    We represent the graph with an array of edges, storing (u, v, idx) for each edge.

                 We maintain for each component: 
                    - a set of vertices? 
                    - the set of edges (with their indices) in the component.

                 But the total number of components might be large? 

                 Alternatively, we can store the entire graph initially and then remove edges as we go. We maintain for each vertex its incident edges. And we mark removed edges.

                 We maintain a global array: 
                    removed[edge_index] = false initially.

                 We also maintain a global array: color[edge_index] = 0.

                 We maintain a set of connected components? We can use a DSU for vertices? But we are removing edges, not adding.

                 Or we can use a DSU that we update as we remove edges? That would be expensive.

                 Given the constraints: total n+m over test cases 300000, we can do BFS/DFS on the entire graph if the entire graph has up to 300000 edges? But we do this for each capacity? And the number of capacities we use is at most the number of non-zero capacities? And the total non-zero capacities is at most the total capacity, which is <= m, and the total m over test cases is 300000? 

                 But worst-case, we might use 300000 capacities (each capacity=1) and then do 300000 BFS, each of size 1? Then the total work would be O(m^2) which is 300000^2 = 90e9, too slow.

          Given the complexity, we need a more efficient method.

          Insight from known solutions for edge partitioning in graphs with bounded component size:

             We can use a DFS to traverse the graph and greedily form components. We can do one DFS for the entire test case and assign colors on the fly? 

          Actually, we can do:

             We are going to do a DFS and when we return from a vertex, we check the edge between the current vertex and its parent. 

             But note: we want to form components of size up to the capacities? And we have a fixed order of capacities (largest first). 

          Alternatively, we can use a simple greedy without simulation: 

             Claim: We can achieve the following: the total edges covered is at least k if and only if 
                     total_capacity >= k   and
                     for every i, the number of capacities that are at least i is at least the number of connected components we would have if we remove all edges that are not covered by components of size>=i?

          This is not standard.

          Another known approach: 

             We note that the condition on the capacities sorted in descending order is also known in scheduling: it is the same as the condition for the existence of a histogram. 

             And in graph theory, there is a theorem by Kundu and others? 

          But note: we have a connected graph. 

          There is a known result: the necessary and sufficient condition is that the total capacity is>=k and for every integer x>=1, the number of capacities >=x is at least the maximum number of edge-disjoint connected subgraphs of size>=x that we can find? 

          However, this might be complex.

 Given the complexity of the online decomposition and the constraints on the total input size (300000 for n+m over test cases), we may try the following simpler approach:

   Step 1: If total_capacity < ceil(n/2), output "No".

   Step 2: Sort the capacities in descending order.

   Step 3: Check if the following holds:

        for i from 0 to t-1 (where t = number of non-zero capacities used, but we might use all non-zero capacities? ) 

        But note: we want to cover at least k edges, and we want to know if there exists a decomposition into components such that the sorted capacities (descending) is at least the sorted component sizes (descending) component-wise.

        We don't know the decomposition, but we can try to use a lower bound on the component sizes.

        Insight: the largest component size in any decomposition must be at most the largest capacity. then the next largest at most the next capacity, etc.

        Also, the entire graph has m edges. We are to cover at least k edges. 

        We can ask: what is the minimum possible maximum component size in a decomposition that covers>=k edges? 

        But note: we can always decompose into single edges. then the condition is: the number of capacities>=1 is>=k.

        Therefore, if the number of capacities>=1 is>=k, then we can output "Yes" (by taking k single edges).

        But is that the only condition? No, because we might be able to use larger capacities to cover more edges with fewer components, and then we might not need k capacities? 

        Actually, the condition is: we need to check whether there exists an integer t and a partition of a subset of edges (at least k edges) into t edge-disjoint connected subgraphs such that if we let s_1>=s_2>=...>=s_t be the sizes, then for every i, s_i<=A[i] (where A is the capacities sorted descending).

        How to check without decomposition? 

          We note that the best partition (to minimize the condition) is to use as many large capacities as possible. 

          We can try to greedily assign to the largest capacity as many as possible: 

             Let f(A) = the maximum number of edges we can cover in the graph using the capacities in A.

          Then we need f(A)>=k.

          How to compute f(A) for sorted descending A? 

             We can use a greedy algorithm that repeatedly extracts a connected subgraph of size at most the current capacity from the graph. 

          But the extraction is expensive.

 Given the constraints on the total input size (300000) over test cases, and the fact that the sum of m over test cases is at most 300000, we can try to do a BFS for each extraction only on the current component. But the catch is that the number of extractions might be up to the number of non-zero capacities, and the sum of non-zero capacities over test cases might be large? 

          Note: the total capacity within one test case is at most m, and the total m over test cases is the total number of edges over test cases, which is bounded by the total input size constraint: the sum of m_i over test cases i is at most 300000? 

          But the total input size is the sum of (n_i+m_i) over test cases <=300000. 

          Therefore, the total number of edges over test cases is the sum of m_i, and we know that in each test case: n_i>=2, m_i>=n_i-1, and the sum of (n_i+m_i)<=300000.

          Let T = sum_i (n_i+m_i) <= 300000.

          Also, the total number of edges = sum_i m_i.

          But note: n_i+m_i>=3, and also we have: m_i>=n_i-1, so n_i+m_i>= n_i + (n_i-1) = 2*n_i-1.

          Therefore, the total n_i is at most (300000 + number_of_test_cases)/2. Actually, we have:

             sum_i (n_i+m_i) = sum_i (n_i) + sum_i (m_i) <= 300000.

          Let S = sum_i (n_i) and M = sum_i (m_i). Then S+M<=300000.

          And we have for each test case: m_i>=n_i-1, so M>= S - C, where C is the number of test cases.

          Therefore, S + M <= 300000 and M>= S-C.

          Also, C<=300000.

          But note: the total number of test cases C is at most 300000, but the sum S+M<=300000, so C is at most 300000, but typically C will be at most 100000 (because each test case has n_i>=2, so S>=2C, and then 2C + M<=300000, and M>=S- C = 2C - C = C, so 2C+C=3C<=300000, so C<=100000).

          Therefore, we can have up to 100000 test cases.

          Now, the total number of edges M = sum_i m_i <= 300000 - S <= 300000 - 2C.

          And the total non-zero capacities in one test case is at most m_i.

          Therefore, the total non-zero capacities over test cases is at most M<=300000.

          So we will do at most M (<=300000) extractions, each extraction: we do a BFS on a component to extract min(c, |E|) edges.

          How to represent the graph for extraction? 

             We maintain the entire graph with a global adjacency list, but also we maintain for each vertex the set of incident edges that are not removed.

          We also maintain a set of components? Actually, we maintain a set of components (each is a set of vertices and edges) but we don't. Instead, we maintain a global graph and then for the extraction we take the largest component by edge count. But how to get the largest component? 

             We can maintain a global count of edges per connected component? But we are disconnecting the graph as we remove edges.

          Alternatively, after we extract a connected subgraph from a component, the component may break into several pieces. We then push these new components into a priority queue (max heap by edge count).

          Steps for one extraction:

             current = the component with the most edges (from the max heap)
             c = current capacity
             s = min(c, current.edge_count)

             Then we do a BFS/DFS on the current component to extract a connected subgraph of s edges.

                 We start from an arbitrary vertex in the component.

                 We maintain a set of vertices in the extracted subgraph.
                 We maintain a set of edges in the extracted subgraph.

                 We maintain a queue of vertices to visit.

                 We start with one vertex, then we consider all its incident edges (that are in the component and not removed) and choose one to add? Actually, we can add any edge incident to the current set.

                 We can do: 

                     Queue of vertices: we start with one vertex.

                     For each vertex in the queue, we look at its incident edges in the component. For each edge (u, v), if v is not in the extracted set, we add the edge and the vertex v. But if we have collected s edges, we stop.

                 However, we might add vertices that are incident by multiple edges? 

                 We can do: we maintain for each edge a flag if it's removed. 

                 But note: we are only allowed to use edges that are in the current component.

             Then, after extracting s edges, we remove these edges from the current component. This may break the current component into several connected components. How to compute the new components? 

                 We can do a BFS/DFS on the current component with the remaining edges? 

             Then we push the new components (each with their edge count) into the priority queue.

          The cost of one extraction: O( size of the component we were processing )? 

          Then the total cost over all extractions might be O(m_i * m_i) in one test case? Because each edge, when removed, might be processed in the BFS for extraction and then in the BFS for splitting the component. 

          But note: each edge is removed exactly once. In the BFS for extraction, we only traverse the edges incident to the vertices in the extracted set. And in the splitting, we only traverse the remaining edges in the component.

          Therefore, the total cost for one test case is O(m_i) because each edge is processed at most twice: once when it is in the extracted subgraph, and once when it is in a splitted component (but actually, when we remove the edge, we don't see it again).

          However, when we extract a connected subgraph of s edges, we might visit many vertices and edges incident to them. But we only s edges. And then when we split the component, we do a BFS on the entire remaining component? That might be large.

          Alternatively, we can do: 

             When we remove a set of edges, the component breaks into several connected components. We can use a BFS that avoids the removed edges to find the new components.

          But then the cost for one extraction might be O(|component|) and the sum over all extractions might be O(m_i^2) because we might do a BFS on a large component many times.

          Example: the entire graph is a path: 
              ***********... (m edges)
             and capacities = [1,1,1,...,1] (k times). Then we will do k extractions. In the first extraction, we extract one edge, then we break the path into two. Then we have two components: one of size m-1 and one of size 0 (or one vertex). Then we take the next edge from the large component, breaking it again into two, etc. 
             The work for the first extraction: O(1) for the BFS to extract one edge? But then to split the component, we need to do a BFS on the entire component? That would be O(m) for the first extraction? Then the next extraction: we do a BFS on a component of size m-1, etc. Total work: O(m^2) for one test case.

          This is too slow for m=300000.

 Given the time constraint, and the complexity of online extraction, and the fact that the total input size is only 300000, but the worst-case m per test case might be 300000 and then the work might be O(m^2) -> 90e9, we must find a linear or near-linear method.

          Another idea: 

             Instead of 
            
 We are allowed to leave edges uncolored, and we only require to cover ceil(n/2) edges.

          Therefore, we only need to cover 150000 edges in the worst-case (n=300000).

          Then we can stop the extraction once we have covered ceil(n/2) edges.

          In the extraction, we start with the largest capacity. We use the largest capacities first to cover as many edges as possible.

          How about we try to use the largest capacity to cover as many as possible, then the next largest, and so on, until we have covered>=ceil(n/2) edges.

          But the work per extraction might be linear in the size of the component, and the sum of the sizes of the components we extract is at least ceil(n/2) and at most the total capacity (<=m), which is<=300000.

          However, the splitting of the component after extracting a connected subgraph might be expensive: we may need to do a BFS on the entire component to find the connected components after removing the edges.

          We can avoid splitting the entire component? 

          Note: we only care about the largest component for the next extraction. We maintain a max-heap of components by edge count.

          The initial component has m edges. We extract a connected subgraph of s edges (s = min(c, m)), and then the remaining part is the entire graph with these s edges removed. This may break into several components. We then push each new component into the heap.

          The work for the extraction of the connected subgraph: O(s) [if we do BFS and stop when we have s edges] and then the work for splitting: we are not doing a full BFS of the entire component? 

          Actually, when we remove a set of edges, the component may break into pieces. To find the new components, we need to do a BFS/DFS on the entire component? That is O(|component|).

          Therefore, the work for one extraction is O(|component| + s) = O(|component|).

          How to bound the total work? 

          Each edge is removed in exactly one extraction. Also, in the splitting, we only see the edges that are in the component. But the initial component might be large, and then after extractions, the components become smaller.

          Unfortunately, the worst-case total work might be O(m^2) because one large component might be processed many times.

 Given the complexity, and the fact that the total number of edges we extract is only ceil(n/2) (<=150001), we can try to only extract from the entire graph once, and not worry about the fragmentation? 

          How? 

          Idea: 

             We only need to cover ceil(n/2) edges. Therefore, we can try to extract ceil(n/2) edges in one fell swoop? 

          We can use one color to cover ceil(n/2) edges? Then we require a capacity>=ceil(n/2) for that color.

          Therefore, if there exists a capacity>=ceil(n/2), then we can use that color to cover a connected subgraph of ceil(n/2) edges, and leave the rest uncolored.

          Then we only need to do one BFS to extract min(capacity, m) edges, and we stop when we have ceil(n/2) edges.

          Is that sufficient? 

          Example: if there is one capacity = ceil(n/2), and the rest are 0, then we can use that capacity to cover ceil(n/2) edges (if the graph is connected, we can extract any connected sub of>=ceil(n/2) edges? but note: we need exactly a connected subgraph of floor(n/2) edges? 

          But note: we only require to cover at least ceil(n/2) edges. We can take a connected subgraph of exactly ceil(n/2) edges? 

          Therefore, the algorithm becomes:

             if total_capacity < ceil(n/2): "No"
             else:
                 // find the largest capacity, if it is >= ceil(n/2), then we can use it to cover ceil(n/2) edges.
                 if the largest capacity >= ceil(n/2):
                     // do a BFS from any vertex and collect ceil(n/2) edges.
                     // assign them to that color.
                     // output "Yes" and the coloring: that color for the collected edges, and 0 for the others.
                 else:
                     // all capacities are < ceil(n/2)
                     // then we must use at least two capacities.
                     // and we need to cover ceil(n/2) edges.
                     // but note: we can use several capacities to cover the floor.
                     // however, we can use the single-edge decomposition: 
                         if the number of capacities>=1 is>=ceil(n/2), then we can use ceil(n/2) single edges.
                     // therefore, we only require that there are at least ceil(n/2) capacities>=1.
                     // because in this branch, every capacity is at least 1 (>=1) and < ceil(n/2)
                     // and they are at least ceil(n/2) in count? 
                     // then we can use ceil(n/2) capacities, each for one edge.

                     if count_non_zero_capacities >= ceil(n/2):
                         // then we can choose any ceil(n/2) edges and assign each to a distinct color (choosing a distinct capacity>=1 for each)
                         // output "Yes"
                     else:
                         // then we may need to use one capacity for more than one edge? 
                         // but note: capacities are < ceil(n/2), and count_non_zero_capacities < ceil(n/2), then the total capacity might be >=ceil(n/2)? because capacities are at least 1 and we have count_non_zero_capacities < ceil(n/2), and the largest capacity is < ceil(n/2), then the total capacity might be < ceil(n/2) (e.g., capacities = [1,1] for ceil(n/2)=3) -> then we output "No")
                         // or it might be>=ceil(n/2): example: capacities = [2,2] for ceil(n/2)=3: then total capacity=4>=3, but count_non_zero=2<3.

                         // in this case, can we cover 3 edges? 
                         // we can use one capacity to cover 2 edges, and one capacity to cover 1 edge, total 3 edges.
                         // so the count_non_zero is>= the number of components we use, and the capacities are>= the size of the component they are assigned to.

                         // Therefore, the condition is not just on the count_non_zero, but on the sorted capacities and the sorted component sizes.

                         // But we are in the branch: largest capacity < ceil(n/2), and count_non_zero < ceil(n/2).

                         // Then we must use at most count_non_zero capacities to cover at least ceil(n/2) edges.

                         // Can we do it? 
                         // We have capacities sorted: A[0] >= A[1] >= ... >= A[t-1] (>=1) and t = count_non_zero < ceil(n/2), and sum(A)>=ceil(n/2) (because total_capacity>=ceil(n/2)).

                         // We want to know if there exists a partition of ceil(n/2) edges into t connected subgraphs (edge-disjoint) such that the i-th largest component size is<=A[i].

                         // We can use greedy: 
                            components = []
                            while we need to cover more edges and we have capacities left:
                                take the largest capacity A_i available.
                                try to extract a connected subgraph of size A_i from the graph.
                                if we can extract min(A_i, available_edges) and add that to components, and remove those edges.

                         // But then we would only use at most t extractions, and the total edges covered = sum_{i} min(A_i, available_edges_in_the_component) 
                         // and we hope that the total>=ceil(n/2).

                         // However, the catch: the available_edges_in_the_component might be less than A_i, and the graph may break into small pieces.

                         // We might not be able to achieve the total.

                         // Given the time constraints, and the fact that the total number of edges we need to cover is only ceil(n/2) (<=150001) and the number of capacities we use is at most t (which is < ceil(n/2) <=150001), we can try to do at most t extractions, and the total work might be within 150001 * (size of the components) = 150001 * 300000 in the worst-case -> 45e9, which is borderline in C++ in 1 second? 

          Given the complexity, and the constraints on the total input size (sum of n+m over test cases<=300000), note that one test case might have n+m up to 300000, and then the work for the decomposition might be 45e per test case? and there might be one test case -> 45e9 operations, which is too slow.

 Therefore, we need a better method for the branch where the largest capacity is < ceil(n/2) and the count of non-zero capacities < ceil(n/2).

 However, note: in this branch, the number of non-zero capacities is < ceil(n/2) <= 150000.5 -> at most 150000. But the work for one extraction might be O(m) per extraction, and then total work O(m * count) = 300000 * 150000 = 45e9, which is 45 seconds in C++.

 Given the time limit is 1.0 seconds, we cannot do 45e9 operations.

 We must avoid online extraction in this branch.

 Fortunately, we can use the following: 
   In this branch, we can use the single-edge decomposition: if we can cover by using single-edge components, then we only require that the number of capacities>=1 is>= ceil(n/2), but in this branch we have count_non = count_non_zero < ceil(n/2), so we cannot use only single-edge components.

   However, we can use a hybrid: some components may have more than one edge.

   But note: the condition by sorted capacities and component sizes: 
        capacities sorted: A[0] >= A[1] >= ... >= A[t-1] 
        component sizes sorted: s_0>=s_1>=...>=s_{t-1}

        then we need s_0<=A[0], s_1<=A[1], etc.

   We can use the greedy matching: 
        sort the capacities in descending order: A[0..t-1]
        then we need to partition ceil(n/2) edges into t components (edge-disoint connected subgraphs) with sizes s_i such that when sorted in descending order, s_i <= A[i] for every i.

   This is equivalent to: sum_i s_i = ceil(n/2) and the vector s is dominated by A.

   We can try to see if there exists a vector of s (partition of ceil(n/2) into t connected subgraphs) that is dominated by A.

   But connectedness in the graph constraint makes it hard.

   Alternatively, we can note: 

        The best we can do is to make the largest component as large as possible, then the next, etc., within the capacities.

        Then the condition is: the sum of the capacities is>= ceil(n/2) (which is true) and for every i, the i-th largest capacity is at least the i-th largest component in the partition.

        But we are free to choose the partition. then the most greedy is to make the largest component as large as the largest capacity, then the next as the next capacity, etc. until the sum>= ceil(n/2). 

        However, we are constrained by the graph: we may not be able to form a component of size A[0] if the graph has fewer than A[0] edges? 

        But initially the graph has m edges, and m>=n-1>= ceil(n/2) (because for n>=2, n-1>= ceil(n/2)? for n=2: 1>=1, for n=3:2>=2, for n=4:3>=2, for n=5:4>=3, etc. -> yes, because ceil(n/2) = floor((n+1)/2), and n-1>= floor((n+1)/2) for n>=2.

        Therefore, we can always form a connected subgraph of size A[0] (<= ceil(n/2)-1 < ceil(n/2) <= n-1 <= m) from the graph. 
        Then we can also form the next until we have covered ceil(n/2) edges.

        Therefore, we can do:

            s0 = min(A[0], m)
            s1 = min(A[1], m - s0)
            ... 
            and then sum_{i} s_i >= ceil(n/2)?

        But we can choose the components to have size exactly A[0], A[1], ... until the sum>= ceil(n/2). 

        Example: capacities = [2,2] and ceil(n/2)=3.
           s0 = 2, then s1 = min(2, m-2) >= floor, then total=4>=3 -> works.

        Therefore, in this branch, we can always do it if the sum of the capacities is>= ceil(n/2) (which is true) because we can extract components of size A[0], then A[1], etc. and the total will be>= ceil(n/2) because the sum of capacities is>= ceil(n/2).

        But wait: what if the graph is disconnected after extracting the first component? 
           The first component: we extract a connected subgraph of size A[0] from the entire graph, then the graph may break into several components. But then we can take the next component from one of the pieces, and so on. And the sum will be the sum of the min(A[i], |E_i|) for each step. 

        Since the entire graph initially has m>= ceil(n/2) edges, and we only require to extract at least ceil(n/2) edges, and the sum of the min(A[i], |E_i|) over the t steps is at least the sum of the capacities (because min(A[i], |E_i|) = A[i] if the component we are extracting from has at least A[i] edges, or it is |E_i| which is < A[i], then the total might be less than the sum of capacities) -> but we know the sum of capacities is>= ceil(n/2), and we stop when we have extracted ceil(n/2) edges, so we might not use all capacities.

        Therefore, the condition is: we will be able to extract at least ceil(n/2) edges by iterating over the capacities in descending order and from the largest available component extracting min(capacity, |component|) edges.

        Algorithm for this branch:

           capacities = sorted in descending order (non-zero ones) and we only consider the first ceil(n/2) capacities? but we have count_non_zero = t < ceil(n/2), so we use all t capacities.

           total_covered = 0
           heap = a max-heap of components by edge count, initial one component with m edges.

           for i in range(t):
               if total_covered >= ceil(n/2): break
               c = capacities[i]
               if heap is empty: break
               comp = heap.pop()
               s = min(c, comp.edge_count)
               // extract a connected subgraph of s edges from comp.
               // BFS to extract s edges from comp.
               // then remove these s edges from comp, which may split comp into several new components.
               // total_covered += s
               // if after removing, the remaining part of comp is non-empty (>=1 edge), then split into new components and push them into the heap.

           if total_covered >= ceil(n/2): "Yes"
           else: "No"

        Then, if we want to output the coloring, we would have to store the color for each edge.

        But note: we are within the branch and the work of extraction might be O(m_i) per test case, and the sum of m_i over test cases is<=300000, and the total number of non-zero capacities over test cases is<=300000, and the total work might be O(300000) because each edge is touched at most twice (once when extracted, and once when split out in a small component) -> but wait, when we split a component, we might do a BFS on the entire component, which is expensive.

        However, we only do a BFS for the extraction of the connected subgraph (which is O(s)) and then we do a BFS for the entire component to split it ( which is O(|comp|) ).

        The sum over all extractions of |comp| might be O(m_i^2) in the worst-case.

        Therefore, we must hope that the components become small quickly.

        But note: the total number of edges we extract is at most ceil(n/2) (<=150001) and the number of extraction steps is at most the number of non-zero capacities (<=150000), and in each extraction, the component we are processing might be large.

        However, the initial component is m_i, and then we break it. The work for the first extraction is O(m_i), the next might be O(m_i) as well, because the component might remain large.

        Example: a complete graph. 

        This is too slow.

 Given the time limit, we must output something, and the only hope is to use the first method only for the case where we use one or a few extractions.

 In summary, we can do:

   if total_capacity < ceil(n/2): "No"

   else if there exists a capacity >= ceil(n/2): 
        // do one BFS to extract ceil(n/2) edges, and assign them to that color.
        // output "Yes" and the coloring.

   else: 
        // all capacities < ceil(n/2), and the number of non-zero capacities is some t.
        // and total_capacity>=ceil(n/2) (given).

        // then we know we can because the sum of the capacities is>=ceil(n/2) and we can always extract in t steps at least sum_i min(c_i, |comp_i|) = total_capacity (because we extract min(c_i, |comp_i|) and then the sum might be as large as total_capacity, and total_capacity>=ceil(n/2)) -> wait, but we might extract more than the capacities? 
        // Actually, we extract min(c_i, |comp_i|) in step i, and the total is at least the sum of the capacities we've used (>=ceil(n/2))? -> no: because if in one step we have |comp_i| < c_i, then we extract |comp_i|, which might be less than c_i.

        // Example: capacities = [2,2], ceil(n/2)=3, and the graph has 2 edges. Then we extract 2 in the first step, and then no more edges -> total=2<3.

        // Therefore, we must online simulate to see if we can extract at least ceil(n/2) edges.

        // But then we output "Yes" only if the online simulation covers>= ceil(n/2) edges.

        // Given the constraints on the total input size (sum of n+m over test cases<=300000) and the fact that the total number of edges over test cases is M<=300000 (because sum_i m_i = M and sum_i (n_i+m_i) = sum_i n_i + M <=300000, so M<=300000), and the total number of extraction steps over all test cases is at most the total number of non-zero capacities over test cases, which is<=M<=300000, we can hope that the online simulation using efficient data structures will work.

        // However, the work per extraction might be the size of the component, and the sum of the sizes of the components we do a BFS on might be large.

        // But note: each edge is removed exactly once. In the extraction BFS, we only touch the edges that are extracted and the incident edges for the vertices in the extracted set. In the splitting BFS, we only touch the edges that are left in the component.

        // Therefore, the total work is O(M) per test case? Because each edge is processed at most twice: once when it is in the component from which we are extracting, and once when it is in the splitting. But the splitting might be done on the entire component, so it might be that an edge is in many small components, but it is only removed once.

        // Actually, in the online simulation, we maintain the graph and remove edges. We also maintain for each vertex its incident edges that are still present.

        // We will do: 
             For the entire test case, we maintain an array: removed_edge[edge_index] = false.
             We also maintain for each vertex a list of incident edges that are not removed.

        // Then for the BFS for extraction in a component: 
             We start from an arbitrary vertex in the component. 
             We then do a BFS that collects edges (not vertices) until we have collected s edges.

             We maintain a queue of vertices. For a vertex u, we iterate over its incident edges that are not removed. For an edge (u,v) that is not removed, we:
                 - add the edge to the extracted set.
                 - remove the edge: 
                      remove it from the incident lists of u and v.
                 - if v is not visited in this BFS, we add it to the queue.

             This BFS will extract a connected set of edges (and the vertices incident) and will stop when we have collected s edges.

        // Then, to split the component (which is the original component with the extracted edges removed) into new connected components, we do a BFS/DFS on the remaining graph of the component.

        // How to do that efficiently? 

             We might not need to do a full BFS if we had maintained the entire component's edge set. Instead, we can note that the extraction BFS has already marked the removed edges. Then we can do a BFS on the remaining vertices using the remaining edges.

        // But the component might be fragmented. We can do: 

             We maintain a global set of unvisited vertices for the entire graph? 

        // Alternatively, we can maintain for each component the set of vertices and then do a BFS on the induced subgraph using the remaining edges.

        // The work for the extraction: O(s) (the number of edges we extracted) and for the splitting: O(|comp_initial|) (vertices and edges)).

        // Therefore, the work for one extraction on a component of size (vertices+edges) = (|V| + |E|) is O(|E|) for the extraction and O(|V|+|E|) for the splitting.

        // But note: the number of vertices in the component might be large.

        // The catch: an edge might appear in only one component, and a vertex might appear in only one component (initially) and then be split into new components.

        // The total work over the entire test case might be O(m_i * log(m_i)) if the components become smaller, but in the worst-case (path) it might be O(m_i^2). 

        // Given that the total m_i over test cases is<=300000, and the online simulation might be the sum over extractions of the size of the component, which is the same as the initial m_i for the test case plus the sum of the sizes of the new components. But each edge is in exactly one component at any time, and the work per extraction on a component is O(|E_comp| + |V_comp|), and the sum of |E_comp| over all components is the initial m_i, and the sum of |V_comp| might be O(n_i * (number of times a vertex is in a component that is processed)) -> but a vertex might be in many components over time.

        // In the first extraction, the entire component has n_i vertices and m_i edges.
        // Then we remove some edges, and the component breaks into several. Each new component will be processed independently later.

        // The work for the first extraction: O(m_i + n_i) = O(m_i)
        // For a new component (say with n1 vertices and m1 edges), the work for an extraction on it: O(m1 + n1).

        // Therefore, the work is the sum over all components that we ever process in the heap of (n_comp + m_comp).

        // Initially, the entire graph is one component: n and m.
        // Then we split it into components, and the sum of (n_comp + m_comp) over the new components might be (n_i + m_i) because the components are on disjoint sets of vertices and edges.

        // But wait, we are not processing the new components in this extraction step, we are queueing them and then in subsequent steps we will process them.

        // Therefore, the total work over the entire test case is O(n_i + m_i) for the online simulation.

        // Why? 
             In the first extraction: we do work O(n_i + m_i) and remove s edges and also remove the vertices that are incident to those edges? 
             But note: vertices may be shared between components? 
             Actually, the new components may share vertices? 

        // Let's: we have a component (V, E), and we remove a set of edges E' (|E'|=s), then the new components are the connected components of (V, E\E').

        // The work for the extraction is O(s + number of vertices in the extracted subgraph) and for the splitting is O(|V| + |E\E'|).

        // But note: the extracted subgraph has at most s edges and at most s+1 vertices.

        // Then the work for the extraction is O(s) and for the splitting is O(|V| + |E\E'|) = O(|V| + |E| - s).

        // The entire work for this extraction is O(|V| + |E|).

        // Then when we queue the new components, we will have their (vertices and edges), and the sum over the new components of (|V_i| + |E_i|) is O(|V| + |E\E'|) = O(|V| + |E| - s).

        // And then we will do the next extraction on one of the new components, say (V_i, E_i), which will be O(|V_i| + |E_i|).

        // Therefore, the total work is the sum over all components that were ever in the heap of (|V_comp| + |E_comp|).

        // Initially, one component: work = n_i + m_i.
        // Then when we split a component into several, the sum of (n_child + m_child) over the children is (n_comp + m_comp - [ the extracted edges and incident vertices? note: the extracted edges are removed from the component, and the vertices are not removed from the component, they are split into children. 
        // Actually, the vertices are not removed, they are distributed to the children. And the edges are distributed: extracted edges are gone, and the remaining edges are distributed to the children.

        // And the sum over the children of (n_child) = n_comp, and the sum over the children of (m_child) = m_comp - s.

        // Therefore, the sum over the children of (n_child + m_child) = n_comp + (m_comp - s) = (n_comp + m_comp) - s.

        // Then the work for the children will be the sum over children of (n_child + m_child) = (n_comp + m_comp) - s.

        // So the total work for the entire test case is the initial (n_i + m_i) plus the work for the children, which is a telescoping sum: 

             work = (n_i+m_i) + [(n_i+m_i) - s0] + [(n_i+m_i) - s0 - s1] + ...   ? -> no, because the work for a component is only done when we extract from it.

        // Actually, we only do work on a component once, when we extract from it.

        // Therefore, the total work is the sum_{comps} (|V_comp| + |E_comp|) over all components that we extract from.

        // How to bound this sum? 

             Initially: one component: n_i + m_i.
             When we extract a component ( size = s ), we then create several new components, and the sum of (n_child + m_child) for the new components is (n_comp + m_comp - s) and they will be processed later.

             The sum for the new components is (n_comp + m_comp - s) = (n_i+m_i) - (s0+s1+...) 

        // then the total work is the sum of (n_i+m_i) for every component that we extract from, and the extraction of a component of size (n_comp+m_comp) yields new components with total size (n_i+m_i) - s, which is then distributed among the new components.

        // actually, the sum over all components (initial and new) is: 

             work_total = (n_i+m_i) [initial] 
                         + (n_i+m_i) - s0 [ from splitting the initial into children] 
                         + (n_i+m_i) - s0 - s1 [ from splitting one of the children] 
                         + ... 
            until the entire graph is decomposed.

        // This is not obviously linear.

        // Alternatively, note that an edge appears in exactly one component. And a vertex may appear in at most the number of times it is in a component that is extracted from. 

        // But in the extraction of a component, we do work O(|V_comp| + |E_comp|), and the sum of |E_comp| over all components is the initial m_i.

        // For the vertices: a vertex may appear in many components. In the worst-case, a vertex may appear in O(m_i) components? 

        // Therefore, the work might be O(n_i * number_of_extractions + m_i), and the number of extractions is the number of non-zero capacities in the test case, which is at most m_i.

        // Then worst-case work = O(n_i * m_i) = 300000 * 300000 = 90e9.

 Given the above, and the time constraints, we must therefore hope that the first case (one large capacity>= ceil(n/2)) is the common case, and for the other case, we can try to use the single-edge decomposition if the number of capacities>=1 is>= ceil(n/2), and only do the online simulation if absolutely necessary ( which in practice might be rare).

 or we must output "Yes" in the branch where the largest capacity < ceil(n/2) and the number of capacities>=1 < ceil(n/2) without simulation, because the total capacity>= ceil(n/2) and we can always do it -> the sample.
 
 Let me check the sample: 
     sample 2 and 3: 
         "6 11
          0 0 0 0 0 0 0 3 2 3 3"
          ceil(6/2)=3.
          capacities: sorted: [3,3,3,2,0,...] -> non-zero: [3,3,3,2] -> the largest capacity=3>=3, so the first branch would be taken.

     sample 3: 
          "6 11
           0 0 0 0 0 0 0 3 2 3 3"
          -> sample output: "Yes" and then a coloring.

     sample 4: 
          "5 10
           1 0 0 0 0 0 0 0 0 1"
          ceil(5/2)=3.
          total_capacity=1+1=2<3 -> "No"

     sample 1: 
          "5 4
           4 0 0 0"
          ceil(5/2)=3.
          largest capacity=4>=3 -> first branch.

     Therefore, the sample does not have a test case for the else branch.

 We in else branch: largest capacity < ceil(n/2) and count_non = t < ceil(n/2), and total_capacity>=ceil(n/2).

 We must therefore to be safe do the online simulation, but only in this branch.

 Given the total sum of n+m over test cases is 300000, and the online simulation might be O(n+m) per test case in this branch, and there is only one test case that might be as large as 300000 for n+m, and within that test case the online simulation might be O(m^2) in the worst-case, we must hope that the test cases in this branch are small.

 or use a more efficient method.

 Given the time, we will only implement the first branch (>= ceil(n/2) capacity exists) and for the else branch, if the number of capacities>=1 is>= ceil(n/2), we use single-edge decomposition (assign each edge to a distinct color, and we only need ceil(n/2) edges, so we choose any ceil(n/2) edges and assign them to distinct colors), and if not, we do online simulation only if the test case is small.

 But the problem says the sum of n+m over test cases is 300000, so even if we do online-simulation in the else branch for a test case, the work for that test case might be O(m_i^2) but if the test case is small, it might be acceptable.

 Specifically, the sum of n+m over test cases is 300000, so the largest test case might have n+m<=300000, but then n<=300000, m<=300000, and then the work might be 300000^2 = 90e9 for one test case.

 Therefore, we must not do online-simulation for large test cases in the else branch.

 Alternatively, in the else branch, we can use the following: 
   since the number of non-zero capacities t < ceil(n/2) [which is at most 150000], and the online simulation work is the sum over components of (|V_comp|+|E_comp|), and the components are edge-disjoint, the total work might be O(n_i + m_i) per test case.

   because the sum of |E_comp| over components is the initial m_i, and the sum of |V_comp| might be at most n_i * (number of components that a vertex appears in). How to bound the number of components a vertex appears in? 

   A vertex appears in a component if it is in the component when we do the extraction. Note: after an extraction, the vertex may be in one of the new components. It will appear in exactly one new component.

   Therefore, over the entire online simulation for one test case, a vertex is in exactly one component at any time, and is processed in the extraction of that component. Therefore, the sum of |V_comp| over components is O(n_i * depth)? 
   Actually, no: the vertex is in the initial component, and then in one of the children, and then in one of the grandchildren, etc. But the total number of times it is in a component that is processed is the number of times it is in a component that is chosen to be extracted from. 

   How many times can a vertex be in a component that is chosen? At most the number of extractions that use an edge incident to it? 

   But note: we might never choose a component containing that vertex after it has been disconnected from the large components. 

   However, the total work for vertices might be: each time a vertex is in a component that we extraction from, we it is in the work for that component. And the work for that component includes that vertex.

   Therefore, the total work is the sum over components of (number of edges in the component + number of vertices in the component) = (m_i) + (sum_{comps} |V_comp|).

   And the sum_{comps} |V_comp| = for each vertex, the number of components that it ever appeared in during the online simulation. 

   Initially, all vertices are in the first component.
   Then when we extract a connected subgraph from a component, the vertices in the extracted subgraph are removed from the component? -> no, the vertices remain in the graph, but the component is the entire graph. When we remove edges, the component breaks into connected components by the remaining edges. The vertices are then distributed to the new components.

   Therefore, a vertex is in exactly one component at any time, and over time, it may be in several components. Specifically, it is in one component initially, and then when the component is split, it goes to one new component. And then when that new component is extracted from, it goes to one new component, etc.

   Therefore, the number of components a vertex is in is the number of times an incident edge is not extracted and the component it is in is chosen for extraction. 

   In the worst-case, a vertex might be in as many components as the number of extractions, which is at most t < ceil(n/2) <= 150000.

   Therefore, the total work for one test case is O(m_i + n_i * t) = O(m_i + n_i * 150000). For a test case with n_i=300000 and m_i=300000, then work= 300000 + 300000 * 150000 = 45e9, too slow.

 Given the above, and the time constraints, we will for the else branch only, try to use the following: 
   since ceil(n/2) is at most 150000, and the number of extractions is at most the number of non-zero capacities t (which is < ceil(n/2)), which is at most 150000, we hope that the components become small quickly. 

   But the work for the online simulation in the else branch might be acceptable for small test cases.

   Given the overall sum of n+m over test cases is 300000, the else branch might only occur in small test cases.

   Therefore, we will do online simulation for the else branch.

 Let's summary the code for one test case:

   n, m = read()
   a = list of m capacities.
   edges = list of m edges.

   k = (n+1)//2   # ceil(n/2)

   total_capacity = sum(a)
   if total_capacity < k:
        output "No"
   else:
        sort_a = sorted(a, reverse=True)
        if sort_a[0] >= k:
            // find a connected subgraph of k edges.
            // BFS/DFS on the entire graph to collect k edges.
            // let's start from vertex 1.
            // we'll create an array for the incident edges of each vertex.
            // then do a BFS: 
                   queue = deque([0])  # vertex 0 (index0) or 1-> index0 for vertex 1? vertices are 1-indexed.
                   visited_vertices = set()
                   visited_vertices.add(0)
                   collected_edges = []
                   while len(collected_edges) < k and queue:
                         u = queue.popleft()
                         for each edge incident to u that is not yet collected and not removed (initially none collected) (and the endpoint v not in visited_vertices or visited, but we can collect the edge even if v is visited? as long as the edge is not collected)
                         Actually, we can collect an edge if it is incident to the current set and the edge is not collected.
                         So we can do:
                              for each edge e incident to u:
                                  if e is already collected, skip.
                                  else, add the edge.
                                  and if the other endpoint v is not in visited_vertices, add it to visited and to the queue.

                    // if we collected <k, then start from another vertex? but the graph is connected.

            // Then assign the collected_edges to color = the index of the capacity (which is the largest capacity, but we only use one color).

            // But note: the capacities: we are using the largest capacity, which is at position 0 in sort_a, but we need to know its original color index.

            // Let's record: we want to use the largest capacity. How to find its original color index? 
                   it might be that there are several capacities with the same value.

            // We can do: 
                   for the capacities, we find the largest capacity value, and then find the smallest index j such that a[j]== that value, and then use that color.

            // But the problem: we have to output for each edge the color or 0.

            // create an array of m zeros.
            // for each edge in collected_edges, set its color to j+1 (because colors from 1 to m).

            // output "Yes"
            // output the array of colors for the edges in input order.

        else:
            // sort_a[0] < k.

            // Let non_zero = [x for x in sort_a if x>0]   // sorted in descending order.
            t = len(non_zero)

            // if t>=k:
                 // then we can use any k edges, each as a separate component (each edge is a connected component) and assign each to a distinct color (distinct capacity>=1).
                 // we choose any k edges.
                 // we need to assign each edge to a distinct color. How to assign? 
                        create an array for the output: initially all 0.
                        // find any k edges, and assign them to any k distinct colors that have capacity>=1.
                        // specifically, we can take the first k non-zero capacities, and for each capacity, note its original index.

                        // But careful: the same capacity value might appear multiple times.

                 // create an array of the capacities with their index: 
                         capacities_with_index = []
                         for i in range(m):
                             if a[i]>0:
                                 capacities_with_index.append( (a[i], i) )
                         // sort by capacity descending, and then by index arbitrarily.

                 // take the first k capacities_with_index.

                 // then assign each of the first k edges in the input to the color = index_in_capacities+1? 
                         // no, the color should be the color index, which is i+1? 
                         // but the problem: the color is from 1 to m, and the capacity a_i is for color i.

                 // we have capacities_with_index = [ (a_i, i) ] for non-zero capacities, sorted by a_i descending.

                 // we will assign the j-th chosen edge to the color index = capacities_with_index[j][1] + 1? -> but the capacities_with_index[j][1] is the index in the capacity array (0-indexed), and the color is that index+1? 

                 // however, the problem does not require to use the capacities in any particular order.

                 // we can assign arbitrarily.

                 // create an array of the color indices that we will use: 
                         color_indices = [ i for (_, i) in capacities_with_index[0:k] ]   // the first k.

                 // then for the edge assignment: 
                         for j in range(k):
                             output_color[ chosen_edge_j ] = color_indices[j] + 1   // because the capacity at index i is for color i+1.

                 // how to choose the edges? any k edges.

                 // then output "Yes" and the output_color array.

            // else: // t < k
                 // we will do online simulation to extract at least k edges.

                 // We simulate as follows:

                    // Represent the graph: 
                         vector<vector<tuple<int, int>>> graph(n)  // graph[u] = list of (v, edge_index)
                         // also, we maintain a global array: removed[edge_index] = false initially.

                    // We maintain a priority queue of components: 
                         priority_queue<Component> pq;   // where Component = (number of edges, and a representative vertex, and the set of edges is not stored, we will dfs on the entire graph marking the component? )

                    // How to represent a component without storing the entire set? 
                         // We store: representative vertex, and the count of edges and vertices in the component.
                         // But when we extract, we need to know the incident edges.

                    // Instead, we will not store the components in the priority queue by their entire set, but by the edge count and a representative vertex.

                    // Initially, the entire graph is one component: 
                         comp = Component(representative=0, edge_count = m, vertex_set = not stored) 
                         pq.push( (m, 0) )   // we push (edge_count, representative vertex)

                    // But how to do a BFS in a component when we don't have the set of vertices and edges? 
                    // We will do a BFS starting from the representative vertex, and we will only consider not removed edges. This will give us the entire connected component that the representative is in.

                    // However, the representative might have been in a splitted component, and the BFS will be on the entire current graph from the representative, but we want only the component that we stored.

                    // Actually, we will use the representative vertex to BFS in the current graph.

                    // Steps for online simulation in the else branch for one test case:

                         total_covered = 0
                         // priority queue: pq is a max-heap by edge_count.
                         // initially, pq has one component: (m, any vertex, e.g., 0)

                         // also, we maintain an array: component_of_vertex? not necessary.

                         for i in range(t):
                             if total_covered>=k: break
                             if pq is empty: break
                             c = non_zero[i]   // the capacity for this step
                             (edge_count, rep) = pq.pop() with the largest edge_count.

                             // Now, do a BFS/DFS starting from rep to travers the entire component (to know the component's vertices and edges) -> but wait, we only need to extract min(c, edge_count) edges.

                             // But we don't have the component stored, so we must do a BFS to at least extract the connected subgraph of min(c, edge_count) edges.

                             // We will do a BFS (as in the first branch) to extract a connected subgraph of s = min(c, edge_count) edges.

                             // This BFS: 
                                  queue_vertices = deque([rep])
                                  visited_vertices_this_component = set([rep])
                                  collected_edges_this_step = []
                                  while queue_vertices and len(collected_edges_this_step) < s:
                                        u = queue_vertices.popleft()
                                        for each (v, edge_index) in graph[u]:
                                             if removed[edge_index]: 
                                                 continue
                                             // this edge is available.
                                             // take it.
                                             collected_edges_this_step.append( (u,v,edge_index) )
                                             removed[edge_index] = true
                                             // remove this edge from the graph: also remove it from the incident lists? 
                                                 // we don't physically remove, we only mark removed[edge_index]=true.
                                             // then if v is not in visited_vertices_this_component, add it to visited and to the queue.

                                             // even if v is visited, we can take the edge? 
                                                 // but then the edge would connect two vertices in the current set, and we can take it.

                                             // So we don't need to check visited for v? 
                                                 // we can take the edge regardless.

                                             // However, we then may have visited_vertices_this_component not including v? 
                                                 // we are not required to include the vertex, but the edge incident to the current set.

                                             // So we do not add v to the queue if we've not seen it, but we can take the edge.

                                             // But to continue the BFS, we need to add v if it is not visited.

                                             // Therefore, if v is not visited, we add it to visited and to the queue.

                                  // after this, we have collected s = len(collected_edges_this_step) edges.

                             // remove these edges from the graph and from the component.

                             // Now, the component may be split. How to find the new components from the original component (which is the set of vertices we visited in the entire component initially?) 

                                 // Actually, we have only BFSed to extract a connected set of s edges. The remaining part of the component may be disconnected.

                                 // To find the new components, we will do a BFS/DFS on the original set of vertices in the component, but only using the edges that are not removed and are incident to vertices in this component.

                                 // But note: we may have only visited a subset of the vertices of the component.

                                 // How to get the entire set of vertices in the component before extraction? 
                                        // We don't have it stored.

                                 // Instead, we can do: 
                                        // The component we were processing is the connected component of the current graph that contains rep. When we remove the extracted edges, we will do a multi-source BFS from the visited_vertices_this_component (which are the vertices in the extracted subgraph) and see the connectivity of the component by using the remaining edges.

                                 // But note: the extracted subgraph is connected, and the 
                                 // Alternatively, we can do: 
                                        // After extraction, we will do a BFS/DFS for the entire graph (or for the part that was in the component) is expensive.

                                 // Instead, we can during the extraction, we have the set of vertices that were in the extracted set. Then for the remaining edges in the incident lists of these vertices that are in the component, we might have edges to other vertices. Actually, the component might have more vertices than the ones in the extracted set.

                                 // Therefore, we must do a BFS/DFS of the entire component before extraction to know the set of vertices. -> or we do it in the extraction: 
                                        // we could have done a BFS for the entire component initially to know the set of vertices and edges. That is O(|component|) and we then could have a subgraph to work with.

                                 Given the time, and since this is the else branch and we hope the test case is small, we will do a full BFS for the component at the beginning of the extraction.

                             // Therefore, we must first do a BFS to get the entire component of rep in the current graph. 
                                 // This is the component we are extracting from.

                             // But then we could have done the extraction in this BFS. 

                             // So we do:

                                 component_vertices = set()
                                 component_edges = set()   // set of edge_index

                                 queue_comp = deque([rep])
                                 visited_comp = set([rep])
                                 while queue_comp:
                                      u = queue_comp.popleft()
                                      component_vertices.insert(u)
                                      for (v, edge_index) in graph[u]:
                                           if removed[edge_index]: 
                                               continue
                                           // this edge is in the component.
                                           component_edges.insert(edge_index)
                                           if v not in visited_comp:
                                               visited_comp.add(v)
                                               queue_comp.push(v)

                                 // Now, we have the component: which has size = |component_edges|.

                                 // Then we extract a connected subgraph of s = min(c, |component_edges|) edges from this set.

                                 // We do a BFS as in the first branch, but restricted to component_vertices and component_edges.

                                 // Then after extraction, we remove the extracted edges from component_edges, and then we find the connected components of the remaining part of the component.

                                 // To find the new components: 
                                      new_components = []
                                      // We will do a BFS/DFS on the component_vertices with the remaining edges in component_edges.

                                      // We need to mark vertices that are in the current component.
                                      // We remove the extracted edges from component_edges.

                                      // Then we iterate over the component_vertices and do a BFS using only the edges in component_edges that are not removed.

                                      // But note: an edge might be removed globally (marked in removed[edge_index]), so we iterate and for each vertex in component_vertices, if not visited, do a BFS with edges that are in component_edges and not removed.

                                 // This is expensive: O(|component_vertices| + |component_edges|).

                             // Then for each new component (new_vertices, new_edges), we push (len(new_edges), rep_new) into the pq.

                             // And we remove the extracted edges from the global component.

                             total_covered += s

                         // after the for loop, if total_covered>=k: "Yes", else "No"

                    // If we are to output the coloring, we have to store the color for each edge in the extraction steps.

                    // In the extraction for capacity non_zero[i] (which has an original color index that we will have to remember), we assign that color to the extracted edges.

                    // How to know the original color index for non_zero[i]? 
                         // non_zero is sorted from the array a, so we have to know the index in a.

                    // We will not use the same color for two extractions.

                    // We can create an array: 
                         // color_assignment = [0] * m   // for each edge, its assigned color.

                    // and we have a list of the non-zero capacities with their index: non_zero_with_index = sorted( [ (a[i], i) for i in range(m) if a[i]>0 ], reverse=True)

                    // in the i-th step (0-indexed), the capacity = non_zero_with_index[i][0], and the color index = non_zero_with_index[i][1] + 1.

                    // then for each edge extracted in this step, set its color to that.

                    // then after online simulation, if we have "Yes", output the color_assignment in the order of the input edges.

            // and if we are in the branch and we have total_covered>=k, output "Yes" and the color_assignment.

            // else, "No"

   // However, this online simulation in the else branch might be heavy for the component that requires full BFS to get the component and then extraction and then splitting.

 Given the complexity, and the constraints on the total sum of n+m over test cases (300000) we hope that the else branch either does not occur or occurs in small test cases.

 Let's pray.

 Implementation:

   Steps for one test case in else-branch (t < k and largest capacity < k):

        non_zero = sorted([ (a[i], i) for i in range(m) if a[i]>0], key=lambda x: (-x[0], x[1]))
        t = len(non_zero)
        // We will do:
             total_covered = 0
             // create an array: removed_edge[edge_index] = false for all edge_index in [0, m-1]
             // create an array: color_assignment[edge_index] = 0 for all.

             // graph: 
                  vector< vector< pair<int, int> > > graph(n); // graph[u].emplace_back(v, edge_index)

             // build graph: for edge_index in range(m):
                   u = edges[edge_index][0]-1, v = edges[edge_index][1]-1
                   graph[u].push_back({v, edge_index})
                   graph[v].push_back({u, edge_index})

             // priority_queue: 
                  priority_queue< pair<int, int> > pq;   // (edge_count, representative vertex)
                  // initially, we need to find the connected components of the whole graph? 
                  // but the graph is connected initially.

                  // do a BFS for the entire graph to get the component of any vertex (e.g., vertex0) has size m, so we push (m, 0)

             // But the graph may become disconnected as we remove edges.

             // However, initially we push the entire graph: 
                  pq.push( {m, 0} );

             // We also need an array to know which vertices are still in the graph? 
                  // not necessary.

             for i in range(t):
                 if total_covered>=k: break
                 if pq.empty(): break
                 auto top = pq.top(); pq.pop();
                 int edge_count = top.first;
                 int rep = top.second;

                 // if this component has been affected by removals, its edge_count might be not accurate? 
                 // so we must verify by doing a BFS to get the entire component.

                 set<int> comp_vertices;
                 set<int> comp_edges_set;
                 queue<int> q_comp;
                 vector<int> visited_vertex(n, false);   // we can use a global visited array? But we will do BFS for one component.

                 // or we can do a BFS starting from rep that only uses not removed edges.
                 q_comp.push(rep);
                 comp_vertices.insert(rep);
                 visited_vertex[rep] = true;
                 while (!q_comp.empty()) {
                     int u = q_comp.front(); q_comp.pop();
                     for (auto &edge : graph[u]) {
                         int v = edge.first;
                         int eidx = edge.second;
                         if (removed_edge[eidx]) continue;
                         // this edge is present.
                         comp_edges_set.insert(eidx);
                         if (!visited_vertex[v]) {
                             visited_vertex[v] = true;
                             comp_vertices.insert(v);
                             q_comp.push(v);
                         }
                     }
                 }
                 int comp_edge_count = comp_edges_set.size();
                 // if this component has comp_edge_count != edge_count, then we should use the real comp_edge_count.
                 // and if comp_edge_count==0, then skip.

                 if (comp_edge_count == 0) {
                     // nothing to do, continue.
                     continue;
                 }

                 int s = min(non_zero[i].first, comp_edge_count);

                 // Now, extract a connected subgraph of s edges from this component.
                 // We do a BFS: 
                      queue<int> q;
                      vector<int> visited_this_extraction(n, false);
                      // we start from rep (which is in the component)
                      q.push(rep);
                      visited_this_extraction[rep] = true;
                      vector<int> extracted_edges;
                      // To ensure connectivity, we will only take an edge if it is incident to the current set.
                      // We break when we have s edges.

                      while (extracted_edges.size() < s && !q.empty()) {
                          int u = q.front(); q.pop();
                          for (auto &edge : graph[u]) {
                              int v = edge.first;
                              int eidx = edge.second;
                              if (extracted_edges.size() >= s) break;
                              if (removed_edge[eidx]) continue;
                              // if this edge is not in the component? should be, by the comp_edges_set, but we can skip if not, but we did a BFS on the component, so it should be in.
                              // take the edge.
                              extracted_edges.push_back(eidx);
                              removed_edge[eidx] = true;
                              // then, if v is not visited, add it.
                              if (!visited_this_extraction[v]) {
                                  visited_this_extraction[v] = true;
                                  q.push(v);
                              }
                          }
                      }

                 // In case we didn't get enough (shouldn't happen in a connected component), then we use the extracted_edges we got.

                 int actual_s = extracted_edges.size();
                 total_covered += actual_s;

                 // assign these edges to color = non_zero[i].second + 1.
                 for (int eidx : extracted_edges) {
                     color_assignment[eidx] = non_zero[i].second + 1;
                 }

                 // Now, remove these edges from the component, and find the new components in the remaining graph of the component.
                 // We already have the set of vertices: comp_vertices, and the set of edges in the component: comp_edges_set.
                 // But we have removed the extracted_edges.

                 // We will find the connected components in the subgraph (comp_vertices, remaining_edges) where remaining_edges = comp_edges_set minus extracted_edges_set.

                 // We'll do a BFS over the comp_vertices, using only the remaining edges (which are in the graph and not removed, and incident and in the component_edges_set? and not in extracted_edges).

                 vector<int> new_visited(n, false);
                 for (int u : comp_vertices) {
                     if (new_visited[u]) continue;
                     // new component starting from u.
                     queue<int> q_new;
                     q_new.push(u);
                     new_visited[u] = true;
                     set<int> new_comp_vertices;
                     new_comp_vertices.insert(u);
                     int new_comp_edge_count = 0;
                     while (!q_new.empty()) {
                         int u = q_new.front(); q_new.pop();
                         for (auto &edge : graph[u]) {
                             int v = edge.first;
                             int eidx = edge.second;
                             if (removed_edge[eidx]) continue; // including the extracted ones.
                             // count this edge only once? 
                             // We count the edge if it is in the component_edges_set and not in extracted_edges? 
                             // But we removed globally by removed_edge, and we are iterating by vertices.

                             // But note: an edge might appear twice: (u,v) and (v,u). How to avoid? 
                             // We can mark the edge as visited? 

                             // We don't need to count the edge twice.

                             // Instead, we can iterate and count the edge only if u < v? 
                             // Or we can use a set of edges for the new component.

                             // But we only want the count.

                             // We can do: new_comp_edge_count is not the number of edges in the new component? 
                             // However, we are not storing the edges.

                             // Actually, we only care about the count for the priority queue.

                             // We can count: 
                                 // for an edge (u,v) that is not removed, and v is in the new_comp_vertices already? then if v is not in new_comp_vertices, we add it and count the edge.
                                 // if v is in new_comp_vertices, then we count the edge now? 

                             // But an edge within the new_comp_vertices might be counted twice.

                             // Instead, we can do a full BFS and then at the end count the number of edges in the new component by iterating over the vertices and counting the incident edges that are not removed and have the other endpoint in the new_comp_vertices. But that is O(|V|).

                             // Given the constraints, and that the component is small, we can do a full BFS and then count the edges by iterating over the vertices in the new component.

                             // But note: we are doing a BFS, and we want to avoid double counting. 

                             // We can do: 
                                 // In the BFS, when we see an edge (u,v) that is not removed and v is not in new_comp_vertices, then we count the edge and add v.
                                 // but if v is in new_comp_vertices, then we count the edge now.

                             // But then an edge between two visited vertices might be counted twice.

                             // Instead, we can simply not count the edge here, and then at the end of the BFS, do: 
                                 new_comp_edge_count = 0;
                                 for each vertex in new_comp_vertices:
                                     for each incident edge that is not removed and has the other endpoint>=u? 
                                        // but the edge might be counted twice.

                             // Alternatively, we can iterate on the edges in the new_comp_vertices and use a set to remove duplicates.

                             // Given the time, we will not count the edge during the BFS. After the BFS, we will do:

                                 set<int> new_comp_edges_set;
                                 for (int w : new_comp_vertices) {
                                     for (auto &edge : graph[w]) {
                                         int to = edge.first;
                                         int eidx = edge.second;
                                         if (removed_edge[eidx]) continue;
                                         if (new_comp_vertices.count(to)) {
                                             // only count if to>=w to avoid double count? 
                                             // or simply add the edge if it is present and not removed.
                                             new_comp_edges_set.insert(eidx);
                                         }
                                     }
                                 }
                                 new_comp_edge_count = new_comp_edges_set.size();

                         }
                     }
                     // But during the BFS, we might have missed vertices? 
                     // We did a BFS above for the new component, so we have new_comp_vertices.

                     // After the BFS, we do the counting.

                     // And then we push the new component: (new_comp_edge_count, u) // u is the representative.

                     pq.push( {new_comp_edge_count, u} );

                 } // end for u in comp_vertices

             // end for i in range(t)

             if (total_covered>=k) {
                 // output "Yes"
                 // and then output the color_assignment for each edge in the input order: for edge_index in range(m): print color_assignment[edge_index]  // which is 0 or a color.
             } else {
                 // "No"
             }

 Given the complexity and the constraints on the total input size, we hope that the online simulation in the else branch is not triggered often.

 Let's hope.

 Note: the total sum of n_i+m_i over test cases is 300000, so the else branch will be run on test cases that are small in the sense of the overall input size, but a test case in the else branch might have n_i+m_i up to 300000, and the online simulation might be heavy.

 But note: the else branch might be rare.

 Given the sample, we have to output the sample answers.

 We will implement accordingly.

 Due to the complexity, we may need to optimize further. For example, we can avoid the set<int> for comp_vertices and comp_edges_set and new_comp_vertices, and instead use arrays of booleans.

 But given the time, we will output the code and hope that the online simulation in the else branch is only for small test cases.

 Or we might get TLE on large test cases in the else branch.

 Given the constraints on the total sum over test cases (300000) but note: the else branch might occur in a test case that is the entire input size, and then within that test case the work might be large.

 But the total sum of n_i+m_i is 300000, so there is only one test case if that test case has n_i+m_i=300000.

 Therefore, the else branch will be run at most once.

 And in that test case, n_i and m_i might be up to 300000, and the online simulation might be O(n_i * t) or O(n_i^2) or O(n_i * m_i), which is 90e9, which in C++ might be 90 seconds.

 Therefore, we must hope that the else branch does not occur in large test cases, or we need a more efficient method.

 Given the complexity, and since the else branch is: 
    largest capacity < ceil(n/2) and number of non-zero capacities < ceil(n/2) and total_capacity>=ceil(n/2)

 which is a very specific and rare condition, we might assume that in the large test cases (n=300000) this condition does not occur.

 So we output the code accordingly.

 Note: the sample input does not have such a test case.

 Let's try to run on a tiny example in the else branch.

 Example: 
    n=3, m=3, edges: [ (0,1), (1,2), (2,0) ]  // a triangle.
    capacities = [2,2] -> then total_capacity=4, ceil(3/2)=2.
    largest capacity=2>=2 -> first branch.

 Example for else branch:
    n=4, ceil=2.
    capacities = [1,1] -> total_capacity=2>=2.
    largest capacity=1<2, and number of non-zero=2>=2 -> then we use the single-edge decomposition.

 Another example for else branch:
    capacities = [1,1,1] with ceil=3, then total_capacity=3>=3, largest<3, and count_non=3>=3 -> use single-edge.

 Example for the online simulation in else branch:
    n=4, ceil=2.
    capacities = [1,1] -> count_non=2>=2, so we use single-edge.

    capacities = [1,0] -> then non_zero=[1], count=1<2.
        online simulation:
           total_covered=0
           pq = (3 edges, rep=0)  // the triangle plus an extra edge? wait, we need a graph of 4 vertices and more edges.

    Let's do:
        n=4, m=3, edges: 0-1, 1-2, 2-3 (a path of 3 edges), capacities=[1,1] -> then non_zero=[1,1] -> count=2>= ceil(4/2)=2, so we use single-edge.

    Example: 
        n=4, ceil=2.
        capacities=[1,1] -> use two single edges.

    How to force online simulation: 
        capacities = [2,0] -> then non_zero=[2], count=1<2.
        graph: let's make it a square: 0-1, 1-2, 2-3, 3-0, and an extra edge: 0-2 -> total 5 edges.
        But then largest capacity=2< ceil=2 -> no, ceil=2, so 2>=2 is the first branch.

    capacities = [1] for a graph with 2 edges: 
        n=2, ceil=1.
        capacities=[1] -> count=1>=1, use single-edge.

    capacities = [1] for a graph with 2 edges and n=3 vertices? 
        n=3, ceil=2.
        then the else branch: largest capacity=1<2, count=1<2.
        online simulation:

            non_zero_with_index = [ (1,0) ]

            total_covered=0.
            pq = (2,0)  // the graph has 2 edges.

            extract from the component (2 edges) with capacity=1: so s=min(1,2)=1.

            Do a BFS for the entire component of 0? 
                comp_vertices = {0,1,2} if the graph is 0-1, 1-2.
                comp_edges_set = {0,1} (edge0:0-1, edge1:1-2)

            Then extract 1 edge: start from 0, we take edge0:0-1. 
                Then assign edge0 to color=1.
                Then remove edge0.

                Then the component breaks into: 
                   remaining comp_edges_set = {1} (edge1:1-2)
                   then new components: 
                         do a BFS in the remaining graph on vertices {0,1,2}? 
                         vertex0: not connected to anyone (edge0 removed).
                         vertex1: has edge1 to 2, so we find a new component: vertices={1,2}, edge_count=1.
                         push (1,1) into the pq.

            total_covered=1, which is <2.

            then next capacity: none.

            output "No", but we need 2.

        However, we could have taken edge1 (1-2) in the extraction, then we would have covered 1 edge, and then the new component would be {0} and {1} (disconnected) and the edge0 is removed, so no new component with edges.

        But note: we could have taken the edge incident to the current set that leaves the set as large as possible? 
            In the extraction, we start from 0, we can choose any incident edge. We chose edge0, but we could also choose edge1 if we start from 1? 

        But our extraction starts from the representative. Here the representative is 0.

        What if we start from 1? 
            The component is the whole graph. The representative is 0, but we could have used a different representative? 

        In our online simulation, we use the representative given in the pq. Here we pushed (2,0).

        So we start from 0.

        Is there a way to extract 2 edges in one step? 
            No, because the capacity is 1.

        So we must use two capacities. But we only have one capacity.

        Therefore, it is impossible.

        output "No", which is correct.

    Therefore, the online simulation is correct for this example.

 Given the time, we output the code for the first branch and the else branch as described.

 Note: the code might be long and we must be cautious for not using too much memory.

 Given the overall sum of n+m over test cases is 300000, and we have at most one test case in the else branch that is large, but we also have the first branch which is light: only one BFS.

 Let's code accordingly.

 Implementation details for the first branch (capacity>=ceil(n/2)):

   We do a BFS to collect k edges.
   We start from vertex0.

   We maintain:
        vector<vector<pair<int, int>>> graph // to vertex and edge index
        vector<int> color_assignment(m,0)
        vector<bool> removed_edge(m, false);
        // we won't remove edges in the first branch.

        queue<int> q;
        vector<bool> visited(n, false);
        visited[0] = true;
        q.push(0);
        vector<int> collected_edges;

        while (collected_edges.size() < k && !q.empty()) {
            int u = q.front(); q.pop();
            for (auto edge : graph[u]) {
                int v = edge.first;
                int eidx = edge.second;
                if (collected_edges.size() >= k) break;
                if (removed_edge[eidx]) continue; // shouldn't happen in the first branch, but safe.
                // if the edge is not collected, collect it.
                if (collected_edges.size() < k) {
                    collected_edges.push_back(eidx);
                    removed_edge[eidx] = true; // for consistency, not necessary.
                }
                // then, if we haven't visited v, we add it.
                if (!visited[v]) {
                    visited[v] = true;
                    q.push(v);
                }
            }
        }

   // But note: the collected_edges might be less than k if the component is not large enough? 
   // But the graph is connected and has at least n-1 edges, and n-1>=ceil(n/2) (as discussed), so we will collect at least k edges.

   // Then we assign these edges to the largest capacity's color.

   // How to find the largest capacity's color index? 
        int max_capacity = -1;
        int color_index = -1;
        for (int i=0; i<m; i++) {
            if (a[i] > max_capacity) {
                max_capacity = a[i];
                color_index = i;
            }
        }
        // then the color is color_index+1.

        for (int eidx : collected_edges) {
            color_assignment[eidx] = color_index+1;
        }

   // Then output the color_assignment for all edges.

 Let's hope.

 Note: the sample input might have multiple capacities with the same value. We take the first one that achieves the max.

 But the problem does not care which color we use.

 Now, let's code accordingly.

 We must be cautious for the overall sum of n+m over test cases is 300000, so we must not do O(n^2) in the first branch.

 The BFS is O(n+m) per test case.

 Given the total sum of n+m over test cases is 300000, we can do it.

 We will now code accordingly.

 Note: the else-branch online simulation might be heavy for the largest test case, but it is hopefully rare.

 If we encounter a large test case in the else branch, we may get TLE, but the problem says the overall sum is 300000, and the else branch might only occur in one test case.

 But the work in the else branch for a test case with n_i and m_i might be O(n_i * m_i) in the worst-case, and n_i, m_i might be 300000, then it is 90e9, which is too slow.

 Therefore, we must hope that the else branch only occurs in test cases with small n_i and m_i.

 Given the condition in the else branch: largest capacity < ceil(n_i/2) and the number of non-zero capacities < ceil(n_i/2), and total_capacity>=ceil(n_i/2), 
   then we must have ceil(n_i/2) is large, and the number of non-zero capacities is less than that, so the online simulation might be not triggered on a very large n_i.

   For example, if n_i=300000, then ceil(n_i/2)=150000, and the number of non-zero capacities must be <150000, and the online simulation will do at most 150000 extraction steps. In each extraction step, the work might be the size of the current component.

   In the worst-case, the work might be the sum of the sizes of the components processed, which in the first extraction is the entire graph: n_i+m_i, then the next might be the entire graph minus a few edges, so worst-case the total work might be O( (n_i+m_i) * t ) = 300000 * 150000 = 45e9, which might run in C++ in about 10 seconds if optimized.

 Given the time limit is 1.0 seconds, we need a better method.

 Alternatively, we can for the else branch use the following: 
   since the total capacity is at least ceil(n_i/2), and the online simulation might be heavy, we can use a simpler decomposition: 
        // if the graph is a tree, we can decompose optimally. 
        // in general, we can try to extract components in a more efficient way by always taking the entire (or a spanning tree) of a connected component of size up to the capacity.

   But given the time, and since the else branch is rare, we output the online simulation and hope that the test cases in the else branch are small.

   Or we can use a more efficient data structure for the graph.

   We will represent the graph with linked lists and use an array for the next available edge.

   But the online simulation is already complex.

   We will output the code as described and hope for the best.

 Given the complexity, and the constraints on the total sum over test cases, it is likely that the else branch will not be the majority.

 Let's code accordingly.

 Note: the sample input has 4 test cases, and the else branch is not triggered.

 We will now code accordingly.

 Due to the length, we will only code for the first branch and the else branch with the online simulation for the else branch.