 We note that the total number of numbers with non-decreasing digits in base 10 up to 10^18 is C(18+9, 9) - 1 (but we generate via BFS/DFS). However, the actual set of numbers n for which both n and n^2 are sorted is very small (only about 110 numbers for n up to 10^18).

 Therefore, we can precompute all such numbers (n) that are sorted and such that n^2 is sorted. We'll generate all sorted numbers (non-decreasing digits) in base 10 up to 10^18, then for each of these we check if n^2 is sorted.

 Steps:
 1. Precompute all sorted numbers up to 10^18. We can do this by generating numbers by increasing length (from 1 to 18) and for each starting digit, then next digit must be >= last digit.

 2. For each sorted number n, compute n_sq = n*n. Since n <= 10^18, n_sq <= 10^36, so we can use Python's built-in integers (which handle arbitrary large numbers) to compute and then convert to string.

 3. Check if the string representation of n_sq has non-decreasing digits.

 4. Store all n that satisfy the condition in a sorted list.

 5. For each test case, we are given X and we need to count the number of valid n <= X. We can use bisect to get the count.

 However, note: the total number of sorted numbers (non-decreasing digits) up to 10^18 is about 18+9 choose 9 = 48000? Actually, the formula is C(18+10-1, 10-1) = C(27,9) which is 4686825. That is about 4.6 million. We can generate 4.6 million numbers in Python? But T up to 100000, so we cannot precompute 4.6 million and then check each one by squaring and checking the square (which might be expensive for 4.6 million numbers) because squaring a 18-digit number and then converting to a string of 36 digits and then checking non-decreasing for 36 digits might be heavy.

 But note: the problem says that there are infinitely many such numbers only when base-1 has a nontrivial square. For base 10, base-1=9 which is 3^2 -> so there are infinitely many? However, the problem states that we only go up to 10^18. But in fact, the set of such n that satisfy the condition (both n and n^2 are sorted) is actually very small. According to known sequences (like OEIS A023087) and the problem sample, we know that the entire set of such n up to 10^18 is only about 110 numbers.

 Therefore, we can generate the set of sorted numbers (which is 4.6 million) but then we only check those that are sorted? However, 4.6 million is acceptable in C++ but in Python we must be cautious. But 4.6 million is acceptable in PyPy or Py if we code carefully? Alternatively, we can generate the sorted numbers and then check the square. The squaring for 4.6 million 18-digit numbers: each squaring is O(1) because fixed 18 digits? Actually, the multiplication for two 18-digit numbers is O(18^2) which is 324, so total operations 4.6e6 * 324 = about 1.5e9 operations which is too heavy in Python.

 We need a smarter approach.

 Alternate approach: Instead of generating all sorted numbers and then filtering by the condition (which would require 4.6 million squaring operations, which is too heavy in Python), we can use DFS to generate the sorted numbers and then check the square only for the ones that are generated. However, the problem is the squaring operation is expensive for such a large set.

 But wait: the problem states that there are only about 110 numbers that satisfy the condition. Therefore, we can generate all sorted numbers (4.6 million) and then check the square? Actually, 4.6 million is acceptable in C++ but in Python the squaring and string conversion for 4.6 million numbers might be borderline in PyPy/C++ but in Python? Let's estimate:

  - Generating the sorted numbers: we do a BFS/DFS with at most 4.6 million numbers. This is acceptable in C++ but in Python? We can try to optimize by not storing the entire set if we don't have to? Actually, we have to check each one.

  - However, 4.6 million is acceptable in Pyton if we run it once (precomputation) and then answer T queries. But T can be up to 100000, so we need the precomputation to be done once and then store the list of valid n. Then each query is a binary search over the list (which has about 110 elements).

  But note: the problem says that the valid n are only about 110, but we are generating 4.6 million sorted numbers. We are going to check 4.6 million squares? That might be acceptable? Let me calculate:

    For each sorted number n (4.6 million):
        n_sq = n * n  -> This is a big integer multiplication. For an 18-digit number, multiplying two 18-digit numbers using standard algorithms is O(18^2) = 324 operations? But Python uses Karatsuba for big integers? Actually, we don't know, but 4.6 million multiplications of 18-digit numbers in Python might be slow? 

    Then we convert to a string: which is O(36) per number. Then check non-decreasing: O(36) per number.

    Total operations: 4.6e6 * (mult_cost + 36 + 36). The multiplication cost for 18-digit numbers: worst-case, but in practice, 18-digit numbers are about 60 bits? Actually, 10^18 is 60 bits? So 60*60 = 3600 operations per multiplication? That would be 4.6e6 * 3600 = 16.56e9 operations? That is too high.

  Alternatively, we can avoid the multiplication? Or note that the condition that n^2 is sorted is very rare, so we can break early in the string check? But we have to do the multiplication and the string conversion for each.

  However, we can note that if n is large, say 10^18, then n^2 is 10^36, which is 37 digits. But the problem is the total set of sorted numbers is 4.6 million. We need to do 4.6 million big integer multiplications and string conversions. This might be acceptable in Pyton in PyPy? Or in C++? But in Python, we must avoid.

  Alternatively, we can generate the sorted numbers and then use an optimized way? Or we can use mathematical properties to skip some?

  But note: the condition that n^2 is sorted is so rare that we can generate the sorted numbers and then check the square only for the ones that are generated? Actually, 4.6 million is acceptable in C++ but in Python it might run in a few minutes? But the problem requires T up to 100000 and we are precomputing, so if we run the precomputation once, then we can answer the queries quickly. However, in an online judge, we have to run the entire program in a few seconds. 4.6 million big integer multiplications in Python might take around 10 seconds? (if each takes 0.000002 seconds? 2 microseconds per multiplication? That would be 10 seconds total). But we also have the conversion to string and the check. 

  Alternatively, we can avoid generating the entire set of sorted numbers? We know that the set of n for which n and n^2 are sorted is very small. So we can use DFS to generate the sorted numbers, but we can prune early? How?

  We can generate the sorted numbers and then check the square. But we can also precompute the entire set of sorted numbers and then store the ones that satisfy the condition. Since the valid set is only 110, we can also output them and then hardcode? But the problem constraints say T up to 100000 and X up to 10^18, so we can precompute the entire list of valid n (about 110) and then for each test case, we do a binary search over 110 numbers. That is acceptable.

  How to get the set of valid n? We can generate all sorted numbers (which is 4.6 million) and then for each, compute the square and check if it's sorted. This precomputation must be done once. Then we store the valid n in a sorted list.

  However, 4.6 million multiplications in Python might be too slow. We need to optimize the generation.

  Alternatively, we can generate the sorted numbers without BFS? We can use combinations with repetition. The sorted numbers are exactly the non-decreasing sequences of digits. We can generate by selecting the next digit. But the count is 4.6 million.

  We can try to use iterative generation and avoid recursion? We'll use a queue.

  But the main bottleneck is the squaring and the string conversion. We can avoid converting the entire square to string if we can check without conversion? For example, we can compute the digits of the square without converting to a string? We can use math to extract the digits and then check non-decreasing? That doesn't avoid the cost.

  Alternatively, we can avoid generating the entire set? We know that if n is large, then n^2 has many digits. The condition that n^2 is sorted is very strict. We can break early if the square is not sorted? But we have to compute the entire square to know.

  However, we can note that the set of valid n is known: we can look for known sequences. For base 10, the known sequence is in OEIS: A023087. The sequence of numbers such that n and n^2 (in base 10) have digits in nondecreasing order. The known terms up to 10^18 are:

  1, 2, 3, 4, 5, 6, 7, 13, 44, 45, 46, 116, 117, ... 

  But we cannot rely on hardcoding because the problem says X up to 10^18.

  How many terms are there? According to the OEIS, there are 110 terms below 10^18.

  Therefore, we can generate all the sorted numbers (4.6 million) and then check the square. We hope that in Python, 4.6 million multiplications and string conversions of up to 36-digit numbers is acceptable? Let's test:

    We are going to do 4.6e6 iterations. In each:
        n is an integer (we represent as an integer, which is efficient for small integers? but n up to 10^18, which is 18 digits, so big integers, but Python handles that)
        Compute n_sq = n * n -> that's a big integer multiplication (for numbers with 18 digits: 18*18 = 324 digit multiplications? But Python uses Karatsuba? For 18 digits, it might be using the naive method? Actually, 18 is small, so it's O(1) in practice? But 4.6e6 is acceptable in C++ but in Python it might be acceptable if we use PyPy or if the multiplication is optimized? 

    Then convert to string: that's O(digits) = 36 operations per number? Then check non-decreasing: 36 operations per number.

    Total operations: 4.6e6 * (cost of multiplication for 18-digit numbers + 72). The multiplication cost: 18-digit * 18-digit: worst-case 18*18 = 324 digit multiplications? Then adding the partial products? But 4.6e6 * 324 = 1.49e9 digit multiplications? That's too high in Python.

  We need a different approach: we can avoid generating the entire set of sorted numbers? We can iterate over the sorted numbers in a smarter way? Actually, the set of sorted numbers is generated by:

      from 1 to 9, then for each next digit from last_digit to 9.

  But we cannot avoid generating each one. However, we can avoid computing the square for every sorted number? How? We can use pruning: if the square is going to be too big? But we have to compute the square to know.

  Alternatively, we can use the fact that the square must be non-decreasing. There are known properties: the square of a number with non-decreasing digits is non-decreasing only in very rare cases. We can use mathematical bounds? For example, if the number n is large, then n^2 has many digits and the first digits must be non-decreasing. But that doesn't help much.

  However, we can break early in the digit check for the square? That doesn't avoid the multiplication and string conversion.

  Actually, we can avoid the string conversion? We can compute the digits of n^2 by repeated division by 10? Then we can store the digits in an array and check. But that is the same cost as converting to string.

  Another idea: we can avoid generating all sorted numbers? We can generate the sorted numbers and then skip the ones that are too large? But we generate up to 10^18.

  Alternatively, we can use the known fact that the valid numbers are only 110. How can we generate only the valid numbers? We can do DFS with state: (current number, last digit, current length) and then also track the square? But the square is huge. We cannot track the square as we build the digits? 

  Actually, we can use recursion to build n and also build n^2? That seems difficult.

  After research, known solutions for this problem (in C++) generate all sorted numbers (non-decreasing) and then check the square. The set of sorted numbers is about 4.6 million, and in C++ it runs in under 1 second. But in Python, we need to do the same? We can try to optimize by:

    - Using iterative generation without recursion (using a list and then a queue) and then using a list for the valid ones.

    - Then we do the multiplication and string conversion.

  How long will 4.6e6 multiplications and string conversions take in Python? We can test on a small set: 100000 multiplications of 18-digit numbers and string conversion.

  But we cannot rely on the judge's speed? We must assume worst-case.

  Alternatively, we can precompute the list of valid numbers (only 110) and then store them in the code? Then we don't need to generate the sorted numbers? But the problem says T up to 100000 and X up to 10^18, and we are not allowed to hardcode beyond 10^18. However, we can generate the valid numbers by a DFS that only goes through the sorted numbers? But we need to generate 4.6 million numbers? That is too heavy in Python? Or we can use combinatorial generation? 

  Given the constraints, we decide to precompute the valid numbers (by generating all sorted numbers and then checking the square) and hope that in Pyton we can do 4.6e6 iterations with the multiplication and string conversion in under 10 seconds? Or we can use an iterative BFS that generates the sorted numbers and then checks. We can also use a list and then iterate.

  But note: the total number of sorted numbers is:

      For length=1: 9
      For length=2: 45
      ... 
      Total = C(18+9, 9) = 4686825? Actually, the formula is: 
          numbers = C(18+10, 10) - 1? Actually, the formula for non-decreasing numbers of length k is C(9+k, 9). Then we sum for k=1 to 18? Actually, we can generate all by a DFS that goes from 1 to 18 digits.

  How to generate:

      We can use a DFS that goes digit by digit, and we keep the last digit and the current value.

  We'll do:

      stack = [ (current_value, last_digit, length) ]
      Start: for d in 1..9: push (d, d, 1)

      Then for each state, extend by digits from last_digit to 9, and current_value = current_value*10 + d, and update last_digit to d, and length+1.

  We break when current_value > 10**18? Actually, we can stop when length==18? But we can also stop when current_value*10 + d > 10**18? Actually, we set max_value = 10**18.

  We then store the current_value in a list.

  Then for each number in the list, compute the square, convert to string, check if sorted.

  Then store the n that satisfy.

  Then sort the list of valid n.

  Then for each test case, we do a binary search for the count of valid n <= X.

  Since the valid n are only about 110, the binary search for each test case is O(log(110)) which is 7 comparisons.

  The main cost is the precomputation: generating 4.6e6 sorted numbers and then for each:

        sq = n * n
        s = str(sq)
        for i in range(len(s)-1): if s[i] > s[i+1]: break

  We can optimize the check by:

        s = str(sq)
        for i in range(len(s)-1):
            if s[i] > s[i+1]:
                break
        else:
            valid_list.append(n)

  How long? We generate about 4.6e6 numbers. The multiplication: for an 18-digit number, the square is 36 digits. The multiplication algorithm: Python uses Karatsuba for big integers? The time for multiplying two numbers of n digits is about O(n^1.585) for Karatsuba? For n=18, that is 18^1.585 ≈ 18^1.5 = 18*sqrt(18) ≈ 18*4.24 = 76.32? Then 4.6e6 * 76.32 ≈ 350e6 operations? Then the string conversion: converting a 36-digit number to a string: 36 operations per number -> 4.6e6*36 = 165e6. Then the check: worst-case 36 comparisons per number -> 165e6. Total operations: 350e6 (for multiplication) + 165e6 (string conversion) + 165e6 (check) = 680e6 operations? This is acceptable in Pyton? In Pyton, each operation might be more than one CPU cycle, but 680e6 operations might take about 10 seconds? 

  But note: the multiplication for big integers in Python is implemented in C and is very efficient. The string conversion is also in C. The check loop is in Python and might be slower.

  Alternatively, we can avoid the string conversion? We can get the digits by:

        digits = []
        x = sq
        while x:
            digits.append(x % 10)
            x //= 10
        digits.reverse()

  Then check if digits are non-decreasing. This is O(36) per number. But modulo and division for a 36-digit number? That might be 36 steps per number, and 4.6e6 * 36 = 165e6, which is acceptable.

  But which is faster: converting to string and then comparing characters? Or using integer division? The integer division for big integers might be more expensive than converting to a string? 

  Actually, converting to string is also O(n) and does divisions by 10? So it's similar. But the built-in str might be faster because it's in C.

  We can do a test? But we don't have the judge. We'll use the string conversion and then check.

  We'll generate the sorted numbers and then filter. We note that the list of valid n is small (about 110) so we can store them.

  Steps:

      max_val = 10**18
      sorted_numbers = []   # we will generate all sorted numbers

      # BFS using a queue (or DFS using a stack) - we use a stack for DFS? Actually, we can use a list and iterate by increasing length? But we use a queue.

      Let's use a list and we start with all digits 1-9.

      Then we iterate:

          current = list of numbers we have (from 1 to 9) as start.

          Then for each number, we extend it by appending a digit from last_digit to 9. We stop if the new number exceeds max_val.

      We store each number we generate.

      Then for each number in sorted_numbers:

          sq = n * n
          s = str(sq)
          if all(s[i] <= s[i+1] for i in range(len(s)-1)):
              valid_n.append(n)

      Then sort valid_n (though the generation is in increasing order? Actually, we generate by increasing length and then by increasing value? But we can store as we generate? Actually, the BFS by digit length produces in increasing order? But we do not sort the entire sorted_numbers? We don't need to sort the entire sorted_numbers, but we do need to sort the valid_n? Actually, the sorted_numbers are generated in increasing order? 

      How? We start with 1-digit: 1,2,...,9 -> then 2-digit: 11,12,...,19,22,...,99 -> so the entire list is increasing? Actually, we generate by increasing length and then by increasing value? But the 1-digit numbers are less than 2-digit numbers? So we can generate in increasing order? We can use a BFS by length? Then we can just append in the order of length? But then the entire list is sorted? Actually, we can generate in sorted order? We use a queue: we start with 1,2,...,9. Then we pop in the order of generation? Then we generate 1 -> then 1 followed by 1..9 -> 10,11,...,19? But 10 is 10 which is greater than 1? But we want to generate in increasing order? Actually, we are generating by increasing length and then by increasing value? Then the entire list is sorted? Actually, we can store and then we don't have to sort the entire sorted_numbers, but we don't care because we are going to check each. But the valid_n we get might be in increasing order? Because if we generate the sorted_numbers in increasing order, then when we check and add to valid_n, we get in increasing order.

      But note: the smallest sorted number is 1, then 2, then ... 9, then 11,12,..., but 10 is not generated? Actually, 10 is not sorted? So the next is 11, which is 11. Then 12, ... 19, then 22, etc. So the entire sequence is increasing? Then the valid_n we store will be in increasing order? Then we don't need to sort valid_n? 

      However, the condition: we check as we generate? We generate by increasing value? Then the valid_n we append are in increasing order? So we don't need to sort valid_n.

  But wait: we use a queue: we start with 1..9. Then we pop 1 and then generate 10,11,...,19 -> then we pop 2 and generate 22,...,29? Then we pop 3? Then 4? Then 5? Then 6? Then 7? Then 8? Then 9? Then we pop 10? But 10 is not generated? Actually, we start with 1..9 and then we generate numbers of length 2? Then we pop the next: the next is 1 followed by 1? which is 11? Then 12? ... Then 19? Then 2? Then we generate 22,23,...,29? Then 3? Then 33,...,39? ... Then 99? Then we start with 11? Then we generate 111,112,...,119? So the order is: 
        1,2,...,9, then 11,12,...,19,22,...,29,...,99, then 111,112,...,119,122,...,129,... 

      This is not increasing? Because 19 is 19, then we generate 22 which is 22>19? Then 22,23,...,29, then 33? which is 33>29? So the entire list is increasing? Actually, we are using a queue: FIFO. So we first generate all 1-digit, then all 2-digit? Then the 2-digit are generated in increasing order? Because we start with 1 and then we generate 11,12,...,19, then we pop 2 and generate 22,23,...,29? So the entire list of generated numbers is: 
          [1,2,...,9, 11,12,...,19, 22,23,...,29, 33,...,99, 111,112,...,119, 122,...,129, ...]

      This is increasing? Because 9<11, 19<22, 29<33, etc. So yes, the entire list is in increasing order? Then we can just store as we go? Then valid_n will be in increasing order.

  So we don't need to sort valid_n.

  Then for each test case, we can do:

        count = number of valid_n that are <= X.

        Since valid_n is sorted, we can do:

            import bisect
            idx = bisect.bisect_right(valid_n, X)
            print(idx)

  However, we generate the entire list of sorted_numbers (4.6e6) and then check the square? Then store the valid ones (about 110). Then we use the valid_n list to answer queries.

  Code structure:

      Precomputation:
          max_val = 10**18
          q = collections.deque()
          for d in range(1,10):
              q.append( (d, d) )   # current number and last digit

          sorted_numbers = []   # we don't need to store all? Actually, we can iterate without storing? But we need to check the square for each, so we store the n? Or we can process immediately.

          valid_n = []

          while q:
              n, last = q.popleft()
              # Check: compute n^2 and check if sorted
              # But note: we want to avoid if n is too big? But we are generating only up to max_val.
              # Process n: check if n and n^2 are sorted? Actually, n is sorted by generation. We only check n^2.
              sq = n * n
              s = str(sq)
              # Check if s is non-decreasing
              is_valid = True
              for i in range(len(s)-1):
                  if s[i] > s[i+1]:
                      is_valid = False
                      break
              if is_valid:
                  valid_n.append(n)

              # Then generate next numbers: if n*10 <= max_val, then we can append digits from last to 9.
              if n * 10 > max_val:
                  continue

              for d in range(last, 10):
                  next_n = n * 10 + d
                  if next_n > max_val:
                      break
                  q.append( (next_n, d) )

          # Then valid_n is sorted? Because we are popping from the queue in increasing order? The queue: we start with 1-digit, then 2-digit, and the 2-digit are generated in increasing order? But the queue: we are using a deque (FIFO) so we get the numbers in increasing order? Actually, we start with 1, then we push 11,12,...,19. Then we pop 2 and push 22,...,29. Then we pop 3? ... Then we pop 9? Then we pop 11? Then we push 111,112,...,119? Then 12? But 12 is not in the queue yet? Actually, we generated 12 from 1? Then we popped 2, then 3,..., then 9, then 11? Then 12 is after 11? Because we pushed 11, then 12, ... then 19? Then we popped 11, then 12? Then we generate 121? But 121 is not sorted? Actually, we require non-decreasing? So we only generate digits >= last digit? For 12: last digit is 2, so we generate 22,23,...,29? Then 121 is not generated? Because we require the next digit to be at least 2? So 121: the last digit is 1 which is < 2? So we don't generate 121? Actually, for 12: last digit is 2? Then we generate 12 followed by d in [2,9]: so 122,123,...,129.

          And then we push these? Then the queue: after 19 we have 22,23,...,29, then 33,...,99, then 111,...,119, then 122,...,129? Then we pop 22? Then generate 222,223,...,229? Then we pop 23? ... 

          So the queue is ordered: 
              [1,2,...,9, 11,12,...,19, 22,23,...,29, 33,...,99, 111,112,...,119, 122,...,129, 133,...,199, 222,...]

          This is increasing? Because 19<22, 29<33, 99<111, 119<122? So yes, the numbers are generated in increasing order? Then the valid_n we append are in increasing order.

      Then we can use valid_n as a sorted list.

  But note: the queue may grow to 4.6e6 elements? We are storing each sorted number? Then we pop each one and process? Then we push its children? Then the total number of operations is about 4.6e6 * (1 + (number of children))? The average branching factor: for each number, we generate (10 - last_digit) children? The last_digit can be from 0 to 9? Actually, the last_digit is at least 1? And the average branching factor is (10-1)+(10-2)+...? Not exactly. But worst-case the queue has 4.6e6 elements? And we do 4.6e6 pops? Then each pop we do one multiplication and one string conversion and one check? Then we generate the children? The total cost is acceptable? The multiplication and string conversion is the bottleneck.

  We'll write the code accordingly.

  However, we must avoid recursion limits? We use a deque for BFS.

  We'll try to run the precomputation and see if it runs in the judge? But we have to hope that 4.6e6 iterations is acceptable in Pyton? In Pyton, 4.6e6 iterations is acceptable? But the multiplication and string conversion per iteration might be heavy.

  We can try to optimize the string conversion? We can avoid the inner loop if we break early? The inner loop is O(36) which is fixed. 

  Alternatively, we can avoid the multiplication for n that are too large? Actually, we have to check all.

  We'll write the code and hope that it runs in under 10 seconds? Or we can use an iterative generation without storing the entire queue? We are storing the entire queue? The memory is 4.6e6 integers? Each integer is 18 digits? That is 4.6e6 * 18*4 bytes? 4.6e6 * 72 bytes = 331e6 bytes? 331 MB? But the problem memory limit is 1024 MB? So it's acceptable.

  But time: 4.6e6 * (cost of multiplication and string conversion). 

  We'll write the code and hope that the judge's Python is fast enough.

  Alternatively, we can precompute the list of valid_n in an external program and then hardcode? But the problem says we must write a solution.

  We decide to write the BFS and hope that the multiplication and string conversion is efficient in Pyton.

  Steps:

      import collections

      max_val = 10**18
      q = collections.deque()
      valid_n = []

      for d in range(1,10):
          q.append( (d, d) )   # (current number, last digit)

      while q:
          n, last = q.popleft()

          # Check n: compute n^2 and check if its digits are non-decreasing.
          sq = n * n
          s = str(sq)
          # Check s for non-decreasing
          flag = True
          for i in range(len(s)-1):
              if s[i] > s[i+1]:
                  flag = False
                  break
          if flag:
              valid_n.append(n)

          # Generate next numbers: if n*10 <= max_val, then we can append digits from last to 9.
          if n * 10 > max_val:
              continue

          for d in range(last, 10):
              next_n = n * 10 + d
              if next_n > max_val:
                  break
              q.append( (next_n, d) )

      # Now valid_n is a sorted list (by the order of generation, which is increasing) of all valid n.

      Then we process T test cases.

  But note: the sample: 
        X=5: valid_n: which numbers? 1: 1 -> 1^2=1 -> sorted? yes -> valid_n=[1]
            2: 2 -> 4 -> sorted? yes -> [1,2]
            3: [1,2,3]
            4: [1,2,3,4]
            5: [1,2,3,4,5] -> then for X=5, we output 5? 
        But the sample output for X=5 is 5? Then for X=8: 7? 
        Then the next: 6 -> 6^2=36 -> sorted? 3 and 6: 3<=6 -> yes -> valid_n has 6? -> then 7: 7^2=49 -> sorted? 4<=9 -> yes -> then 7 is valid? Then for X=8: we have n=1,2,3,4,5,6,7 -> 7 numbers? 
        Then 8: 8^2=64 -> 6 and 4: 6>4 -> not sorted -> skip.
        Then 9: 9^2=81 -> 8>1 -> skip.
        Then 11: 11^2=121 -> 1<=2, 2<=1 -> no? skip.
        Then 12: 12^2=144: 1<=4, 4<=4 -> sorted -> valid_n now has 12? Then for X=13: 1,2,3,4,5,6,7,12 -> 8 numbers? But sample output for X=13 is 9? 

        What about 13: 
            13: 13^2=169 -> 1<=6, 6<=9 -> sorted? yes -> so 13 is valid.

        Then for X=13: n=1,2,3,4,5,6,7,12,13 -> 9 numbers.

        So we have to generate 13? Then we do: after 9, we generate 11, then 12, then 13? Then we check 13: 13^2=169 -> sorted? yes.

        So the code should work.

  But note: we must generate 13? 
        We start: 
            q: [1,2,...,9]
            pop 1: then generate 11,12,...,19 -> push these? Then pop 2: generate 22,...,29 -> then pop 3: ... pop 9: then pop 11: then check 11 -> invalid? then generate 111,112,...,119? Then pop 12: check 12 -> valid? then generate 122,123,...,129? Then pop 13: we haven't generated 13? How did 13 get in? 

        Actually, we generated 13 when we popped 1? We generated 11,12,13,...,19? So 13 is generated from 1? Then when we pop 1, we generate 11,12,13,14,...,19? Then we pop 2? Then 3? ... Then 9? Then we pop 11? Then 12? Then 13? 

        So 13 is in the queue? Then we pop 13 and check it? Then we find it is valid.

        Then the order of popping: 
            pop 1 -> then 2, then 3, then 4, then 5, then 6, then 7, then 8, then 9, then 11, then 12, then 13, then 14, ... then 19, then 22, etc.

        So 13 is popped after 9 and 11 and 12? Then we check 13 -> valid.

        Then for X=13: we have n=1,2,3,4,5,6,7,12,13? -> 9 numbers? But what about 8? 8 is popped and then we check: 8^2=64 -> not sorted -> skip. Then 9: 81 -> not sorted -> skip. Then 11: 121 -> not sorted -> skip. Then 12: 144 -> sorted -> valid_n becomes [1,2,3,4,5,6,7,12] then 13: valid_n becomes [1,2,3,4,5,6,7,12,13]. So count for X=13 is 9.

  Therefore, the code should be:

      Precomputation: generate all sorted numbers (non-decreasing digits) up to 10^18 by BFS (using a queue). For each, check if n^2 is sorted. If yes, store n.

      Then for each test case, we do a binary search (or since the list is small, we can do linear? But 110 is small, so we can also store the entire list and then for each test case iterate? But T up to 100000, so we do:

          Precompute: valid_n = [1,2,3,4,5,6,7,12,13, ...] (about 110 numbers)

          Then for each test case, we can do:

              count = 0
              for x in valid_n:
                  if x <= X:
                      count += 1
                  else:
                      break
              print(count)

          Since the list is small (110), we can do a linear scan? 100000 * 110 = 11e6, which is acceptable.

      Or we can use bisect: 

          import bisect
          idx = bisect.bisect_right(valid_n, X)
          print(idx)

      This is O(log(110)) per test case, so total O(T * log(110)) which is about 100000 * 7 = 700000 comparisons? But we don't need to use bisect? We can do:

          Precomputation: store the list of valid_n and sort? Actually, we generated in increasing order? Then we can use bisect.

  Code:

      import collections

      max_val = 10**18
      q = collections.deque()
      valid_n = []

      # Start with digits 1 to 9
      for d in range(1,10):
          q.append((d, d))

      while q:
          n, last = q.popleft()

          # Check n: compute n^2 and check if sorted
          sq = n * n
          s = str(sq)
          # Check if s is non-decreasing
          if all(s[i] <= s[i+1] for i in range(len(s)-1)):
              valid_n.append(n)

          # If n*10 <= max_val, then we can generate more
          if n * 10 > max_val:
              continue

          for d in range(last, 10):
              next_n = n * 10 + d
              if next_n > max_val:
                  break
              q.append((next_n, d))

      # Now valid_n is in increasing order? So we can use bisect.

      Then:

          T = int(input().strip())
          from bisect import bisect_right
          for i in range(T):
              X = int(input().strip())
              # Find the largest index where valid_n[index] <= X
              idx = bisect_right(valid_n, X)
              print(idx)

  However, we note that the list valid_n is not necessarily contiguous? But we generated in increasing order? Then we can use bisect.

  But we generated in the order of the queue? We argued that the queue pops in increasing order? Then valid_n is in increasing order? Then we don't need to sort? Then bisect_right will work? Actually, bisect_right requires the list to be sorted. Since we generated in increasing order, the list is sorted.

  But note: the queue pops the smallest? Actually, we start with the smallest and we generate the next numbers that are larger? Then the queue: we push the next numbers that are larger? Then the queue: the next number we pop is the smallest? So the entire list is sorted.

  Therefore, we can use bisect.

  Let's run the precomputation: how many sorted numbers? 4686825? Then we do 4.6e6 iterations? In Python, we hope it runs in time.

  But the judge: time limit 1 second? 4.6e6 iterations in Python might be borderline? But the multiplication and string conversion for each is expensive.

  We can try to optimize the inner loop for the string? We use:

        if all(s[i] <= s[i+1] for i in range(len(s)-1)):

  This is O(len(s)) but len(s) is at most 36? So 4.6e6 * 36 = 165e6 comparisons? That is acceptable in Pyton? It might be in C++ but in Python? 165e6 comparisons might take a few seconds.

  Alternatively, we can write:

        for i in range(len(s)-1):
            if s[i] > s[i+1]:
                break
        else:
            valid_n.append(n)

  This breaks early if not sorted. But worst-case it does 36 comparisons. But for numbers that are sorted? We have to do all? But the sorted condition is rare? Only 110 are sorted? But we are checking every number? So we do 4.6e6 * (average length of the string and the break condition). The average length: the square of n? n is up to 10^18, so the square has 1 to 37 digits? The average length? But worst-case 37? And we break as soon as we find a decrease? But for a random number, we break early? But the numbers we generate are sorted in base 10? But the square might be random? So we break early? But worst-case we do 36 per number? So 4.6e6 * 36 = 165e6? That is acceptable in Pyton? In Pyton, 165e6 iterations might take about 10 seconds? 

  We need to optimize.

  We can avoid the string conversion? We can check the digits of the square without converting to a string? 

      digits = []
      x = sq
      while x:
          digits.append(x % 10)
          x //= 10
      # Then reverse digits? Actually, we can check from the least significant digit? But we want the most significant first? 
      # Then we can reverse? Or we can check the digits in reverse? 

      Actually, the condition is: d0 <= d1 <= ... <= dk. 
      But we get the digits from least significant to most significant? So the list is [d0, d1, ..., dk] in reverse? Then we can check from the last to the first? 

      We can do:

          x = sq
          prev = 10   # a big digit
          while x:
              d = x % 10
              if d > prev:   # because we are going from right to left, we require non-increasing? Actually, we want non-decreasing from left to right, which is non-increasing from right to left? 
                  break
              prev = d
              x //= 10
          else:
              valid_n.append(n)

      But note: this checks that the digits are non-decreasing from right to left? But we want from left to right? 

      Example: 144: 
          digits: [4,4,1] (if we do modulo: first 4, then 4, then 1). Then we check: 
              d=4: prev=10 -> 4<=10 -> set prev=4
              d=4: 4<=4 -> prev=4
              d=1: 1<=4 -> then we set prev=1 -> and then we break? Then we say it's sorted? But 1, then 4, then 4: from left to right: 1,4,4 is sorted? But in our list we have 1 at the end? 

      Actually, we want the entire number to be non-decreasing from left to right. The leftmost digit is the most significant? So we need to check from the most significant to the least? 

      How to get the digits from most to least? We can get the number of digits? Then we can extract the most significant? Or we can store the digits in an array and then reverse? Then check? Then the cost is the same as converting to string? 

      Alternatively, we can do:

          x = sq
          digits = []
          while x:
              digits.append(x % 10)
              x //= 10
          # Now digits is in reverse order? So we reverse to get the most significant first? 
          digits.reverse()
          for i in range(len(digits)-1):
              if digits[i] > digits[i+1]:
                  break
          else:
              valid_n.append(n)

      This is the same as the string method? 

      But the cost: we do 36 iterations for the modulo and then 36 iterations for the check? Then we also have the reverse? 36 elements? So 36+36+36 = 108 per number? 4.6e6 * 108 = 500e6? That is more than the string method? 

      So the string method might be faster? 

  We'll stick to the string method? But we can break early in the string method? 

      s = str(sq)
      for i in range(len(s)-1):
          if s[i] > s[i+1]:
              break
      else:
          valid_n.append(n)

  This is the same as the string method with explicit loop? The built-in all() does the same? But we break early? The explicit loop breaks early? The all() does not break? Actually, all() breaks at the first false? So we can use:

      if all(s[i] <= s[i+1] for i in range(len(s)-1)):

  This is equivalent? 

  But which is faster? The explicit loop might be faster? Or the all with a generator? 

  We can use:

      # Option 1: explicit loop with break
      flag = True
      for i in range(len(s)-1):
          if s[i] > s[i+1]:
              flag = False
              break
      if flag: ...

      # Option 2: all(...) 

  They are equivalent in performance? 

  We'll use the explicit loop for breaking early? But worst-case we do 36 steps? So it doesn't matter? 

  We'll write the code and hope it runs in the judge.

  But note: the total cost of the inner loop (the digit check) is 4.6e6 * (average length of the square) which is about 4.6e6 * 36 = 165e6 iterations? In Pyton, 165e6 iterations might be acceptable in C++ but in Python? It might be 10 seconds? 

  We can try to run locally? 

  Alternatively, we can use known results: the valid numbers are only 110? Then we can hardcode? But the problem says we must write the program.

  We'll generate the list of valid numbers and then output the answers? 

  But we hope that the judge's Python is fast enough? 

  Let me calculate: 4.6e6 * 36 = 165e6 iterations? In Pyton, each iteration is a character comparison? That is fast? 

  We'll write the code.

  We note: we must use a 64-bit version of Python to handle integers up to 10^36? But Python integers are arbitrary large.

  Code:

      import collections

      max_val = 10**18
      q = collections.deque()
      valid_n = []

      for d in range(1,10):
          q.append((d, d))

      while q:
          n, last = q.popleft()

          # Check n^2
          n_sq = n * n
          s = str(n_sq)
          # Check non-decreasing
          sorted_flag = True
          for i in range(1, len(s)):
              if s[i] < s[i-1]:   # then not sorted? Actually, we require non-decreasing: so s[i-1] <= s[i]. So if s[i] < s[i-1] -> break.
                  sorted_flag = False
                  break

          if sorted_flag:
              valid_n.append(n)

          if n * 10 > max_val:
              continue

          for d in range(last, 10):
              next_n = n * 10 + d
              if next_n > max_val:
                  break
              q.append((next_n, d))

      # Now valid_n is the list of valid numbers, in increasing order.

      # Precomputation is done.

      T = int(input().strip())
      # We can use bisect to answer each query
      import bisect
      for _ in range(T):
          X = int(input().strip())
          # Count the number of valid_n <= X
          # Since valid_n is sorted, we use bisect_right: the insertion position to keep sorted? 
          # bisect_right returns the insertion position, which is the index at which X would be inserted to keep sorted, but it returns the index after the last element <= X.
          idx = bisect.bisect_right(valid_n, X)
          print(idx)

  But note: we can also do:

          count = 0
          for num in valid_n:
              if num <= X:
                  count += 1
              else:
                  break
          print(count)

  Since the list is small (110), we can do the linear scan? Then we don't need bisect.

  We'll do the linear scan per test case? 100000 * 110 = 11e6, which is acceptable? Yes.

  But to be consistent, we can do:

      # Precomputation: store valid_n (about 110 numbers)

      T = int(input().strip())
      for _ in range(T):
          X = int(input().strip())
          # Since valid_n is sorted, we can break early
          cnt = 0
          for num in valid_n:
              if num <= X:
                  cnt += 1
              else:
                  break
          print(cnt)

  This is simpler.

  Let me test with the sample:

      valid_n for n up to 13: [1,2,3,4,5,6,7,12,13]

      Query X=5: we iterate: 1<=5 -> cnt=1, 2<=5 -> 2, 3->3,4->4,5->5,6>5? -> break? Actually, 6 is 6>5? Then we break? Then we output 5.

      Query X=8: we iterate: 1,2,3,4,5,6,7: then 12>8? break? then output 7.

      Query X=13: we iterate: 1,2,3,4,5,6,7,12,13: 13<=13 -> cnt=9, then next? none? so 9.

  So it works.

  We run the precomputation once at the start, then process the queries.

  But the precomputation might take time? We hope that the generation of 4.6e6 numbers is acceptable in Pyton? 

  We'll run locally? For example, generate all sorted numbers up to 10^18? Then we do 4.6e6 iterations? Then we do 4.6e6 multiplications and string conversions? 

  We can test for 10^5? Actually, we are doing 4.6e6? It might take a minute? But the judge might be faster? 

  We can try to optimize the multiplication? But the multiplication is for big integers? 

  Alternatively, we note that the valid numbers are only 110? Then we can generate the sorted numbers and then only check the square for the ones that are generated? We cannot avoid generating the entire set? 

  But we hope that the judge runs the precomputation in a few seconds.

  Let me run a small test: generate the first 100000 sorted numbers and see the time.

  We'll do:

      import time
      start = time.time()
      # generate the first 100000 sorted numbers and do nothing? 
      q = deque()
      for d in range(1,10):
          q.append((d,d))

      count = 0
      while q:
          n, last = q.popleft()
          count += 1
          if count % 100000 == 0:
              print(count)
          if n * 10 > max_val:
              continue
          for d in range(last,10):
              next_n = n*10+d
              if next_n > max_val:
                  break
              q.append((next_n,d))

      print("Total generated:", count)
      end = time.time()
      print("Time:", end-start)

  On my machine? 

  But we are not doing the expensive part (the multiplication and string conversion) in this test.

  We'll also test with the multiplication and string conversion? 

  Given the constraints, we write the code as described.

  We hope it runs.

  Code:

      import collections

      max_val = 10**18
      q = collections.deque()
      valid_n = []

      # Start with digits 1-9
      for d in range(1,10):
          q.append((d, d))

      total_count = 0
      while q:
          total_count += 1
          n, last = q.popleft()

          # Compute square and check
          n_sq = n * n
          s = str(n_sq)
          # Check if s is non-decreasing: from left to right
          is_sorted = True
          for i in range(1, len(s)):
              if s[i] < s[i-1]:
                  is_sorted = False
                  break

          if is_sorted:
              valid_n.append(n)

          if n * 10 > max_val:
              continue

          for next_d in range(last, 10):
              next_num = n * 10 + next_d
              if next_num > max_val:
                  break
              q.append((next_num, next_d))

      # Precomputation done: valid_n is a list of valid numbers (about 110) in increasing order.

      T = int(input())
      res = []
      for _ in range(T):
          X = int(input())
          cnt = 0
          for num in valid_n:
              if num <= X:
                  cnt += 1
              else:
                  break
          res.append(str(cnt))

      print("\n".join(res))

  But note: the problem sample input:

        3
        5
        8
        13

      Output:
        5
        7
        9

  We'll run the precomputation and then the sample? 

  However, we must be cautious: the total_count (the number of sorted numbers) is 4686825? Then the multiplication and string conversion for 4.6e6 numbers? 

  We run locally? 

  Alternatively, we can note that the valid_n for base10 is known? We can output valid_n and see if it matches the known sequence? 

  Known sequence (from OEIS A023087): 
      1, 2, 3, 4, 5, 6, 7, 13, 44, 45, 46, 116, 117, ... 

  We'll run for small max_val? say 200.

  We expect: 
        n=1,2,3,4,5,6,7, then 13? then 44? but 44>200? 

      So valid_n for max_val=200: [1,2,3,4,5,6,7,13]

      Then for X=13: count=8? but we also have 13? Then count=8? But the sample for X=13 is 9? 

      We missed one? 

      Actually, we have 1,2,3,4,5,6,7, and then 12? and then 13? 

      So 12: n=12 -> 144 -> sorted? yes. Then 13: 169 -> sorted? yes.

      Then for X=13: 1,2,3,4,5,6,7,12,13 -> 9.

      So we must have 12 in the list.

  How do we generate 12? 
        We start with 1, then generate 11,12,...,19. Then we pop 1, then 2, then ... then 7, then 8,9, then 11? Then 12? Then 13? 

      So we have to pop 12? Then we check 12: 144 -> sorted? yes -> append 12.

      Then pop 13: 169 -> sorted? yes -> append 13.

      So the list: [1,2,3,4,5,6,7,12,13]

  Therefore, the code should generate 12.

  But note: the queue: we push 11,12,...,19 when we pop 1? Then we push 22,...,29 when we pop 2? ... Then we pop 1, then 2, then 3, then 4, then 5, then 6, then 7, then 8, then 9, then 11, then 12, then 13? 

  Then when we pop 11: we check 11 -> 121: 1<=2, 2>=1? -> no? Actually, 121: 
        digits: 1,2,1 -> 1<=2 is true, but 2>=1? -> false? so not sorted.

  Then 11 is invalid.

  Then we pop 12: 12^2=144: 1<=4 and 4<=4 -> sorted -> valid.

  Then pop 13: 13^2=169: 1<=6 and 6<=9 -> sorted -> valid.

  Then we have 1,2,...,7,12,13 -> 9 numbers for X=13.

  So the code should be correct.

  We run the entire code and hope it runs in the judge's time limit.

  If it is too slow, we can try to use the known list of 110 numbers? But we must compute them? 

  Alternatively, we can precompute the list of valid_n once and then cache? But the problem has multiple test cases? We do precomputation once at the start.

  We'll run the code.

  Note: we must use a deque from collections.

  Final code:

      import collections

      max_val = 10**18
      q = collections.deque()
      valid_n = []

      # Start with digits 1 to 9
      for d in range(1,10):
          q.append((d, d))

      while q:
          n, last = q.popleft()

          # Check n^2
          n_sq = n * n
          s = str(n_sq)
          # Check non-decreasing: from left to right
          flag = True
          for i in range(1, len(s)):
              if s[i] < s[i-1]:   # we break when we see a decrease
                  flag = False
                  break
          if flag:
              valid_n.append(n)

          # If we can extend the number: if n*10 <= max_val, then we extend
          if n * 10 > max_val:
              continue

          for d in range(last, 10):
              next_n = n * 10 + d
              if next_n > max_val:
                  break
              q.append((next_n, d))

      # Now valid_n is sorted? 
      # But note: the queue pops in increasing order? Then valid_n is in increasing order? 
      # Then we can break early in the query.

      T = int(input().strip())
      out_lines = []
      for i in range(T):
          X = int(input().strip())
          cnt = 0
          for num in valid_n:
              if num <= X:
                  cnt += 1
              else:
                  break
          out_lines.append(str(cnt))

      print("\n".join(out_lines))

  Let me test with the sample.

  But note: the sample: 
        X=5: we should get 5? 
        X=8: 7?
        X=13: 9?

  We run with the sample.

  We hope.

  But the judge: T up to 100000, but the precomputation is done once. The precomputation: we generate 4.6e6 sorted numbers? Then the main loop for the queries: 100000 * 110 = 11e6? which is acceptable.

  However, the precomputation: 4.6e6 multiplications and string conversions? We hope it runs in 10 seconds? 

  If not, we can use the known set of 110 numbers? We can compute them offline and then hardcode? But the problem says we must write the program.

  We output the code.

  Note: the problem memory limit is 1024 MB? We store 4.6e6 numbers in the queue? Each number is an integer (about 20 bytes? for 10^18, it takes about 8 bytes? Actually, Python integers take more? But we store two integers per queue element? The queue element: (n, last). The last is a digit (0-9) so we can store in a byte? But in Python, it's an int. The total memory for the queue: at most 4.6e6 * (size of two integers). The integer n: for numbers up to 10^18, it takes about 18*4/10? Actually, Python integers are stored in a variable size. The number 10^18 is about 60 bits? so about 8 bytes? Then the queue element: two integers: about 16 bytes? Then total 4.6e6 * 16 bytes = 73.6e6 bytes? 73.6 MB? Then we store valid_n: 110 integers? negligible. Then the list of sorted_numbers: we don't store? So total memory is acceptable.

  We run.

  If it is too slow, we might need to optimize the multiplication? But the multiplication is for big integers? 

  We hope.

  Let's run and submit.

  We note: the sample input 3 numbers: 5,8,13 -> we output 5,7,9.

  We run the code on the sample.

  But in the code: we break the inner loop as soon as we find a decrease? 

  We write the code as above.

  One more note: the condition for non-decreasing is: for i from 0 to len(s)-2: s[i] <= s[i+1]. 
        We did: for i in range(1, len(s)): if s[i] < s[i-1]: then not sorted.

  This is equivalent? Because if s[i] < s[i-1] then we have a decrease? And if we don't have any such decrease, then it is non-decreasing.

  So it is correct.

  We run the sample: 
        n=1: s="1" -> no loop -> flag=True -> valid_n=[1]
        n=2: s="4" -> valid_n=[1,2]
        ... 
        n=8: s="64" -> 
             i=1: s[1]='4', s[0]='6': 4<6 -> flag=False -> skip.
        n=9: s="81" -> 1<8 -> skip.
        n=11: s="121" -> 
             i=1: s[1]='2', s[0]='1': 2>=1 -> no break? 
             i=2: s[2]='1', s[1]='2': 1<2 -> break -> skip.
        n=12: s="144" -> 
             i=1: s[1]='4', s[0]='1': 4>=1 -> continue.
             i=2: s[2]='4', s[1]='4': 4>=4 -> continue.
             then flag=True -> append 12: valid_n=[1,2,3,4,5,6,7,12]
        n=13: s="169" -> 
             i=1: 6>=1 -> continue.
             i=2: 9>=6 -> continue -> append: valid_n=[1,2,3,4,5,6,7,12,13]

  Then for X=5: 1,2,3,4,5 (5 numbers) -> output 5.
        X=8: 1,2,3,4,5,6,7 (7 numbers) -> output 7.
        X=13: 1,2,3,4,5,6,7,12,13 (9 numbers) -> output 9.

  Correct.

  We run the entire code.

  We hope it runs in the judge.

  If it is too slow, we might need to use a faster language? But the problem requires Python.

  We note: the total precomputation time is dominated by 4.6e6 * (cost of multiplication and string conversion). 

  We hope.

  We'll submit.

  But note: the multiplication for n=10**18: that is a big integer? But Python handles it.

  We run.

  If it TLE, we might have to use the known list of 110 numbers? But we compute them? 

  Alternatively, we can cache the precomputation? But we do it once.

  We output the code.

  Note: We must use the condition: if n*10 > max_val: then skip. This avoids generating numbers that are too big? 

  Let me run locally for max_val=10**18? 

  But I don't know if I have enough time? 

  We trust the algorithm.

  Code: