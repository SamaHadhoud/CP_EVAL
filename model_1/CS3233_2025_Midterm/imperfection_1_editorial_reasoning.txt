 We are to delete some elements so that the resulting array is perfect.
 Conditions for a perfect array:
   Let M = max(V) in the resulting array. Then we require:
        count(M) > |V| - count(M)
   This simplifies to: 2 * count(M) > |V|

 What does this mean?
   Since |V| = count(M) + (count of all other elements), we have:
        2 * count(M) > count(M) + (others)
        => count(M) > (others)

   So the number of occurrences of the maximum element must be greater than the total occurrences of all other elements.

 How can we achieve this?
   Note: In the resulting array, the maximum element must be the global maximum of the array? 
   But observe: if we delete some elements, the maximum of the remaining array might be less than the original maximum.

 However, note that we are allowed to delete arbitrarily. We can choose which elements to keep.

 Important: The resulting array's maximum element must be the maximum of the entire array? 
   Actually, no: we can delete the original maximums and then the next largest becomes the maximum? 
   But then the condition must hold for that new maximum.

 However, note that we can choose to keep any subset. But note the condition: the maximum element in the subset must be the majority.

 How to approach?

 Observation:
   In the final array, let the maximum element be x. Then:
     - All elements in the array must be ≤ x.
     - The condition: the frequency of x must be > (total number of elements that are not x).

   Also note: if we choose x to be the maximum, then we cannot have any element greater than x. So we must delete every element with value greater than x.

   Therefore, the candidate for the maximum in the final array must be one of the distinct numbers in the original array.

   Since we are allowed to delete arbitrarily, we can choose a candidate x (which will be the maximum of the final array) and then:
     1. Delete all elements with value > x. (Because if we leave any element greater than x, then x is not the maximum.)
     2. Then, we have an array of elements ≤ x. Now, we require that the count of x is greater than the count of all other elements (which are < x).

   How to achieve condition (2)? 
        We can delete some of the non-x elements (which are < x) and even delete some x's? 
        But note: if we delete an x, that might make the condition harder to satisfy because we are reducing the count of x and also reducing the total length. 
        Actually, we can also choose to delete some x's? Let's see:

        Condition: Let 
            k = count of x in the array (after step 1: we have not deleted any x yet, but we have deleted the ones above x)
            t = total count of elements that are < x (after step 1)

        Then we have to satisfy: 
            (number of x's we keep) > (number of non-x's we keep)

        But note: we can also delete some x's? Why would we? Because if we delete an x, we can reduce the total non-x we have to delete? 
        However, observe: 
            Let k' = number of x we keep (0 <= k' <= k)
            Let t' = number of non-x we keep (0 <= t' <= t)

            Condition: k' > t'

        Also, the total size of the array is k' + t'. We require k' > (k'+t')/2 => k' > t'.

        We are allowed to delete arbitrarily. We can choose to keep as many x as we want (from 0 to k) and as many non-x as we want (from 0 to t) as long as k' > t'.

        But note: we don't have to delete the non-x's arbitrarily: we can choose which ones to delete. However, we have deletion costs.

        Our goal: minimize total deletion cost.

        The deletion cost for step 1: we must delete every element with value > x. That cost is fixed for candidate x.

        For step 2: we can choose to delete some non-x (to reduce t') and also delete some x (if we want). But note:

          We require: k' > t'. Since k' = k - (number of x we delete) and t' = t - (number of non-x we delete), the condition becomes:
             (k - d_x) > (t - d_t)   [where d_x = number of x we delete, d_t = number of non-x we delete]

          Rearranged: (k - d_x) - (t - d_t) > 0
          => (k - t) - (d_x - d_t) > 0?   -> This form is not straightforward.

        Alternatively, we can express: we require k' >= t' + 1. So:
            k - d_x >= t - d_t + 1   => k - t - 1 >= d_x - d_t.

        However, we are free to choose which non-x to delete and which x to delete? How to minimize cost?

        Actually, we can think: we are going to keep the array. We can decide independently on each element? But note we have costs.

        We are going to delete some non-x and some x. The cost for deleting a non-x element i is B_i, and for an x element i is B_i.

        We want to minimize: 
          cost = (cost of deleting all elements > x) + (cost of deleting some non-x and some x)

        But note: we are allowed to also choose to keep the non-x arbitrarily? Actually, we don't have to delete all non-x? 
        We can keep as many non-x as we want as long as the condition holds.

        However, we must satisfy: k' > t'. 

        We can also choose to delete all non-x? Then condition: k' > 0 -> so we must keep at least one x? But if we delete all non-x, then condition becomes: k' > 0 -> which is true as long as we keep at least one x.

        Alternatively, we can keep some non-x? But then we must have k' > t'. 

        How to minimize cost? We have two sets: 
          Set X: the elements with value x (we can choose to delete any subset of these, each with cost B_i)
          Set Y: the elements with value < x (we can choose to delete any subset of these, each with cost B_i)

        Condition: (|X| - |deleted from X|) > (|Y| - |deleted from Y|) 
          => (|X| - |Y|) > |deleted from X| - |deleted from Y|

        But note: we can also express the condition as:
            (|X| - |deleted from X|) > (|Y| - |deleted from Y|)
            => (|X| - |Y|) > |deleted from X| - |deleted from Y|

        This is not linear.

        Alternatively, we can rearrange:
            |X| - |deleted from X| > |Y| - |deleted from Y|
            => |deleted from Y| > |Y| - (|X| - |deleted from X|) 
            => |deleted from Y| > (|Y| - |X|) + |deleted from X|

        This is messy.

        Let:
            Let k0 = |X| (after step 1, we have k0 = count(x) in the original array for values <= x, but we haven't deleted any non-x above? Actually step1: we delete all > x, so k0 is the count of x originally in the entire array? Actually, we might have deleted the x that are above? No: x is fixed and we delete only values greater than x. So the set of x remains intact.)

            Let t0 = |Y| = total non-x elements that are <= x (so they are < x) after step 1.

        Condition: (k0 - dx) > (t0 - dy)   [dx: number of x we delete, dy: number of non-x we delete]

        => k0 - dx > t0 - dy
        => dy - dx > t0 - k0

        Let R = t0 - k0 + 1. Then we require: dy - dx >= R? 
          Actually: k0 - dx > t0 - dy  => dy + dx? > t0 - k0? 

        Let me rearrange: 
            k0 - dx > t0 - dy
            => dy - dx > t0 - k0

        So if we let D = dy - dx, then we require D > t0 - k0.

        Since t0 - k0 might be negative? Then we might not need to delete any? 

        Example: if k0 > t0, then t0-k0 is negative. Then we require D > negative number -> which is always true (if we delete nothing, then D=0). 

        But note: if we delete nothing, condition is k0 > t0 -> which is satisfied.

        However, what if k0 <= t0? Then t0 - k0 >= 0. Then we require D = dy - dx >= (t0 - k0) + 1? (because we require strictly greater)

        Actually: the inequality is strict: we require dy - dx > t0 - k0. Since dy and dx are integers, we can write:
            dy - dx >= (t0 - k0) + 1.

        So we have to achieve at least (t0 - k0 + 1) for the difference (dy - dx).

        How to minimize the total cost? 
          We are to choose:
            dx: number of x we delete (we can choose which ones) -> each x we delete costs the corresponding B_i.
            dy: number of non-x we delete (we can choose which ones) -> each non-x we delete costs the corresponding B_i.

          But note: we can also choose to delete more than the minimum? But we want minimal cost.

        Alternatively, we can think: we are going to choose a set of deletions from the non-x and from the x. The condition is:

            (number of non-x we delete) - (number of x we delete) >= (t0 - k0 + 1)

        And we want to minimize the total cost: 
            cost = (sum of cost of deleted non-x) + (sum of cost of deleted x) + (the fixed cost for deleting values > x)

        How to choose the deletions? 

        We note:
          We can choose arbitrarily which non-x to delete and which x to delete. 

        We have two sets of costs: 
          For non-x: we have a list of costs for each element in Y. We can delete any subset of these.
          For x: we have a list of costs for each element in X. We can delete any subset of these.

        But note: the condition is on the difference of the counts: dy - dx >= D0, where D0 = t0 - k0 + 1.

        We can reframe: We start with no deletion (dx=0, dy=0). Then we can choose to delete some non-x (which increases dy) and delete some x (which increases dx) but note: deleting an x increases dx by 1 and decreases the left side (dy-dx) by 1? Actually:

            Initially: dy - dx = 0.

            When we delete one non-x: dy increases by 1 -> then (dy-dx) becomes 1.
            When we delete one x: dx increases by 1 -> then (dy-dx) becomes -1.

        So we can view: 
            Each non-x we delete: adds 1 to the difference (dy-dx) and costs c (the cost of that non-x).
            Each x we delete: subtracts 1 from the difference (dy-dx) and costs c (the cost of that x).

        Therefore, we can think of each operation:

            Operation 1: delete a non-x: (difference) += 1, cost += c
            Operation 2: delete an x: (difference) -= 1, cost += c

        And we require the difference >= D0, where D0 = t0 - k0 + 1.

        Now note: we can also choose to delete an element or not. We want to minimize the total cost.

        We can use dynamic programming? But note: we have two sets and the total deletion count is not fixed, and we care about the difference (which can be negative?).

        However, the constraints: N up to 300,000. The difference D0 = t0 - k0 + 1, and note that t0 and k0 are at most 300,000, so D0 can be as large as 300,000? and negative? 

        Alternatively, we can note:

          The condition: we require at least D0 = max(0, t0 - k0 + 1) non-x deletions? Why? 

          Actually, if D0 <= 0, then we don't need to do anything? 

          But wait: if D0 = t0 - k0 + 1 <= 0, then we have k0 >= t0+1, so condition holds without any deletion? 

          So for candidate x, the cost for step 2 is 0? 

          However, we can also delete some x? But why would we? It doesn't help the condition and only adds cost. Similarly, we don't need to delete any non-x.

          Therefore, for candidate x with k0 >= t0+1, the only cost is the fixed cost (deleting elements > x).

        Now, if D0 = t0 - k0 + 1 > 0, then we require at least D0 net non-x deletions (in the sense of the difference) but note: we can also delete x which reduces the net. 

        Actually, the net we need is D0. How can we achieve it? 

          We can delete some non-x and some x. But note: we can also delete more non-x to compensate for deleting x? 

          Example: we need net = 3. We can:
            - delete 3 non-x and 0 x: net change = 3 -> cost = cost of 3 non-x.
            - delete 4 non-x and 1 x: net change = 4 - 1 = 3 -> cost = cost of 4 non-x + cost of 1 x.

          So we have multiple ways.

        How to minimize the total cost? 

          We can consider: we want to achieve a net change of at least D0. We can do:

            Option 1: delete only non-x: then we need to delete at least D0 non-x. Then the cost is the sum of the smallest D0 non-x? 

            Option 2: delete some x as well: then if we delete one x, we need to delete D0+1 non-x? Then the cost is the sum of the smallest D0+1 non-x plus the cost of one x. But which x? 

          Actually, we can choose which non-x to delete arbitrarily (we want the cheapest ones) and which x to delete arbitrarily (again the cheapest ones).

          Let:
            Let we delete a non-negative integer a (non-x deletions) and b (x deletions). Then we require: a - b >= D0.

          The cost is: 
             cost = (sum of the a smallest non-x) + (sum of the b smallest x)

          Then we need to minimize this cost over a, b such that a-b>=D0, and 0<=a<=t0, 0<=b<=k0.

        How to compute this quickly? 

          We can iterate over b (number of x we delete) from 0 to min(k0, a_max) and then a = D0 + b? But note: we can delete more non-x than required? 

          Actually, for fixed b, we require a >= D0 + b. Then the minimal cost for non-x for a given a is the prefix sum of sorted non-x costs. Similarly for x, the minimal cost for b deletions is the prefix sum of sorted x costs.

          Then for each b from 0 to k0:
             a_min = D0 + b
             if a_min <= t0, then total cost = prefix_nonx[a_min] + prefix_x[b]
             and if a_min > t0, then we cannot achieve with this b.

          Then we take the minimum over b? 

        But note: we can also delete more non-x than a_min? That would cost more? So the minimal for fixed b is to take exactly a_min non-x? 

          Why? Because if we take more than a_min non-x, the cost would be more than the prefix_nonx[a_min] plus the cost of the extra non-x. So we want the minimal for fixed b: we take the minimal a_min non-x.

        However, what if we fix b and take a = a_min, but we can also take a_min + k? That would cost more? So the minimal for fixed b is achieved at a = a_min.

        Therefore, we can do:

          Precomputation:
            Sort the non-x elements by cost -> let non_x_sorted = sorted(costs for non-x) and prefix_nonx[i] = sum of the first i non_x_sorted.
            Sort the x elements by cost -> let x_sorted = sorted(costs for x) and prefix_x[i] = sum of the first i x_sorted.

          Then for b from 0 to k0:
             a = D0 + b
             if a > t0: break (since b increases, a will only get larger) or skip.
             total_cost = prefix_nonx[a] + prefix_x[b]

          Then we take the minimum total_cost over b in [0, min(k0, ...)].

        But note: D0 = t0 - k0 + 1, which can be large? and t0 is the total non-x, so a = D0 + b = (t0 - k0 + 1) + b. 
          Since b is at least 0, a is at least t0 - k0 + 1. And if t0 - k0 + 1 is large, then we might have a > t0 for small b? 

          Actually, we break when b is such that D0 + b > t0. 

        However, note: we are iterating b from 0 to k0, but if k0 is large, and D0 is large, then the iteration might be over k0 which is 300,000, which is acceptable? 

          But worst-case k0 can be 300,000, so the loop is 300,000 iterations -> acceptable.

        But wait: we are considering candidate x over distinct values in the array? How many distinct values? Up to 300,000? Then the entire algorithm would be O(300,000 * 300,000) = 90e9 -> too slow.

        Therefore, we cannot iterate over each candidate x and then for each candidate x iterate over b from 0 to k0.

        We need a better way.

        Alternative approach for candidate x:

          We must:
            Step 1: delete all elements with value > x: cost = sum_{i: A_i > x} B_i.

          Step 2: for the remaining array (only elements <= x), we have:
              k0 = count of x
              t0 = count of elements with value < x

          Then we require net deletion (non-x deletions minus x deletions) >= D0 = max(0, t0 - k0 + 1).

          How to compute the minimal cost for step 2 without iterating over b in [0, k0]? 

          We can note that the minimal cost for step 2 is the minimum over b of [prefix_nonx[D0+b] + prefix_x[b]].

          We can iterate b from 0 to min(k0, t0 - D0) [if D0+b<=t0]? 

          But note: t0 - D0 = t0 - (t0 - k0 + 1) = k0 - 1, so we iterate b from 0 to min(k0, k0-1) -> which is 0 to k0-1. 

          Actually: D0 = t0 - k0 + 1, then a = D0+b = (t0 - k0 + 1) + b, and we require a<=t0 -> (t0 - k0 + 1 + b) <= t0 -> b <= k0-1.

          So b in [0, k0-1]. Then we iterate b from 0 to k0-1? 

          Then for each candidate x, we do a loop of size k0 (which is the count of x). The sum of k0 over all distinct x is the total n? 

          But note: the distinct x are the distinct values in the array. However, the count for each distinct x is the frequency, and the sum of frequencies over distinct x is n. 

          Therefore, the total iteration over all candidate x would be O(n) = 300,000. 

          Why? Because each element is counted in one candidate x (as part of the set of x) and the loop for candidate x is over the count of x (which is the frequency). And the sum of frequencies over distinct x is n.

          So we can do:

            For each distinct candidate x (from smallest to largest? but we need to consider that we delete all elements above x, so we should process candidate x in increasing order? Actually, we can process independently.)

          Steps:

            Precomputation:
              Precompute the fixed cost for each candidate x: 
                 fixed_cost(x) = sum of costs of all elements with value > x.

            Then, for the remaining array (elements <= x), we have:
                 k0 = frequency of x in the entire array? (because we haven't deleted any x) 
                 t0 = total number of elements with value < x? (again in the entire array, because we haven't deleted any)

            But note: we are going to delete elements above x, so the array for step2 is the entire array without the elements above x? 

            How to compute t0? 
                t0 = (total number of elements with value < x) -> we can precompute by a frequency array and prefix sums?

            Actually, we can precompute:

                Let F[i] = frequency of value i.
                Then for candidate x, the fixed cost is the sum of costs for all elements with value > x.

                How to get that quickly? 
                  We can precompute an array for the cost per value? But note: each value may have multiple costs.

            Instead, we can:

                Precompute an array for each value: the list of costs for that value.

                Then, for the fixed cost for candidate x: 
                    fixed_cost(x) = sum_{v = x+1}^{max_value} (sum of costs for all elements with value = v)

                We can precompute an array `sum_cost` for each value: 
                    sum_cost[v] = sum of B_i for all i such that A_i = v.

                Then fixed_cost(x) = sum_{v = x+1}^{max_value} sum_cost[v]. We can compute this with a suffix sum array.

            For step2:

                We have two sets:
                  Set X: all elements with value = x -> we have the list of costs for these.
                  Set Y: all elements with value < x -> we have the list of costs for these.

                Then we sort the list for X and the list for Y.

                Precompute prefix sums for X: 
                    sort the list for X -> then prefix_x[i] for i=0 to k0 (k0 = F[x])
                Similarly, sort the list for Y -> then prefix_y[i] for i=0 to t0 (t0 = total elements with value < x? which we can compute as: 
                    t0 = (prefix frequency sum for values in [1, x-1])? But we don't have the entire list? 

                Actually, we need the entire list of costs for Y? 

                How to get the list for Y? 
                    We can precompute for each value the list of costs? Then the list for Y is the concatenation of the lists for all values < x? 

                But the total length of these lists is the total number of elements with value < x -> which is the entire array? and the distinct x are many, so we cannot do this for each candidate x.

            Alternative: we can precompute the entire set of elements (with value and cost) and then process candidate x in increasing order? 

            Idea: we iterate candidate x from 1 to MAX (MAX = 300000). Then:

                The set Y for candidate x is the set of elements with value < x, which we can accumulate as we iterate x from 1 to MAX.

            Steps:

                Precomputation:
                  MAX_V = 300000
                  For each value v, we store:
                    count[v] = frequency of v
                    list_costs[v] = list of costs for elements with value v.

                  Precompute suffix_sum: 
                    suffix_sum[i] = sum_{v=i}^{MAX_V} sum_cost[v]   -> then fixed_cost(x) = suffix_sum[x+1]

                Now, we want for each candidate x (from 1 to MAX_V, but skip if count[x]==0?):

                  k0 = count[x]
                  t0 = (total number of elements with value < x) -> which is the count of elements in the array with value in [1, x-1]. We can precompute a prefix_count and prefix_sum for the counts? 

                  But for the set Y (elements < x) we need the entire list of costs? 

                We can maintain a data structure for the costs of all elements with value in [1, x-1]. Since we iterate x from 1 to MAX_V, we can accumulate the elements as we go.

                Similarly, for the set X, we have the list for value x.

            We do:

              Let's create a global structure for the set Y (which grows as x increases). 

              We'll iterate x from 1 to MAX_V:

                  For the current candidate x:
                    Step 1: fixed_cost = suffix_sum[x+1]   (which we precomputed)

                    Step 2: 
                         k0 = count[x]
                         t0 = (we can precompute a prefix_count: total_count_below[x] = sum_{v=1}^{x-1} count[v]) 
                         But we also need the entire list of costs for values < x? 

                    However, we are iterating x from 1 to MAX_V. We can maintain:

                         A min-heap for the entire set Y? But we need the entire sorted list to compute prefix sums? 

                    Alternatively, we can maintain a sorted array for Y? But insertion of one value at a time? Then we can do a Fenwick tree or segment tree for the entire set of values? 

                Actually, we don't need the entire set of Y to be sorted for each candidate x? We only need the smallest a elements for a up to t0? 

                We can precompute the entire set of elements with value < x? But that is huge.

            Alternatively, we can precompute the entire set of non-x for each candidate x? But that would be O(n) per candidate x, and there are O(MAX_V) candidates -> 300000*300000 -> 90e9.

            We need a more efficient way.

        Insight:

          We note that the condition D0 = t0 - k0 + 1 might be large? but the minimal cost for step2 is the minimum over b in [0, min(k0-1, ...)] of prefix_nonx[D0+b] + prefix_x[b].

          How can we compute prefix_nonx for the set Y without having the entire list? 

          We can maintain the entire multiset of costs for all elements with value < x. Then we want the prefix sums for this multiset? 

          We can use a Fenwick tree or segment tree for the costs? But note: the costs can be up to 300000, and we have up to 300000 elements.

          Steps:

            Precomputation for Fenwick tree for the entire array? But we are iterating x and we are adding the elements with value = x-1 when we move to x? 

            Actually, we can iterate x from 1 to MAX_V, and as we increase x, we add the elements with value = x-1 to the Fenwick tree? 

            How we do:

                Let's define:
                  We'll have a Fenwick tree (or segment tree) for the cost values (the cost domain is [1, 300000]). The Fenwick tree will support:
                     - Adding a cost with multiplicity and updating the prefix sum.
                     - Query the k-th smallest prefix sum? Actually, we want the sum of the k smallest elements.

                We also need to store the entire multiset? 

                Alternatively, we can use a heap? But we need the k smallest.

            Actually, we can maintain two heaps: a max-heap for the k smallest? but we want the prefix sum for any k.

            Instead, we can use a Fenwick tree that stores the number of elements and the sum for each cost.

            Precomputation:

                Let MAX_C = 300000 (for cost)

                We'll have an array for the Fenwick tree for the entire set Y (which is built incrementally).

            Algorithm:

                Initialize:
                  fixed_cost: we have precomputed suffix_sum for each x.

                  We also precomputed for each value v, the list of costs for that value.

                We'll iterate x from 1 to MAX_V:

                  Step 0: if count[x] == 0, skip candidate x.

                  Step 1: fixed_cost = suffix_sum[x+1]   (this is the cost to delete all > x)

                  Step 2: 
                         k0 = count[x]
                         t0 = total_count_below[x]   # we can precompute an array: prefix_count[x] = sum_{v=1}^{x-1} count[v] -> but note: we haven't built the Fenwick tree for Y? 

                  However, note: we are building the set Y as we go: 
                         At x, the set Y includes all elements with value in [1, x-1]. 

                  How to get total_count_below[x]? 
                         We can precompute: 
                             prefix_count[0] = 0
                             prefix_count[i] = prefix_count[i-1] + count[i-1]   for i>=1? 

                  But we also need the entire multiset of costs for Y? 

                  We are going to add the elements with value = x-1 to the Fenwick tree when we process x? 

                  Actually, we can do:

                      Before processing candidate x, we add all elements with value = x-1 to the Fenwick tree? 

                  But then we iterate x from 1 to MAX_V: 
                      For x=1: then Y is elements with value=0? -> none.
                      For x=2: we add the elements with value=1.
                      For x=3: we add the elements with value=2, etc.

                  So we can do:

                      Precomputation: 
                         Let F = array of frequencies, and for each value, we have the list of costs.

                      We'll create an empty Fenwick tree (or segment tree) for the cost domain [1, MAX_C].

                      Let total_sum_nonx = 0   # we don't need the entire prefix array? we only need the prefix_nonx[i] for i = D0+b, which we don't know? 

                  How to get the sum of the smallest a elements in the set Y? 
                      We can use a Fenwick tree that stores the costs and the counts? 

                  We can use a Fenwick tree that stores the keys by cost. We store:
                         cnt[i] = number of elements in Y with cost = i
                         sum[i] = total cost of elements in Y with cost = i

                  Then we can do a binary search for the k-th smallest? Actually, we want the prefix sum for k smallest.

                  Alternatively, we can use a Fenwick tree for the entire array of costs? 

                  We have two Fenwick trees? 
                    One for the counts: to quickly know how many elements are <= a given cost.
                    One for the sums: to quickly get the sum of costs for all elements <= a given cost.

                  Then, to get the sum of the smallest k elements, we can do:

                     Find the smallest cost such that the cumulative count is >= k? Then we can get the cumulative sum up to that cost? But we might have to break in the middle.

                  Actually, we can use a Fenwick tree that stores the entire distribution. Then the function to get the k smallest sum is:

                      We can use a Fenwick tree for the keys (costs) and then:

                         We want the k smallest: we traverse the Fenwick tree to find the k-th smallest element? 

                  However, we can do:

                      We'll maintain:

                         Fenw_count: Fenwick tree for counts per cost.
                         Fenw_sum: Fenwick tree for sums per cost.

                  Then the prefix_nonx[a] = the sum of the a smallest elements in Y can be computed by:

                      We can do a binary search on the cost to get the threshold? 

                  Alternatively, we can use a segment tree that stores the entire multiset? 

                  But note: we are iterating x, and we add a whole list of costs for value = x-1 at each step. Then we need to update the Fenwick trees for each cost in the list.

                  The total number of elements is 300,000, so the total update is O(n log MAX_C) = 300000 * log(300000) which is acceptable.

                Steps for step2 for candidate x:

                  k0 = count[x]
                  t0 = prefix_count[x]   # which we precomputed: prefix_count[x] = sum_{v=1}^{x-1} count[v]

                  D0 = max(0, t0 - k0 + 1)   # if D0==0, then step2 cost=0.

                  If D0==0, then step2 cost = 0.

                  Else (D0>0):

                      We want to compute:
                         min_{b=0}^{min(k0-1, k0)} { prefix_nonx[D0+b] + prefix_x[b] }

                      How to compute prefix_nonx[D0+b]? 
                         This is the sum of the smallest (D0+b) elements in the set Y.

                      How to compute prefix_x[b]? 
                         We have the list of costs for value=x. We can pre-sort this list? and then precompute the prefix sum for the sorted list? 

                         But note: we are iterating x, and we can precompute for each value the sorted list and its prefix sums? 

                         We can do that at the beginning: for each distinct value x, sort the list of costs and precompute the prefix sum array for x.

                      So for the x set, we have:

                         sorted_x = sorted(list_costs[x])
                         prefix_x_arr = prefix sums for sorted_x: 
                            prefix_x_arr[0] = 0
                            prefix_x_arr[i] = prefix_x_arr[i-1] + sorted_x[i-1]   for i from 1 to k0

                  Then for each b from 0 to min(k0-1, k0): 
                         a = D0+b
                         If a > t0: break.

                         Then candidate_cost = prefix_x_arr[b] + (query the Fenwick trees for the smallest a elements in Y)

                  How to query the Fenwick trees for the smallest a elements? 
                         We can get the sum of the smallest a elements by a Fenwick tree that supports kth element queries? 

                  Actually, we can do:

                         We have a Fenwick tree for the entire set Y. We want the sum of the smallest a elements.

                         We can do a binary search over the cost? Or we can use a Fenwick tree that supports "kth smallest element" by storing the entire distribution? 

                  Alternatively, we can store the entire multiset in a Fenwick tree and then:

                         We want the sum of the smallest a elements.

                         We can traverse the Fenwick tree in increasing order? 

                  But note: we need to do it for each b? Then we iterate b from 0 to k0-1, and for each b we do a query that is O(log MAX_C)? 

                  Then for candidate x, the cost is O(k0 * log MAX_C). The total over all x is O(n * log MAX_C) = 300000 * 20 = 6e6, which is acceptable.

                However, we can precompute the entire Fenwick tree for Y at candidate x? and then we can get the prefix_nonx[a] for any a? 

                  We have the Fenwick trees (count and sum) for the entire set Y. Then:

                         prefix_nonx[a] = the sum of the smallest a elements.

                  How? 
                      We can use the Fenwick trees to get the kth smallest? Actually, we can use a Fenwick tree to get the sum of the first k smallest? 

                  We can store:

                         Fenw_count: so we can query the total count up to a threshold.
                         Fenw_sum: so we can query the total sum up to a threshold.

                  Then to get the sum of the smallest a elements:

                      We can use binary search to find the threshold T such that the cumulative count is >= a? Then:

                         Let T0 = the largest cost such that the cumulative count < a? Then the smallest a elements include:

                            All elements with cost <= T0: which we can get from Fenw_sum.
                            Then we need (a - count(T0)) elements of cost T0+1? 

                  But note: the Fenwick tree stores per integer cost. We can do:

                      We traverse the cost values? That would be O(MAX_C) which is 300000 -> too slow.

                  Alternatively, we can use a Fenwick tree that supports selection? 

                  We can do a binary search on the cost? 

                      Let L=0, R=MAX_C, and we want the smallest threshold T such that Fenw_count(T) >= a.

                  Then the sum = 
                      = (the sum of all elements with cost <= T-1) 
                        + T * (a - Fenw_count(T-1))

                  But wait: we might have multiple elements at cost T? 

                  Actually, we store the counts per cost. So:

                      Let C = Fenw_count(T-1)   [count of elements with cost <= T-1]
                      Then we need a - C more elements at cost T? 
                      Then the sum = Fenw_sum(T-1) + T * (a - C)

                  However, note: we don't have Fenw_sum(T-1) stored? We have Fenw_sum for the entire array? 

                  We can precompute Fenwick trees for the prefix sums? 

                  We have two Fenwick trees:

                     cnt_tree: for counts, so we can do cnt_tree.query(T) = number of elements with cost in [1, T]
                     sum_tree: for sums, so we can do sum_tree.query(T) = total cost of elements with cost in [1, T]

                  Then:

                     Step 1: find the smallest T such that cnt_tree.query(T) >= a.

                     How? We can do a binary search over T in [1, MAX_C]. Then:

                         Let low = 1, high = MAX_C.
                         while low < high:
                            mid = (low+high)//2
                            if cnt_tree.query(mid) >= a:
                                high = mid
                            else:
                                low = mid+1

                     Then T = low.

                     Then the sum of the smallest a elements is:

                         s1 = sum_tree.query(T-1)   # sum of all elements with cost <= T-1
                         s2 = T * (a - cnt_tree.query(T-1))   # the next (a - cnt_tree.query(T-1)) elements at cost T

                         total = s1 + s2

                  But note: what if there are not enough elements at cost T? Actually, by our binary search, we have:

                         cnt_tree.query(T-1) < a <= cnt_tree.query(T)

                  So we take all the elements at cost T? Actually, we only take the required number.

                  However, the Fenwick tree for counts and sums are built for the entire set Y. This query is O(log(MAX_C)*log(MAX_C))? (binary search over the Fenwick tree) -> O(log^2(MAX_C)). 

                  Then for each candidate x and for each b (from 0 to k0-1) we do one such query? Then the total cost is O(n * log^2(MAX_C))? 

                  The total number of candidate x: distinct x with count[x]>0 -> at most 300000 distinct? But note: the inner loop over b: for each candidate x, we iterate b from 0 to k0-1, and the total over all x is O(n). 

                  So total operations: O(n * log^2(MAX_C)) = 300000 * (log2(300000))^2 -> log2(300000) is about 19, then 19^2=361, so 300000*361 = 108.3e6 -> acceptable.

            But note: we can avoid the binary search? 

                  We can store the entire array of costs for Y? Then we can use a segment tree that supports kth smallest element? 

                  Actually, we can use a Fenwick tree to get the kth smallest? 

            Alternatively, we can precompute the entire sorted list for Y? But we are building Y as we iterate x? 

            However, we are iterating x from 1 to MAX_V, and at each x we add the elements with value=x-1. Then the set Y is growing. And we need to query the k smallest at each candidate x for multiple k (for b in [0, k0-1]). 

            We can maintain a data structure that supports:

                  Insertion of a set of numbers (each with a cost value) and then query the sum of the smallest a elements.

            And we want to do the insertions as we move x? 

            We can use a Fenwick tree as described. 

        Steps for the entire algorithm:

          Precomputation:
            MAX_V = 300000
            MAX_C = 300000

            Read n, arrays A and B.

            F = [0]*(MAX_V+2)
            sum_cost = [0]*(MAX_V+2)   # sum_cost[v] = total cost for all elements with value = v

            # Also, for each value v, we store the list of costs: costs_by_value[v] = list()
            costs_by_value = [[] for _ in range(MAX_V+2)]

            for i in range(n):
                a_val = A[i]
                b_val = B[i]
                F[a_val] += 1
                sum_cost[a_val] += b_val
                costs_by_value[a_val].append(b_val)

            # Precompute suffix_sum for fixed_cost: 
            suffix_sum = [0]*(MAX_V+3)   # suffix_sum[i] = sum_{v=i}^{MAX_V} sum_cost[v]
            for i in range(MAX_V, 0, -1):
                suffix_sum[i] = suffix_sum[i+1] + sum_cost[i]

            # Precompute prefix_count: 
            prefix_count = [0]*(MAX_V+2)   # prefix_count[i] = total count of elements with value in [1, i]?
            # Actually, we want for candidate x: total_count_below = count of elements with value in [1, x-1] -> so that is prefix_count[x-1]?
            # But let's define: 
            #   total_count_below[1] = 0
            #   total_count_below[x] = F[1] + F[2] + ... + F[x-1]
            total_count_below = [0]*(MAX_V+2)
            for i in range(1, MAX_V+1):
                total_count_below[i] = total_count_below[i-1] + F[i-1]   # because we are including value i-1? 
                # Actually, we want below x: so for x=1: 0; for x=2: F[1]; for x=3: F[1]+F[2]; ... 
            # Alternatively, we can do:
            #   total_count_below[x] = prefix_count[x] = F[1] + ... + F[x-1]

            # Precompute for each value x (that appears) the sorted list of costs and the prefix sum array for that sorted list.
            #   prefix_x_arr[value] = [0, sorted_x[0], sorted_x[0]+sorted_x[1], ...]   for value=x
            prefix_x_arr = [None]*(MAX_V+2)   # prefix_x_arr[x] = prefix sum array for value x
            for v in range(1, MAX_V+1):
                if F[v] > 0:
                    lst = sorted(costs_by_value[v])
                    arr = [0]*(F[v]+1)
                    for i in range(1, F[v]+1):
                        arr[i] = arr[i-1] + lst[i-1]
                    prefix_x_arr[v] = arr
                # else: leave as None

            # Initialize Fenwick trees for the set Y (which is the set of elements with value < x). We'll have two Fenwick trees: 
            #   cnt_tree: Fenwick tree for counts, size = MAX_C+1 (indexed 1..MAX_C)
            #   sum_tree: Fenwick tree for sums, size = MAX_C+1
            # We'll create FenwickTree classes for counts and sums.

            # We'll iterate x from 1 to MAX_V:

            #   Before processing candidate x, we add the entire list for value = x-1 to the Fenwick trees? 
            #   But note: at x=1, we skip value=0? 
            #   Actually, we start at x=1: then we have not added any value (since value=0 doesn't exist). Then at x=2, we add the elements for value=1.

            #   So we do:

            #       for x in range(1, MAX_V+1):
            #          if x>=2: 
            #             we add all elements with value = x-1 to the Fenwick trees.

            #   How to add? 
            #       For each cost c in costs_by_value[x-1]:
            #          update cnt_tree at c: add 1
            #          update sum_tree at c: add c

            #   Then process candidate x: 

            #       fixed = suffix_sum[x+1]   # cost to delete all > x
            #       k0 = F[x]
            #       t0 = total_count_below[x]   # = prefix_count[x] = F[1]+...+F[x-1]

            #       D0 = max(0, t0 - k0 + 1)

            #       If D0 == 0:
            #           step2 = 0
            #           total_cost = fixed + step2
            #           candidate_ans = min(candidate_ans, total_cost)
            #       Else:
            #           step2 = a big number
            #           For b in range(0, min(k0, k0)):   # actually b from 0 to k0-1? because a = D0+b and we require a<=t0, and D0 = t0-k0+1, then a = t0-k0+1+b, and we require a<=t0 -> b<=k0-1.
            #               a = D0 + b   # = (t0 - k0 + 1) + b
            #               if a > t0: 
            #                   break   # but note: a = t0 - k0 + 1 + b, and b<=k0-1 -> a <= t0 - k0 + 1 + k0-1 = t0, so we don't break? 
            #                   Actually, a = t0 - k0 + 1 + b, and b is from 0 to k0-1, so a_max = t0 - k0 + 1 + k0-1 = t0, so a is at most t0 -> no break.

            #               Then we need to compute:
            #                   cost_nonx = query_sum(a)   # the sum of the smallest a elements in Y
            #                   cost_x = prefix_x_arr[x][b]   # the sum of the smallest b elements in X (if b==0, then 0; if b>=1, then prefix_x_arr[x][b] which we precomputed)
            #                   total_step2 = cost_nonx + cost_x
            #                   step2 = min(step2, total_step2)

            #           total_cost = fixed + step2
            #           candidate_ans = min(candidate_ans, total_cost)

            #   Then update: add the elements with value = x? 
            #       Actually, we are adding value = x-1 at the beginning of the loop for x? 
            #       But for candidate x, the set Y does not include value = x? Only values < x. So we add value = x-1 at the beginning of the loop? 

            #   However, note: we are iterating x from 1 to MAX_V, and we want to process candidate x with the set Y being the elements with value in [1, x-1]. 
            #   So at the start of x, we have in the Fenwick trees the elements for values from 1 to x-2? Then we add value = x-1 at the beginning of the loop.

            #   Then the set Y for candidate x is complete: [1, x-1].

            #   So:

            #       for x in range(1, MAX_V+1):
            #           # Add the elements with value = x-1 (if x>=2)
            #           if x>=2:
            #               for c in costs_by_value[x-1]:
            #                   update cnt_tree: add 1 at c
            #                   update sum_tree: add c at c
            #           ... then process candidate x ...

            #   But note: the set Y for x=1 is empty? Then we skip the update for x=1.

          Then we output the minimal candidate_ans.

        However, note: it is possible that we cannot form any perfect array? Then we must output a number? 
          Actually, the problem says "delete some elements", and it is possible that we delete everything? Then the array is empty. 
          But the condition: for an empty array, the maximum element is undefined? 

          The problem states: the resulting array must be perfect. The condition requires the maximum element to exist and be the majority.

          The problem does not specify for empty array. But note: the majority condition: 
             count(max) > |V| - count(max) 
          For |V|=0: the condition is 0>0? false.

          So we cannot have an empty array.

          What if we delete everything? then the array is empty -> not perfect.

          Then we must leave at least one element? 

          How do we handle that?

          Note: our candidate x must be one of the numbers in the array? But we are iterating over x from 1 to MAX_V. However, we skip if F[x]==0? 

          And if we choose a candidate x, then we must keep at least one x? 

          Also, condition: k' = (number of x we keep) >= 1? 

          But in our step2, if D0==0, we don't delete any x? Then we keep at least one x? 

          But what if we delete all x? Then k'=0, and then condition: 0 > (non-x count) -> false.

          So we must keep at least one x.

          How do we enforce that? 

          In our formulation for step2: we are allowed to delete any subset of x? But note: we require k' = k0 - dx >= 1? 

          Actually, we don't explicitly enforce that. 

          However, note: the condition k' > t' implies k'>=1 (since if k'=0 then the condition becomes 0>t' -> which requires t'<0 -> impossible). 

          Therefore, we must have k'>=1. 

          In our formulation for candidate x, we require:

              k' = k0 - dx >= 1   => dx <= k0-1.

          So our loop for b (dx) is from 0 to k0-1? which is dx in [0, k0-1] -> so k' in [1, k0]. 

          So we are safe.

        One more issue: what if for candidate x, we cannot achieve the condition? 
          Condition: we require a = D0+b <= t0? 
          But as argued: D0 = t0 - k0 + 1, then a = t0 - k0 + 1 + b, and b is at most k0-1, so a <= t0 - k0 + 1 + k0-1 = t0. 
          So a<=t0 always holds? 

          Therefore, we can always form the array for candidate x? 

          But note: if we choose candidate x and the fixed cost is computed, and we can always form the condition for step2? 

          However, what if there are no elements at all? But we have at least one x? because we skip if F[x]==0.

          So for every candidate x that appears in the array, we can form a perfect array? 

          But what if we choose a candidate x that is not the maximum? and then we delete the elements above x, and then we form the condition? 

          Therefore, we iterate over every distinct x that appears? 

        However, note: the problem does not require the candidate x to be the maximum? We choose x arbitrarily? 

        But the condition for the final array: the maximum must be x? and we delete everything above x. 

        Therefore, we must consider every candidate x that appears? 

        But note: if an element x appears, then we can consider candidate x? 

        However, what if we choose candidate x that does not appear? Then we cannot have any x? Then we must delete everything? and then we have an empty array -> not allowed. 

          So we skip if F[x]==0.

        Therefore, the algorithm:

          Initialize candidate_ans = a big number (like 10**18)

          Initialize Fenwick trees for counts and sums (for the entire cost domain [1, MAX_C]) with zeros.

          For x from 1 to MAX_V:

             if x>=2:
                 for each cost c in costs_by_value[x-1]:
                    update cnt_tree: add 1 at position c
                    update sum_tree: add c at position c

             if F[x] == 0: continue

             fixed_cost = suffix_sum[x+1]   # cost to delete all elements > x

             k0 = F[x]   # count of x
             t0 = total_count_below[x]   # total count of elements with value < x

             D0 = max(0, t0 - k0 + 1)

             step2 = 0   # if D0==0
             if D0 == 0:
                 total_cost = fixed_cost
                 candidate_ans = min(candidate_ans, total_cost)
             else:
                 # We'll iterate b from 0 to k0-1 (dx = b, the number of x we delete)
                 best_step2 = 10**18
                 for b in range(0, k0):   # b: number of x we delete, from 0 to k0-1
                     a = D0 + b   # we need to delete a non-x? 
                     # We know a<=t0, as argued.

                     # Query the Fenwick trees for the sum of the smallest a elements in Y (the set of elements with value < x)
                     s_nonx = query_kth_sum(a)   # using the Fenwick trees: we have a function that returns the sum of the smallest a elements.

                     # Get the cost for deleting b of the x: 
                     s_x = prefix_x_arr[x][b]   # the sum of the smallest b elements in the set of x

                     total_step2 = s_nonx + s_x
                     if total_step2 < best_step2:
                         best_step2 = total_step2

                 total_cost = fixed_cost + best_step2
                 candidate_ans = min(candidate_ans, total_cost)

          Print candidate_ans

        However, note: it is possible that there is no candidate x that yields a perfect array? 
          Actually, we have considered every distinct x that appears. 

          But what if we choose x to be the maximum value? Then we don't delete any element above? 

          And we have shown that for each candidate x that appears, we can form a perfect array? 

          Therefore, we output candidate_ans.

        But note: what if the entire array is deleted? we skip that because we require at least one x? 

          However, if no candidate x works? For example, if the array has only one element: 
            Then x = that element, then:
                fixed_cost = suffix_sum[x+1] = 0 (if x is the maximum, then nothing above)
                k0 = 1, t0 = 0 -> D0 = max(0,0-1+1)=max(0,0)=0 -> total_cost=0.

          So that works.

        Complexity: 
          The outer loop: O(MAX_V) = 300000
          The inner loop over b: for each candidate x, we do k0 iterations. The total over all x: sum_{x} k0 = n = 300000.

          However, inside the inner loop, we do a query: query_kth_sum(a) which is O(log^2(MAX_C))? 

          Then total operations: O(n * log^2(MAX_C)) = 300000 * (log2(300000))^2 ~ 300000 * (18)^2 = 300000 * 324 = 97.2e6 -> acceptable.

        However, we can optimize the query to O(log(MAX_C)) by storing the Fenwick trees in a way that we can get the kth element in O(log(MAX_C)) without binary search? 

          Actually, we can use a Fenwick tree to do a "kth smallest element" in O(log(MAX_C)) by walking the tree? 

          We can store the Fenwick tree for counts as a Fenwick tree that supports:

               find_kth(k): returns the smallest index i such that the prefix sum (for counts) from 1 to i >= k.

          Then we can do:

               T = find_kth(a)   # in O(log(MAX_C))

               Then the sum of the smallest a elements = 
                   (prefix_sum_sum_tree[T-1]) + T * (a - prefix_sum_cnt_tree[T-1])

          But we don't have prefix_sum_cnt_tree and prefix_sum_sum_tree stored? 

          Actually, we can store the Fenwick trees for counts and sums. Then:

               prefix_sum_cnt_tree[i] = cnt_tree.range_query(1, i)
               prefix_sum_sum_tree[i] = sum_tree.range_query(1, i)

          But we can compute:

               cnt1 = cnt_tree.range_query(1, T-1)
               sum1 = sum_tree.range_query(1, T-1)
               then the number of elements at T we need = a - cnt1
               then total_sum = sum1 + T * (a - cnt1)

          How to get T? 
               We can do: 
                 T = find_kth(a)   # which we can do by traversing the Fenwick tree for counts? 

          How to implement find_kth? 

            Fenwick tree for counts: we have an array tree_cnt. Then we can traverse:

                def find_kth(k):
                    idx = 0
                    bit_mask = 1 << MAX_BITS
                    s = 0
                    for i in range(MAX_BITS, -1, -1):
                        nidx = idx + (1<<i)
                        if nidx > MAX_C: 
                            continue
                        if s + tree_cnt[nidx] < k:
                            s += tree_cnt[nidx]
                            idx = nidx
                    return idx+1   # because our Fenwick tree is 1-indexed? and we want the next index.

            But note: Fenwick tree for kth element: 

            Alternatively, we can build a Fenwick tree that supports kth element query? 

          We'll do:

            We have the Fenwick tree for counts (tree_cnt) and we want the smallest index such that prefix_sum>=k.

            We can do:

                idx = 0
                s = 0
                bit = 1 << (ceil(log2(MAX_C)))
                while bit:
                    nidx = idx+bit
                    if nidx <= MAX_C:
                        if s + tree_cnt[nidx] < k:
                            s += tree_cnt[nidx]
                            idx = nidx
                    bit //= 2
                return idx+1

          Then we can get T = idx+1? 

          Actually, we want the smallest index T such that the cumulative count >=k. Then:

                T = idx+1

          Then we can get:

                cnt1 = (if T-1>=1 then query_cnt(1, T-1) else 0)
                sum1 = (if T-1>=1 then query_sum(1, T-1) else 0)

          But we can store the Fenwick trees so that we can query the prefix sums quickly? 

          However, we can combine the two: 

                T = find_kth(a)   # O(log(MAX_C))
                cnt1 = query_cnt(1, T-1)   # O(log(MAX_C))
                sum1 = query_sum(1, T-1)   # O(log(MAX_C))

          Then total for one query: 3 * log(MAX_C) -> which is acceptable.

          Then the entire algorithm: O(n * log(MAX_C)) = 300000 * 20 = 6e6.

        Therefore, we implement:

          We have two Fenwick trees: one for counts and one for sums.

          We also implement:
            update(index, delta_count, delta_sum) for both trees.

          And we implement:
            find_kth(k): for the count tree to find the smallest index T such that prefix_sum(1..T) >= k.

          Then query_cnt(l, r) and query_sum(l, r) for the Fenwick trees? 

          Actually, we only need prefix queries: query(1, i). So we can store the Fenwick trees for prefix queries.

          Alternatively, we can precompute the entire Fenwick tree for prefix? 

          But we are updating as we go? 

          We'll implement Fenwick trees that support:

            FenwickTree:
               __init__(n)
               update(i, delta)
               query(i): returns prefix sum [1, i]

          Then:

            def query_range(l, r):
                if l>r: return 0
                return query(r) - query(l-1)

          Then for a given a:

            T = find_kth(a)   # using the count tree? Actually, we can use the Fenwick tree for counts to do find_kth? 

          How to do find_kth in a Fenwick tree? 

            We can use the standard method:

            int find(int cumu) {
                int idx = 0;
                for (int bit = 1 << max_bits; bit; bit >>= 1) {
                    int nidx = idx + bit;
                    if (nidx > n) continue;
                    if (tree_cnt[nidx] < cumu) {
                        cumu -= tree_cnt[nidx];
                        idx = nidx;
                    }
                }
                return idx+1;
            }

          But note: the Fenwick tree for counts is stored in the Fenwick tree structure? 

          We'll create a Fenwick tree class that also supports the kth element? 

          Alternatively, we can use a separate Fenwick tree for counts and then use the standard Fenwick tree for prefix queries? 

        Implementation of Fenwick tree for counts and sums:

          We'll have two Fenw trees: 
            cnt_tree = Fenw(MAX_C)
            sum_tree = Fenw(MAX_C)

          And for the kth element, we can write a function in the Fenw tree? 

          Actually, we can write:

            class Fenw:
                def __init__(self, size):
                    self.n = size
                    self.tree = [0]*(self.n+1)

                def update(self, index, delta):
                    while index <= self.n:
                        self.tree[index] += delta
                        index += index & -index

                def query(self, index):   # prefix sum [1, index]
                    s = 0
                    while index:
                        s += self.tree[index]
                        index -= index & -index
                    return s

                def range_query(self, l, r):
                    if l>r: return 0
                    return self.query(r) - self.query(l-1)

          Then we write a separate function for kth? 

          Alternatively, we can add a method for kth? 

          How about:

            def find_kth(self, k):   # find the smallest index i such that query(i) >= k
                idx = 0
                bit = 1
                while bit < self.n:
                    bit <<= 1
                bit >>= 1
                s = 0
                res = 0
                while bit:
                    nxt = idx + bit
                    if nxt <= self.n:
                        if s + self.tree[nxt] < k:
                            s += self.tree[nxt]
                            idx = nxt
                    bit //= 2
                return idx+1

          But note: the Fenwick tree in the standard implementation does not store the entire array? 

          Actually, we can use the tree to do the binary search? 

          Alternatively, we can do:

            def find_kth(cnt_tree, k):   # using the Fenw tree structure for counts
                # We traverse the tree from the top.
                pos = 0
                s = 0
                bit = 1 << (self.n.bit_length()-1)
                while bit:
                    next_pos = pos + bit
                    if next_pos <= self.n:
                        if s + cnt_tree.tree[next_pos] < k:
                            s += cnt_tree.tree[next_pos]
                            pos = next_pos
                    bit //= 2
                return pos+1

          But we don't have the Fenw tree stored in a way that we can traverse the nodes? 

          Actually, we can do without the tree structure? We can use the standard Fenwick tree kth element method? 

          I'll write a separate function that uses the Fenw tree's tree array? 

          Actually, we can do:

            def find_kth(cnt_tree, k):
                # cnt_tree is a Fenw tree for counts? 
                # We want the smallest index T such that prefix_sum[1..T] >= k.
                # We use the standard Fenwick tree kth element algorithm? 
                s = 0
                pos = 0
                LOGN = cnt_tree.n.bit_length()
                for i in range(LOGN-1, -1, -1):
                    next_pos = pos + (1<<i)
                    if next_pos > cnt_tree.n:
                        continue
                    if s + cnt_tree.tree[next_pos] < k:
                        s += cnt_tree.tree[next_pos]
                        pos = next_pos
                return pos+1

          However, note: the standard Fenwick tree for kth element is implemented by storing the tree in a flat array? 

          Actually, the tree is stored in an array. The above method is known.

        Steps for query_kth_sum(a):

            T = cnt_tree.find_kth(a)   # the smallest index such that prefix_sum(1..T)>=a

            cnt1 = cnt_tree.query(T-1)   # total count in [1, T-1]
            sum1 = sum_tree.query(T-1)   # total sum in [1, T-1]

            cnt_at_T = cnt_tree.range_query(T, T)   # or we can do: cnt_tree.query(T) - cnt_tree.query(T-1) -> but we don't store the array? 
            # Actually, we can get the count at T by: 
            #   cnt_at_T = cnt_tree.range_query(T, T)   # which we can do by query(T) - query(T-1)

            # But note: we don't need the entire count at T? We need: the number of elements at T we take = min(a - cnt1, cnt_at_T) 
            # But by the definition of T: 
            #   cnt_tree.query(T) >= a, and cnt_tree.query(T-1) < a.
            #   So the number we take at T = a - cnt1.

            s = sum1 + T * (a - cnt1)

            return s

        However, note: the Fenwick tree for counts and sums are built with the entire set Y. 

        But we update the Fenw trees as we add the elements with value = x-1. 

        This function is called during the candidate x processing.

        Therefore, the entire algorithm:

          Precomputation as above.

          Initialize:
            cnt_tree = Fenw(MAX_C)
            sum_tree = Fenw(MAX_C)

          candidate_ans = a big number

          For x from 1 to MAX_V:

            # Add elements with value = x-1 (if x>=2) to the Fenw trees.
            if x>=2:
                for c in costs_by_value[x-1]:
                    cnt_tree.update(c, 1)
                    sum_tree.update(c, c)

            if F[x] == 0:
                continue

            fixed_cost = suffix_sum[x+1]

            k0 = F[x]
            t0 = total_count_below[x]   # which we precomputed as the total count of elements with value in [1, x-1]

            D0 = max(0, t0 - k0 + 1)

            if D0 == 0:
                total_cost = fixed_cost
                candidate_ans = min(candidate_ans, total_cost)
            else:
                best_step2 = 10**18
                # We iterate b from 0 to k0-1:
                for b in range(0, k0):
                    a = D0 + b   # number of non-x to delete? Actually, we need to delete at least a non-x? But note: we are going to compute the minimal cost for deleting a non-x (the smallest a) and b x's (the smallest b).

                    # Query the sum for the smallest a non-x in Y:
                    #   If a==0, then s_nonx=0. But a = D0+b >= D0>=1? so a>=1.
                    #   How to query? 
                    #       Step 1: T = the smallest cost such that the cumulative count in cnt_tree >= a.
                    if a > cnt_tree.query(MAX_C): 
                         # This should not happen because the total count in Y is t0, and a<=t0? 
                         # But we have updated the Fenw trees for value in [1, x-1] -> the total count should be t0.
                         # So we break if a>t0? but we know a<=t0.
                         break
                    T = find_kth(cnt_tree, a)   # We have to write this function that uses the Fenw tree structure? 

                    # But we don't have the Fenw tree stored as an array for the tree? We only have the Fenw tree class that supports update and query.

                    # How to implement find_kth? We can do a binary search over [1, MAX_C] using the query? 
                    #   We do:

                    #       low = 1
                    #       high = MAX_C
                    #       while low < high:
                    #          mid = (low+high)//2
                    #          if cnt_tree.query(mid) >= a:
                    #             high = mid
                    #          else:
                    #             low = mid+1
                    #       T = low

                    #   Then we get T.

                    #   Then:
                    #        cnt1 = cnt_tree.query(T-1)   # count of elements in [1, T-1]
                    #        sum1 = sum_tree.query(T-1)   # sum of elements in [1, T-1]
                    #        s_nonx = sum1 + T * (a - cnt1)

                    #   However, note: we must be cautious: what if there are multiple elements at T? 
                    #        We have taken the entire [1, T-1] and then (a - cnt1) elements at T.

                    #   But the sum_tree.query(T) - sum_tree.query(T-1) is the total sum of elements at T? 
                    #        But we don't need that: we only take (a-cnt1) of them, and we take the smallest? 
                    #        Actually, they are all T? 

                    #   So it is correct.

                    #   But the binary search is O(log(MAX_C)) per query? 
                    #   Then total: O(n * log(MAX_C)) = 300000 * 20 = 6e6.

                    #   So we do:

                    low, high = 1, MAX_C
                    while low < high:
                        mid = (low+high)//2
                        if cnt_tree.query(mid) >= a:
                            high = mid
                        else:
                            low = mid+1
                    T = low

                    cnt1 = cnt_tree.query(T-1)   # if T-1>=1, else 0? 
                    # But if T==1, then T-1=0 -> we define query(0)=0.
                    cnt1 = cnt_tree.query(T-1) 
                    sum1 = sum_tree.query(T-1)

                    s_nonx = sum1 + T * (a - cnt1)

                    s_x = prefix_x_arr[x][b]   # the cost for deleting b of the x's (the smallest b)

                    total_step2 = s_nonx + s_x
                    if total_step2 < best_step2:
                        best_step2 = total_step2

                total_cost = fixed_cost + best_step2
                candidate_ans = min(candidate_ans, total_cost)

          Print candidate_ans

        However, note: we must be cautious with T=0? 

          If a==0, then we skip? But D0>=1 and b>=0, so a>=1.

        Also, we must be cautious: the Fenw tree query(0) returns 0? 

          We implemented Fenw_tree.query(i) for i from 1 to MAX_C? 
          We should make sure that if we call query(0), it returns 0.

          We can do:

            def query(self, i):
                if i==0: return 0
                s = 0
                while i:
                    s += self.tree[i]
                    i -= i & -i
                return s

          Or we can avoid calling with T-1=0? 

        Let's test with a=1: 
            T: the smallest index such that cnt_tree.query(T)>=1 -> T will be the smallest cost that has at least one element? 
            Then cnt1 = cnt_tree.query(T-1) = 0.
            sum1 = 0.
            s_nonx = 0 + T * (1) = T.

        Correct.

        But note: the element at T might have cost T? 

        Actually, we stored the elements by their cost. 

        Therefore, the algorithm is complete.

        Let's test with the sample:

          Sample Input #1:
             4
             A = [5, 3, 3, 3]
             B = [3, 2, 2, 2]

          distinct values: 3 and 5.

          Precomputation:

            F[3]=3, F[5]=1.
            costs_by_value[3] = [2,2,2] -> sorted: [2,2,2]; prefix_x_arr[3] = [0,2,4,6] 
            costs_by_value[5] = [3]; prefix_x_arr[5] = [0,3]

            sum_cost[3]=6, sum_cost[5]=3.

            suffix_sum: 
                suffix_sum[6]=0
                suffix_sum[5]=sum_cost[5]=3
                suffix_sum[4]=sum_cost[4]+suffix_sum[5]=0+3=3
                suffix_sum[3]=sum_cost[3]+suffix_sum[4]=6+3=9
                suffix_sum[2]= ... but we don't need beyond x=3 and x=5.

          We iterate x from 1 to 5.

          x=1: F[1]=0 -> skip.

          x=2: we add value=1: but there is no value=1 -> skip. Then F[2]=0 -> skip.

          x=3: 
             We add value=2: none -> so we skip the update.
             Then fixed_cost = suffix_sum[4] = 3 (because we delete elements >3 -> only 5 is above 3, cost=3)
             k0 = F[3]=3, t0 = total_count_below[3] = F[1]+F[2] = 0 -> D0 = max(0,0-3+1)=max(0,-2)=0.
             total_cost = fixed_cost = 3.

          candidate_ans=3.

          x=4: skip.

          x=5:
             Before: we add value=4: none.
             fixed_cost = suffix_sum[6]=0
             k0=1, t0 = F[1]+F[2]+F[3]+F[4] = 0+0+3+0=3
             D0 = max(0, 3-1+1)=max(0,3)=3
             Then we iterate b in [0,0] (since k0=1, b from 0 to 0):
                 a = D0+b = 3
                 Now, we have built the Fenw trees: 
                   We added value=1 at x=2: none.
                   value=2 at x=3: none.
                   value=3 at x=4: we added at x=4? But for x=5, we add value=4 at the beginning of the loop? Then we haven't added value=3? 

             How do we add value=3? 
                 We add value=x-1 at the beginning of the loop for x. 
                 For x=5: we add value=4? But we don't have value=4. 
                 Then we haven't added value=3? 

          Correction: we add value=x-1 at the beginning of the loop for x. 
             For x=5: we add value=4? But we don't have any element with value=4 -> skip.

          Then the set Y for candidate x=5 is the elements with value in [1,4]? which includes value=3? 
          But we haven't added value=3? 

          Why? 
             We add value=x-1 at the beginning of the loop for x. 
             We added value=1 at x=2? 
             value=2 at x=3? 
             value=3 at x=4? 
             value=4 at x=5? 

          So for x=5, we have added value=4 (but none) and we have not added value=3? 

          This is a problem.

        How to fix? 

          The set Y for candidate x should include all elements with value < x. 
          But we are adding only value=x-1 at x. 

          We should add all values < x? 

          But we are iterating x in increasing order. We can add the value=x-1 at x, and then the set Y accumulates? 

          Actually, we have added:

             x=1: no update.
             x=2: add value=1 -> then Y has value=1.
             x=3: add value=2 -> then Y has value=1,2.
             x=4: add value=3 -> then Y has value=1,2,3.
             x=5: add value=4 -> then Y has value=1,2,3,4.

          But in our sample, the elements with value=3 are added at x=4? 

          Then at x=5, the set Y is built? 

          So for candidate x=5, we have the entire set Y: which includes value=3? 

          Therefore, the sample x=5: 
              Y: the three 3's with cost [2,2,2] -> so the Fenw trees have been updated at x=4 (when we processed x=4) for value=3? 

          But note: at x=4, we did:

              if x>=2: add value=3 -> we add the three elements with value=3: each cost=2.

          Then the Fenw trees: 
             cnt_tree: at cost=2: count=3
             sum_tree: at cost=2: total=6

          Then for x=5:

             fixed_cost = 0
             k0=1, t0= total_count_below[5] = F[1]+F[2]+F[3]+F[4] = 0+0+3+0=3
             D0=3
             b=0: a = 3
                 Query: the smallest 3 elements in Y: 
                    The Fenw trees: 
                         cnt_tree: 
                            query(1)=0, query(2)=3 -> so T=2.
                         cnt1 = cnt_tree.query(1) = 0
                         sum1 = 0
                         s_nonx = 0 + 2*(3-0)=6
                 s_x = prefix_x_arr[5][0] = 0   (because we delete 0 of the 5's)
                 total_step2 = 6
                 total_cost = 0+6 = 6.

             candidate_ans = min(3, 6) -> 3.

          So we output 3.

        Therefore, the algorithm is correct for sample1.

        Sample Input #2 is more complex, but we trust the logic.

        However, note: the problem constraints: n up to 300000, and the Fenw tree updates and queries are O(log(MAX_C)), and the inner loop over b is O(n) in total.

        We'll code accordingly.

        But note: we must precompute total_count_below? 

          total_count_below[x] = F[1]+F[2]+...+F[x-1]   -> we can precompute an array.

        Steps:

          MAX_V = 300000
          Precomputation for F, sum_cost, and costs_by_value.

          Precompute suffix_sum: 
             suffix_sum = [0]*(MAX_V+3)
             for i in range(MAX_V,0,-1):
                 suffix_sum[i] = suffix_sum[i+1] + sum_cost[i]

          Precompute total_count_below: 
             total_count_below[1] = 0
             for i in range(2, MAX_V+1):
                 total_count_below[i] = total_count_below[i-1] + F[i-1]

          Precompute for each value x that appears: 
             sort the list of costs for x, and compute the prefix sum array.

          Initialize Fenw trees for counts and sums (size=MAX_C, where MAX_C=300000).

          candidate_ans = 10**18

          For x in range(1, MAX_V+1):

             # Add the elements with value = x-1: 
             if x>=2:
                 for cost_val in costs_by_value[x-1]:
                     cnt_tree.update(cost_val, 1)
                     sum_tree.update(cost_val, cost_val)

             if F[x]==0: continue

             fixed = suffix_sum[x+1]
             k0 = F[x]
             t0 = total_count_below[x]

             D0 = max(0, t0 - k0 + 1)

             if D0==0:
                 total_cost = fixed
                 candidate_ans = min(candidate_ans, total_cost)
             else:
                 best_step2 = 10**18
                 # b from 0 to k0-1
                 for b in range(0, k0):
                     a = D0 + b
                     # If a is greater than the current total count in the Fenw tree, break? But we know the total count in Y is t0, and a<=t0? 
                     #   However, we have updated the Fenw trees for values in [1, x-1] -> the total count is t0, and a<=t0 -> so we skip the check.
                     # Binary search for T: 
                     low, high = 1, MAX_C
                     while low < high:
                         mid = (low+high)//2
                         if cnt_tree.query(mid) >= a:
                             high = mid
                         else:
                             low = mid+1
                     T = low
                     cnt1 = cnt_tree.query(T-1)   # returns 0 if T-1<1
                     sum1 = sum_tree.query(T-1)
                     s_nonx = sum1 + T * (a - cnt1)

                     s_x = prefix_x_arr[x][b]   # the prefix sum for the x set: we precomputed.

                     total_step2 = s_nonx + s_x
                     if total_step2 < best_step2:
                         best_step2 = total_step2

                 total_cost = fixed + best_step2
                 candidate_ans = min(candidate_ans, total_cost)

          Print(candidate_ans)

        But note: we must be cautious: the Fenw tree for the entire set Y is built as we iterate x from 1 to MAX_V. 

        This solution should be O(n log MAX_C) per candidate x in the inner loop? But the inner loop over b: total iterations over all x is O(n). 
        And each iteration does a binary search (O(log(MAX_C)) and two Fenw tree queries (each O(log(MAX_C))). 

        So total time: O(n * (log(MAX_C)) = 300000 * 20 = 6e6, which is acceptable.

        However, note: the binary search is O(log(MAX_C)) per iteration? Then total operations: 300000 * 20 = 6e6.

        But note: the inner loop runs k0 times per candidate x, and the total over x is n=300000, so the total number of iterations is 300000, and each iteration does 3*log(MAX_C) operations? 

        Then 300000 * 20 = 6e6 operations, which is acceptable.

        We'll hope it runs in 1 second.

        Let's run the sample #2? 

          But it is complex, we trust the logic.

        Note: the Fenw tree queries and updates are efficient.

        We output the code accordingly? 

        But note: the problem says memory 1024 MB, and we are storing arrays of size up to 300000, and the Fenw trees are of size 300000, so it is acceptable.

        We'll implement.

        However, we note: the worst-case total_count_below[x] can be 300000, and the inner loop for x with large k0? 

          But the total over all x: the inner loop runs k0 times per candidate x, and the sum of k0 over x is n, so 300000 iterations.

        Therefore, we write the solution accordingly.

        Let's hope.

        We'll output the answer.

        Note: we must be cautious that the Fenw_tree.query(0) returns 0. We can implement:

            def query(self, i):
                if i==0: return 0
                s = 0
                while i>0:
                    s += self.tree[i]
                    i -= i & -i
                return s

        But in the Fenw tree, we typically index from 1 to n. So i=0 is not updated? 

        We can define:

            We'll create Fenw trees of size MAX_C (300000), and indices from 1 to MAX_C.

            Then query(0) is defined to be 0.

        In the update and query functions, we assume indices from 1 to MAX_C.

        For the binary search, we use [1, MAX_C] for low and high.

        This should be safe.

        We'll run the sample #2? 

          Input: 
            15
            A = [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]
            B = [8, 6, 4, 7, 5, 1, 3, 4, 9, 8, 5, 4, 1, 2, 2]

          Expected output: 34.

          How to test? 

          We'll compute candidate_ans for each distinct x.

          But it is long, we trust the code.

        We output the code accordingly.

        However, note: the problem has time limit 1.0s and n=300000, and our inner loop runs 300000 iterations (in total) and each iteration does about 20*3=60 operations? 300000*60=18e6 operations -> acceptable.

        We write the solution.

        IMPORTANT: This is the editorial, so we do not write the actual code. But we have described the algorithm in detail.

        Summary:

          We consider each distinct integer x in the range [1, MAX_V] as a candidate for the maximum of the resulting array.

          Steps for candidate x:
            Step 1: Delete all elements with value > x. The cost is fixed and precomputed by a suffix sum array.
            Step 2: For the remaining elements (which are <= x), we have:
                     k0 = frequency of x
                     t0 = total frequency of elements with value < x
            Condition: The number of x's we keep (k0 - dx) must be > the number of non-x's we keep (t0 - dy), 
                       which is equivalent to: (k0 - dx) > (t0 - dy)  => dy - dx > t0 - k0.
            We define D0 = max(0, t0 - k0 + 1). If D0==0, then we don't need to delete any additional element (step2 cost=0).
            If D0>0, then we need to delete at least D0 net non-x (in the sense of non-x deletions minus x deletions).

            We minimize the cost for step2 by iterating over the number of x's we delete (b, which is from 0 to k0-1) and then the number of non-x deletions is a = D0 + b.

            The cost for step2 for a fixed b is:
                  cost = (sum of the smallest a non-x elements) + (sum of the smallest b x elements)

            We maintain the set of non-x elements (which are the elements with value < x) in two Fenwick trees: one for counts and one for the sum of costs. 
            The set is built incrementally as we iterate x from 1 to MAX_V (by adding the elements with value = x-1 at the beginning of the loop for x).

            We precomputed for each value x the sorted list of costs and the prefix sum array for the set of x.

          The minimal total cost over all candidate x is the answer.

        Why it works: 
          We cover all candidates for the maximum of the resulting array. 
          The condition for a perfect array is satisfied by the candidate x and the deletions we perform.
          The cost is minimized by considering the cheapest deletions.

        Complexity: O(n * log(MAX_C)) which is acceptable for n=300000.

        We hope the editorial is clear.

        Note: The sample input #1 works as shown, and sample input #2 should output 34.

        We output the answer.