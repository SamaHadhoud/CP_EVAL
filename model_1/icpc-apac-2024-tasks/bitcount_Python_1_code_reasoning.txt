 Okay, we are to check for a starting non-negative integer x such that the sequence of popcounts from x to x+n-1 equals the given sequence a[0..n-1].

 Important constraints:
   - t up to 1000, but the sum of n <= 500,000, so we can process each test case in O(n) or O(n log something) as long as the total n is 500k.

 However, note that the numbers x we are looking for might be very large (like the sample: 2305843009213693949, which is 2^61 + 2^60 - 1? actually it's 2^61 - 1, but wait: 2^61-1 is 2305843009213693951, and the sample output is 2305843009213693949).

 Observing the problem:

 We know that the popcount function p(x) is the number of ones in the binary representation. The sequence of consecutive integers has known properties:

   p(x) and p(x+1) are related by the carry chain when adding 1.

 How does adding 1 affect the popcount?
   When we add 1 to x, we flip a sequence of consecutive ones at the least significant bits. For example:
        x = ...01111 -> x+1 = ...10000
   The popcount of x+1 is p(x) - k + 1, where k is the number of consecutive ones at the end.

 Therefore, we have:
      p(x+1) = p(x) - t + 1, where t is the number of trailing ones in x.

 But note: we are to match a given sequence a[0], a[1], ..., a[n-1] with p(x), p(x+1), ... , p(x+n-1).

 We can express the condition for consecutive terms:
      a[i] = p(x+i)

 And we know that:
      a[i+1] - a[i] = (p(x+i+1) - p(x+i)) must be either 1 - (some positive integer) or possibly 1, 0, negative, etc.

 Specifically, the difference d_i = a[i+1] - a[i] must be in the set {1, -t, -t+1, ... }? Actually, the known relation is:

      p(x+1) = p(x) - t + 1,   where t is the number of trailing ones.

 Therefore, we must have:
      a[i+1] - a[i] = 1 - t_i, where t_i is an integer at least 1 (since t is the number of trailing ones, at least 1).

 So the differences can only be: 0 (if t_i=1 then 1-1=0), negative (if t_i>1 then 1-t_i <= -1), or positive? Actually the positive case is only 1: when t_i=0? But wait: if x has no trailing ones (i.e., the last bit is 0), then adding one just flips the last bit: so p(x+1)=p(x)+1? Actually, no: if the last bit is 0, then we flip the last bit from 0 to 1. Then the popcount increases by 1.

 Therefore, the difference can be:
      If the last bit is 0: then p(x+1) = p(x) + 1 -> difference = +1.
      If the last k bits are 1 (k>=1): then we flip k ones to zeros and then a 0 to 1? Actually, the process: ...01...1 (with k ones) becomes ...10...0. The popcount change: we remove k ones and add one one -> so change = -k + 1.

 Hence, the difference d_i = a[i+1] - a[i] must be either:
      +1, or
      a negative integer: -k+1, for some k>=1 -> so negative integers that are at most 0? Actually k>=1: then -k+1 <= 0.

 But note: k can be arbitrarily large? However, note that the popcount of x is at most 60 (as given that a_i is between 0 and 60). Therefore, k cannot exceed the current popcount? Actually, k is the number of trailing ones, and the entire representation might have more than 60 bits? But the condition that a_i are bounded by 60 implies that the numbers x+i we are considering must not have more than 60 ones. However, the numbers themselves might be huge (with many bits) but the number of ones is bounded.

 How to use this?
   Condition on the consecutive differences: 
        d_i = a[i+1] - a[i] must be either 1 or at most 0. Moreover, if d_i <= 0, then we must have d_i = 1 - k for some k>=1. Actually, k = 1 - d_i, so k must be at least 1 (so d_i <= 0) and k must be an integer.

   Also, we can note that the popcount of x+i must be a[i]. Therefore, if we are at a state with a known x (or a candidate x) we can simulate the next? But x might be huge.

 Alternate approach:

 We know that the entire sequence a[0..n-1] must satisfy the consecutive differences condition. So we can first check:

   For i from 0 to n-2:
        if a[i+1] - a[i] not in {1, 0, -1, -2, ... }? Actually, it must be <= 1. Specifically, the only positive difference allowed is +1. For negative differences, there is no lower bound? Actually, the value of k can be arbitrarily large? But note: the popcount of x+i is a[i], which is at least the number of trailing ones k? So k <= a[i]. Therefore, the difference d_i = a[i+1]-a[i] = 1 - k must satisfy: k = 1 - d_i, and we require 1 <= k <= a[i] (since we can't have more trailing ones than the total number of ones). Therefore:

        If d_i > 1: then invalid.
        If d_i <= 0: then we must have k = 1 - d_i, and k must be at least 1 and at most a[i] (the current popcount).

        Also, if d_i==1, then we don't require a condition on k? Actually, in that case k=0? But wait: when we have a trailing zero, then k=0? But the relation was for trailing ones. Actually, the case of trailing zeros: we flip a single zero to one? But that's only if the last bit is zero. Then k (trailing ones) is 0? Actually, no: the trailing ones count is the consecutive ones from the least significant bit. If the last bit is zero, then trailing ones count is 0? Then the formula: p(x+1)=p(x) - 0 + 1? That gives p(x+1)=p(x)+1. So that matches.

        However, note: the formula for the trailing ones is defined when we have at least one trailing one? Actually, when there are no trailing ones, we have k=0. So the formula: p(x+1)=p(x) - 0 + 1? Then difference=1.

        But also note: if we have a block of zeros? Actually, we only flip the last zero to one and then stop. So the trailing ones count for the flip operation is the consecutive ones that are about to be flipped? Actually, no: the trailing ones count is the consecutive ones starting at the least significant bit. If the last bit is zero, then the trailing ones count is 0? Actually, that's not standard. The trailing ones are the consecutive ones starting from the least significant bit. So if the last bit is 0, then trailing ones count is 0.

        Therefore, the relation holds with k being the trailing ones count (which can be 0, and then we get +1).

        However, note: if k=0, then the formula gives p(x+1)=p(x)+1. So the difference is 1.

        But if k>=1, then the difference is 1-k.

        So we have:

          d_i = a[i+1] - a[i] must be either 1 or at most 0.

          Additionally, if d_i <= 0, then we require that k = 1 - d_i is at most a[i] (because we have a[i] ones, so we can't have k>a[i]) and at least 1.

        Therefore, we can do a first validity check:

          for i in range(n-1):
            d = a[i+1] - a[i]
            if d > 1:
                return -1   (impossible)
            if d <= 0:
                k = 1 - d   # because d = 1 - k -> k = 1 - d
                if k < 1:   # actually k>=1 always? because d<=0 -> k=1-d>=1, since d<=0 then k>=1. So we don't need to check k>=1? But k must be at most a[i]?
                if k > a[i]:
                    return -1   # because the current popcount a[i] must be at least k.

        However, note: what if d_i is negative and 1-d_i is not an integer? Actually, d_i is integer, so k=1-d_i is integer.

        But wait: what if d_i=2? Then we break. So we only allow d_i in the set {1, 0, -1, -2, ... } and with the condition for d_i<=0: k=1-d_i <= a[i].

        This check is O(n) per test case, and the total n is 500k, so we can do that.

        However, even if the entire sequence passes this check, it does not guarantee existence? We need to find an x that matches.

 How to find the smallest x?

 Insight: the entire sequence of popcounts for consecutive numbers is determined by the starting x and the carries that occur. The problem has been studied in literature? 

 Alternate Insight: the value x must satisfy that for each i, the popcount of x+i is a[i]. How to express the constraints?

   We can consider the binary representation and the process of adding 1. However, we note that the constraints on the consecutive differences are local. But to find x, we need to consider the entire sequence.

   We can use the following:

      We know that the condition for each i: 
          a[i] = p(x+i)

      And we know the recurrence for consecutive numbers: 
          x+i+1 = (x+i) + 1.

      Therefore, we can model the binary representation and the carry propagation.

   However, note that x might be huge (like 2^60 or more). We cannot iterate over x.

   Instead, we can use a state machine that tracks the "carry" effect and the constraints on the bits.

   Alternatively, we can use known properties of the popcount for consecutive numbers: 

      There is a known fact: the sequence p(x), p(x+1), ... is periodic with period 2^b for some b? But the entire sequence of n consecutive numbers might span many powers of two.

   Another idea: 

      We can try to reconstruct the binary representation of x from the least significant bit (LSB) to the most significant bit (MSB). 

      How? 

          Let x be represented as ... b_k ... b_1 b_0.

          We are going to determine the bits from the LSB upwards. The constraint is that for each consecutive number, the popcount is fixed.

          We can use dynamic programming? But the state space might be huge: we have to remember the entire carry chain? 

      However, note that the trailing ones pattern is important. The state we need to remember:

          - The current position (bit index) we are at.
          - The current popcount for the starting number (x) so far?
          - And also, we need to know the carry when adding i? 

      Actually, we have to simulate the entire sequence of numbers: x, x+1, ... , x+n-1.

      The state must remember the carry from the current bit for each of the n numbers? That would be too expensive.

   Alternatively, we note the following:

      The condition for the entire sequence is local to the trailing ones and the positions where a carry propagates. 

      We can use the constraints derived from the consecutive differences to set conditions on the bits.

      Specifically, the differences a[i+1]-a[i] tell us about the trailing ones in x+i.

      For each i, we know:

          If a[i+1]-a[i] = 1, then the trailing ones count of x+i must be 0. (Because then k=0 -> difference=1)
          If a[i+1]-a[i] = d (<=0), then the trailing ones count k = 1-d, and we know that the last k bits of x+i are ones and the (k+1)-th bit is zero.

      Therefore, we can determine the trailing pattern for each x+i.

      Then, we can set constraints on the bits of x.

      But note: the numbers x+i and x+i+1 are consecutive, so the bits of x+i and x+i+1 are almost the same, except the trailing k+1 bits.

      How to reconstruct x? 

        We can consider the entire sequence and the overlapping constraints.

      Steps:

        Let the sequence of numbers: x, x+1, ..., x+n-1.

        We know for each i (0<=i<=n-2) the trailing ones count k_i for x+i.

        Then, the representation of x+i is: ... 0 1 1 ... 1 (with k_i ones at the end).

        Therefore, the last k_i bits of x+i are ones, and the next bit (if any) is zero.

        Then x+i+1 is ... 1 0 0 ... 0 (with k_i zeros at the end).

        How do we relate the bits of x+i and x+i+1? 

          Actually, we can write:

            x+i = ... 0 1 1 ... 1 (k_i ones) 
            x+i+1 = ... 1 0 0 ... 0 (k_i zeros)

          Therefore, the bits of x+i and x+i+1 are known for the last k_i+1 bits.

        But note: we have the entire sequence. The same bit position might be constrained by multiple numbers.

        We can try to set the bits from the least significant bit to higher bits, and for each bit position j, we know the value for each number in the sequence? But that is O(n) per bit, and the number of bits might be up to 60? Actually, the popcount is at most 60, so the numbers might have up to 60+log2(n) bits? But n can be 500,000 -> about 20 bits. So total bits around 80? But 500,000 numbers and 80 bits per number: that's 40e6 which is acceptable? But wait, we have t test cases and total n=500k, but the total n is the length of the sequences. However, we are going to iterate over bits? And we have to assign bits for each number? That would be O(n * (number of bits)) which is 500k * 80 -> 40e6 per test case? But the total n over test cases is 500k, but note: each test case has n, and the total of all n is 500k. So we can do an algorithm that is O(n * bits) as long as bits is around 80? That would be 500k * 80 = 40e6 worst-case? But 40e6 operations in Python might be borderline in 2 seconds? Actually, worst-case total n is 500k, but each test case n can be 500k? Then worst-case one test case: 500k * 80 = 40e6 operations -> in C++ that is acceptable, in Python? It might be acceptable if optimized in PyPy or PyPy3, but in CP Python we might need to be efficient.

        Alternatively, we can find a more efficient way.

   Another Insight: 

      The problem is known and there are solutions that use the relation to the carry chain and then a greedy reconstruction. 

      Known fact: the condition for the entire sequence is determined by the constraints on the trailing ones for each x+i. 

      Steps:

        Precomputation:

          Step 1: Check the consecutive differences: if at any point we have a[i+1]-a[i] > 1, then output -1. Also, if we have a[i+1]-a[i] <=0, then k_i = 1 - (a[i+1]-a[i]) must be at most a[i]. If not, output -1.

        Step 2: We can reconstruct the trailing ones counts for each i: 
            for i from 0 to n-2:
                if a[i+1] - a[i]] == 1:
                    k_i = 0   # actually, the trailing ones count for x+i is 0? But wait: if k_i=0, then the last bit is 0? Then we flip to 1 -> then the popcount increases by 1.
                else:
                    k_i = 1 - (a[i+1]-a[i]])

            And we know that the trailing ones count for the last number x+n-1 is not constrained? Actually, we don't have a next number.

        Step 3: Now, we want to reconstruct the bits of x. How?

          We note that the trailing ones count k_i for x+i tells us the last k_i+1 bits of x+i: the last k_i bits are ones and the k_i+1-th bit is zero.

          Then, the next number x+i+1 is obtained by flipping the last k_i+1 bits: the last k_i bits become zeros and the k_i+1-th bit becomes one.

          Therefore, the bits of x+i and x+i+1 are known for the positions 0 to k_i (inclusive).

          However, the same bit position might appear in multiple numbers. And we have to assign bits for x.

          How to represent x? 

            We can represent the bits of x as an array of bits (from LSB to MSB). We will build x from the LSB upwards.

          We also note that the entire sequence x, x+1, ... , x+n-1 can be represented as:

            x+i = x + i

          Therefore, the j-th bit of x+i is the j-th bit of (x + i).

          We can express:

            (x+i) mod 2^b = (x mod 2^b + i) mod 2^b

          But if we are reconstructing up to a certain bit, we have to account for carries.

        Alternate approach: 

          We can use a state machine that tracks the current carry and the current popcount for each number? But the state space is too big.

        Instead, we can use the constraints from the trailing ones to set the bits from low to high.

          We know for each i the trailing ones count k_i, which tells us:

             - The last k_i bits of x+i are ones, and the (k_i)-th bit is zero? Actually, the trailing ones count k_i: the bits from position 0 to k_i-1 are ones, and the bit at position k_i is zero.

          Therefore, for the number x+i:

             bit j (for j=0 to k_i-1) must be 1, and bit j=k_i must be 0.

          Then, for the next number x+i+1:

             We know that the last k_i bits are zeros (because we flipped the trailing k_i ones to zeros and then the k_i-th bit becomes one) and the k_i-th bit becomes 1.

          How do we relate to x?

             x+i = ... 0 1 1 ... 1 (k_i ones) -> so the bits are: 
                 bit0 = 1, bit1=1, ... , bit_{k_i-1}=1, bit_{k_i}=0.

          Then, x+i+1 = ... 1 0 0 ... 0 -> so:
                 bit0 = 0, bit1=0, ... , bit_{k_i-1}=0, bit_{k_i}=1.

          But also note: the higher bits might be affected by a carry? Actually, the flip of k_i ones to zeros and then a zero to one: that is the same as adding 1 to x+i. So the higher bits (above k_i) are the same as in x+i? Actually, no: if the k_i-th bit was 0 and we set it to 1, that doesn't cause a carry beyond that? So the bits above k_i remain the same.

          Therefore, we have:

             For the number x+i: 
                 bit j (for j < k_i) = 1, and bit j=k_i = 0.

             For the number x+i+1:
                 bit j (for j < k_i) = 0, and bit j=k_i = 1.

          How to express the bits of x? 

             We have: 
                 x+i = ... 0 1 ... 1 (k_i ones) 

             Therefore, the representation of x+i is:

                 x+i = (some higher bits) * 2^{k_i+1} + (0 * 2^{k_i} + 1*2^{k_i-1} + ... + 1*2^0)

             = (some higher bits) * 2^{k_i+1} + (2^{k_i} - 1)

          So:

                 x+i = M_i * 2^{k_i+1} + (2^{k_i} - 1)

          Then:

                 x+i+1 = M_i * 2^{k_i+1} + 2^{k_i}

          Now, note that x+i = x + i.

          Therefore:

                 x + i = M_i * 2^{k_i+1} + (2^{k_i} - 1)   ... (1)

          and

                 x + i + 1 = M_i * 2^{k_i+1} + 2^{k_i}   ... (2)

          From equation (1):

                 x = M_i * 2^{k_i+1} + (2^{k_i} - 1 - i)

          This must be nonnegative, so M_i must be chosen so that the expression is nonnegative.

          But note: this equation must hold for every i? Actually, only for the i that we have a constraint (i.e., we know k_i). However, we don't know k_i for the last number? Actually, we have constraints for i from 0 to n-2.

          We can write for each i (0<=i<=n-2) a modular equation:

                 x + i ≡ 2^{k_i} - 1   (mod 2^{k_i+1})

          Therefore:

                 x ≡ (2^{k_i} - 1 - i)   (mod 2^{k_i+1})

          So we have a system of linear congruences. Then we can solve for x by the Chinese Remainder Theorem? But note: the moduli 2^{k_i+1} might not be coprime? Actually, they are powers of two. So we can combine them: the least common multiple of several powers of two is the maximum power. Therefore, the solution x must be congruent to a fixed value modulo the maximum modulus that appears? 

          However, note: the constraints might be inconsistent? 

          How to combine the constraints?

             We can iterate over the constraints and update the modulus and the residue.

          Steps:

             Let x ≡ r (mod m) for the current modulus m. Then we get a new constraint: x ≡ r_i (mod m_i) with m_i = 2^{k_i+1}.

          Since the moduli are powers of two, we can combine by taking the maximum exponent? Actually, we can represent the constraints as:

             x must be ≡ r (mod M)   where M = 2^b, and then a new constraint: x ≡ r_i (mod M_i) with M_i=2^{b_i}.

          Then we can set the new modulus to LCM(M, M_i) = 2^{max(b, b_i)}.

          And we require that the current residue r must be congruent to r_i modulo the smaller modulus? Actually, we require:

             r ≡ r_i (mod min(M, M_i))

          If not, then no solution.

          Then we update the residue to the one that satisfies both, modulo the new modulus.

          However, note: the constraints are for different i? And they must all be satisfied simultaneously? But wait: each constraint is independent? Actually, the same x must satisfy all the congruences.

          But note: the constraints from different i might be inconsistent? 

          Therefore, we can:

             Initialize: 
                 modulus = 1, residue = 0.

             For each i from 0 to n-2:
                 m_i = 2^(k_i+1)   [where k_i = 1 - (a[i+1]-a[i]) if a[i+1]-a[i]<=0, and for the case a[i+1]-a[i]==1, k_i=0 -> then m_i=2^(0+1)=2]

                 r_i = (2^(k_i) - 1 - i) mod m_i   (we take modulo m_i to make it nonnegative and in the range [0, m_i-1])

                 Then we combine the constraint: 
                     x ≡ residue (mod modulus)
                     x ≡ r_i (mod m_i)

                 We want to find the smallest nonnegative x that satisfies both? Actually, we are going to combine the constraints.

          How to combine two congruences when the moduli are powers of two? 

            Let M = modulus, and N = m_i = 2^{b_i}. Let L = lcm(M, N) = 2^{max(b, b_i)}.

            We require:
                x ≡ residue (mod M)
                x ≡ r_i (mod N)

            Since M and N are powers of two, we can assume without loss of generality that M <= N (if M>N, we can swap? Actually, we can always set the larger modulus as the LCM). 

            Then the condition for the smaller modulus (say M) is already included in the larger modulus? Actually, the constraint mod N should imply the constraint mod M if M divides N? But if M does not divide N? Actually, in our case, M and N are powers of two: so if M=2^b and N=2^c, then if b<=c, then the constraint mod N is stronger? But we must also check that the residue mod M is consistent with the residue mod N? Specifically, residue mod M must be equal to r_i mod M.

            Condition: residue ≡ r_i (mod min(M, N))? Actually, since M and N are powers of two, the condition is: residue ≡ r_i (mod min(M, N))? Actually, if M and N are powers of two, then the constraints are consistent if and only if residue ≡ r_i (mod gcd(M, N))? But gcd(M, N)=min(M, N). 

            Therefore, if M<=N, then we require residue ≡ r_i (mod M). 
            If M>N, then we require residue ≡ r_i (mod N).

            Actually, we can always take the gcd = min(M, N). So we require residue ≡ r_i (mod min(M, N)).

          Algorithm for combining:

            Let M0 = modulus, r0 = residue.
            Let M1 = m_i = 2^(k_i+1), r1 = r_i.

            Let g = gcd(M0, M1) = 2^{min(b0, b1)}.

            Check: if r0 mod g != r1 mod g, then no solution.

            Then we find x that satisfies:
                x ≡ r0 (mod M0)
                x ≡ r1 (mod M1)

            The solution modulo L = lcm(M0, M1) can be found by:

                Since M0 and M1 are powers of two, we can set L = max(M0, M1) if they are not equal? Actually, LCM(M0, M1) = max(M0, M1) if one divides the other? Actually, the LCM is 2^max(b0, b1). 

            How to compute the residue?

                Without loss of generality, assume M0 <= M1.

                Then we have: 
                  x = r0 + t * M0, for some t.

                We require: r0 + t * M0 ≡ r1 (mod M1)

                => t * M0 ≡ (r1 - r0) (mod M1)

                Since M0 divides M1? Actually, because M1 is a multiple of M0? Because M0=2^b0, M1=2^b1, and b0<=b1 -> M0 divides M1. Then the equation becomes:

                  t * M0 ≡ (r1 - r0) (mod M1)

                But note: M0 divides M1, so we can divide the entire congruence by M0? Actually, we can write:

                  t ≡ ( (r1 - r0) / M0 )   (mod M1/M0)

                Then we can set t0 = ( (r1 - r0) // M0 ) mod (M1//M0)   [if (r1 - r0) is divisible by M0? Actually, we have already the condition that r0 ≡ r1 (mod M0) -> so (r1 - r0) is divisible by M0?]

                Then t = t0 + s * (M1//M0) for any integer s.

                Then x = r0 + M0 * (t0 + s * (M1//M0)) = r0 + M0*t0 + s * M1.

                So the solution modulo M1 (which is the LCM) is x0 = r0 + M0*t0.

                Then we set:
                    residue = x0 mod L? Actually, L = M1? 
                    modulus = M1   (which is the LCM)

            However, note: we might have combined several moduli and the current modulus might be larger? Actually, we are updating modulus to the LCM, which is the maximum modulus? 

            But in our case, the LCM is the maximum of the two moduli? Actually, LCM(2^b0, 2^b1)=2^max(b0,b1). So if we assume M0<=M1, then LCM=M1.

            Therefore, we update:

                residue = r0 + M0 * t0   (and then we can reduce modulo M1? Actually, we can compute it modulo M1? But note: we want the smallest nonnegative solution modulo M1? The expression r0 + M0*t0 is already in the range [0, M1-1]? Not necessarily, so we take residue = (r0 + M0 * t0) % M1.

            Alternatively, we can set:

                residue = r0 + M0 * ( ( (r1 - r0) // M0 ) % (M1//M0) )   [but then we can mod M1]

          However, note: we must also consider that the constraints for different i might have different moduli. We iterate over i from 0 to n-2.

          After processing all constraints, we get a residue r and modulus M. Then the general solution is x = r + t*M for t>=0.

          Then we need the smallest x that satisfies:

                for all i in [0, n-1]: p(x+i) = a[i]

          But wait: we only used the constraints from the consecutive differences (which give the trailing ones counts) to get the modular conditions. However, we also have the constraint that the popcount for each x+i must be a[i]. The modular conditions only fix the lower bits? The higher bits are free? 

          How to check the popcount? 

            We have the condition that the lower bits (up to the maximum modulus, say M=2^B) are fixed. Then the higher bits can be set arbitrarily? 

            But note: the popcount of x+i is a[i]. The value of x+i modulo M is fixed, but the higher bits might add ones. How many ones? 

            We can write:

                x+i = (x+i mod M) + M * t

            Then the popcount is: 
                p(x+i) = p( (x+i mod M) ) + p( M * t )   ??? 

            Actually, the binary representation of x+i is the concatenation of the binary representation of t and the binary representation of (x+i mod M) (if we think of fixed width M). But that is not true: because M is a power of two, the representation of (x+i mod M) is the last B bits, and the rest is t. So the total popcount is p(t) + p(x+i mod M).

            Therefore, we require:

                p(t) + p(x+i mod M) = a[i]   for each i.

            Then:

                p(t) = a[i] - p(x+i mod M)

            And this must be nonnegative. Moreover, since this must hold for every i, we have:

                a[i] - p(x_i) must be the same for every i? 

            Actually, no: because t is the same for all i? Actually, t is the same for x, but x+i: 

                x = t*M + r   -> then x+i = t*M + (r+i)

            Then the representation of x+i is: the higher part (t) and the lower part (r+i mod M). But note: if r+i >= M? Then there is a carry? 

            Actually, we must account for the possibility that r+i overflows M? 

            How? 

                When we write:

                    x+i = t*M + (r+i)

                But if r+i >= M, then we have:

                    x+i = (t+1)*M + (r+i - M) = (t+1)*M + (r+i - M)

                Then the lower part is (r+i) mod M, and the higher part becomes t+1.

                Therefore, the popcount is p(t+1) + p((r+i) mod M).

            So the popcount of x+i is:

                if (r+i) < M: 
                    p(x+i) = p(t) + p(r+i)
                else: 
                    p(x+i) = p(t+1) + p(r+i - M)

            Therefore, we cannot simply set p(t) = a[i] - p(r+i) because we don't know if there was a carry.

          How to handle?

            We have to compute for each i:

                base_i = r + i   (but this might be >= M, then we have to split)

                Then the value of the higher part t_i is:

                    if r+i < M: t_i = t
                    else: t_i = t+1

                Then we require:

                    p(t_i) = a[i] - p( base_i % M )

            But note: base_i % M = (r+i) mod M.

            However, we have:

                base_i = r+i

                Then:

                    if r+i < M: 
                         condition: a[i] = p(t) + p(r+i)
                    else:
                         condition: a[i] = p(t+1) + p(r+i - M)

            Therefore, we can precompute:

                Let c_i = 
                    if r+i < M: then we define: 
                         required_high = a[i] - p(r+i)
                    else:
                         required_high = a[i] - p(r+i - M)

            But note: the value of t is the same for all i? Actually, the higher part is either t or t+1.

            Then we require that:

                For all i such that r+i < M: 
                    p(t) = a[i] - p(r+i)

                For all i such that r+i >= M:
                    p(t+1) = a[i] - p(r+i - M)

            And also, the same t must be used for all i.

            Therefore, we get multiple constraints on t:

                Let:
                    For i in set A (no carry): 
                         required = a[i] - p(r+i) 
                    For i in set B (carry): 
                         required = a[i] - p(r+i - M) 

                Then we require that all the required values for set A are equal to p(t) and all the required values for set B are equal to p(t+1). Moreover, we require that p(t+1) = p(t) - k + 1? Actually, no: t and t+1 are consecutive, so we know:

                    p(t+1) = p(t) + 1 - k, where k is the trailing ones count of t? But we don't know k. However, we can compute p(t+1) from p(t) by the relation: p(t+1)=p(t)+1 if t has no trailing ones? or p(t+1)=p(t)-k+1.

                But note: we are not given the consecutive differences for t? 

            Alternatively, we can note:

                The entire sequence of required_high for set A must be the same value, say v0, and for set B must be the same value, say v1.

                And we require that v0 = p(t) and v1 = p(t+1).

                And we know the relation: p(t+1) = p(t) + 1 - k, for some k>=1? Or k=0? Actually, it can be:

                   if t has k trailing ones: then p(t+1) = p(t) - k + 1.

                Therefore, we require:

                    v1 = v0 - k + 1, for some k>=1? Or k=0? Actually, if k=0 then v1 = v0+1.

                But we don't know k. However, we can check: we must have v0 and v1 satisfying one of the two:

                   either: v1 = v0 + 1   (if k=0: meaning the last bit of t is 0) 
                   or: v1 = v0 - k + 1 for some k>=1 (so v1 <= v0) and v1 must be at least 0.

                But note: we have multiple constraints: all the set A must be v0, and set B must be v1, and then we require that v0 and v1 are the popcounts of consecutive integers.

            However, we can also check: 

                If the set A is nonempty: then all values in A must be the same, and if set B is nonempty: all values in B must be the same.

                Then, we set v0 = the common value in A, and v1 = the common value in B.

                Then we must have:

                    v1 = p(t+1) and v0 = p(t)

                    and the relation: v1 = v0 + 1   OR   v1 = v0 - k + 1 for some k>=1? 

                But note: the relation between p(t) and p(t+1) is fixed: it must be that the difference is 1 - k, and k>=0? Actually k (the trailing ones in t) can be 0, then v1 = v0+1. If k>=1, then v1 = v0 - k + 1, which must be at most v0 and at least v0 - (v0) + 1? (since k cannot exceed v0). 

                Actually, k can be arbitrarily large? But the popcount of t is v0, so k<=v0.

                Therefore, we require:

                    v1 must be either v0+1, or an integer between v0 - v0 + 1 = 1 and v0 (inclusive)? Actually, v1 = v0 - k + 1, and k from 1 to v0 -> then v1 from 1 to v0.

                But note: if t=0, then t+1=1: p(0)=0, p(1)=1 -> then v1 = 1 = 0+1 -> v1 = v0+1.

                How about t=3 (binary 11): then t+1=4 (binary 100): p(3)=2, p(4)=1 -> then v1=1 = 2 - 2 + 1 = 1 -> so that's in the range.

            Therefore, we require that:

                All the values in set A are the same, and all the values in set B are the same.

                And then the two values v0 and v1 must satisfy:

                    v1 = v0+1   OR   v1 <= v0   (and also v1>=0, and the condition that k= v0 - v1 + 1 must be between 1 and v0? Actually, k = v0 - v1 + 1 must be at least 1 and at most v0 -> which means 1<= v0 - v1 + 1 <= v0 -> then v0 - v1 + 1>=1 => v0>=v1, and v0 - v1 + 1<=v0 => v1>=1? Actually, the second part: v0 - v1 + 1 <= v0  => -v1+1<=0 => v1>=1.

                But note: if v0=0, then the only possibility is v1 = v0+1 = 1? because if k>=1, then k<=v0=0 -> impossible. So then v1 must be 1.

            Actually, we can write:

                We must have: 
                    if v0>0: then either v1 = v0+1 or (v1>=1 and v1<=v0) 
                    if v0=0: then v1 must be 1.

            But note: we can compute k from v0 and v1: k = v0 - v1 + 1, and we require k>=1 and k<=v0? 

                k>=1 -> v0 - v1 + 1>=1 -> v0>=v1.
                k<=v0 -> v0 - v1 + 1 <= v0 -> v1>=1.

            So the conditions are:

                Condition 1: v0 and v1 are nonnegative? (they are popcounts, so yes, but we computed by subtracting, so we must have a[i]>=p(r+i) and a[i]>=p(r+i-M) for the respective cases)

                Condition 2: for set A: all the same, set B: all the same.

                Condition 3: if set A is nonempty, then the value v0 is defined; if set B is nonempty, then the value v1 is defined.

                Condition 4: 
                    If both sets are nonempty, then we must have: v1 = v0+1 OR (v1>=1 and v1<=v0) and k = v0 - v1 + 1 must be an integer? (it is) and also we must have k>=1 and k<=v0? (which we already have by v0>=v1 and v1>=1? and v0>=v1 implies k>=1, and v1>=1 implies k<=v0? Actually, k = v0 - v1 + 1 <= v0? because v1>=1 -> k<=v0, and k>=1 because v0>=v1 -> so condition 4 is: v0>=v1 and v1>=1? 

                But note: if set A is empty, then we only have set B: then we require that p(t+1) = v1. Then we can set v0 = v1 - (1 - k) for some k? Actually, we don't have a constraint on v0? But we don't have a constraint on t? Actually, we are free to choose t as long as p(t+1)=v1? But note: t is the higher part for the first number? Actually, the first number x = t*M + r. Then the higher part for x is t. But for the first number, if r<M, then the higher part is t, and the popcount of x is p(t)+p(r). But we don't have a constraint for the first number from set A or set B? Actually, we have:

                    i=0: 
                         base_0 = r+0 = r.
                         if r < M: then condition: a[0] = p(t) + p(r)
                         if r>=M: then condition: a[0] = p(t+1) + p(r - M)

                So the first number is included.

            Therefore, we must have:

                For i=0 to n-1, we have:

                    if r+i < M: condition: a[i] = p(t) + p(r+i)
                    else: condition: a[i] = p(t+1) + p(r+i-M)

                Then we can compute:

                    v0 = a[i] - p(r+i) for every i with r+i<M
                    v1 = a[i] - p(r+i-M) for every i with r+i>=M

                Then we require that all the v0 are the same (say v0*) and all the v1 are the same (say v1*).

                And then we require that:

                    If there is at least one i with r+i<M, then p(t) must be v0*.
                    If there is at least one i with r+i>=M, then p(t+1) must be v1*.

                And then we require that:

                    If both exist: 
                         either v1* = v0*+1   OR   (v0*>=v1* and v1*>=1)   [which implies the k condition?]

                    But note: we also have the relation between p(t) and p(t+1): 
                         p(t+1) = p(t) - k + 1 for some k>=1? Or if k=0 then p(t+1)=p(t)+1.

                    So if both sets are nonempty, we must have:

                         v1* = v0*+1   OR   v1* = v0* - k + 1 for some k in [1, v0*] (which means v1*<=v0* and v1*>=v0*-v0*+1 = 1).

                Actually, we can just check: 

                         if v0* = 0: then the only possibility for v1* is 1? (because if there's a carry then k must be at least 1? But if t=0, then p(t)=0, then t+1=1: p(t+1)=1 -> so v1*=1 is the only possibility)

                         if v0*>0: then we can have either v1* = v0*+1 or v1* in [1, v0*] (but note: we must have v1*>=1).

                However, we don't know k. But we don't need to know k: we only need to know that such a k exists? Actually, the condition on the consecutive integers t and t+1 is automatically satisfied for some k? 

                Actually, for any nonnegative integer t, the relation between p(t) and p(t+1) is always:

                    p(t+1) = p(t) + 1 - k, where k is the number of trailing ones in t? 

                And k>=0? Actually, k can be 0? Then we have p(t+1)=p(t)+1.

                But note: if t has no trailing ones? Then k=0? Actually, the trailing ones count k is defined as the consecutive ones from the least significant bit. If the last bit is 0, then k=0.

                Therefore, the relation always holds. And the condition we require is that:

                    p(t) = v0*   (if there is a non-carry index) 
                    p(t+1) = v1*   (if there is a carry index)

                And we know that for consecutive integers, the only constraint is that v1* must be either v0*+1 or at most v0*? Actually, no: it can be greater? Actually, we saw that the difference can only be 1 (if k=0) or negative (if k>=1). So v1* can be at most v0*+1? Actually, the maximum is v0*+1 (when k=0) and the minimum is v0* - (v0*) + 1 = 1 (if k = v0*).

                Therefore, we require:

                    v1* must be in the range [1, v0*+1]   (if both are defined) 

                And if only non-carry: then we only require that there exists a t such that p(t)=v0* (which is always true? because we can take t with v0* ones, but note: t must be nonnegative, so if v0*=0 then t=0, if v0*>0 then we can form such a t).

                Similarly, if only carry: then we require that there exists a t such that p(t+1)=v1*? Also always true? 

                However, note: we have both constraints? 

                For example: 
                    non-carry: p(t)=v0*
                    carry: p(t+1)=v1*

                Then the consecutive integers t and t+1 must satisfy the popcount relation. And we know that any consecutive pair of integers satisfies that relation? So the only constraint is that v1* is either v0*+1 or at most v0*? Actually, the relation is fixed: for a given t, p(t+1) is determined. But we are free to choose t? 

                Then we can choose t to satisfy both? 

                Conditions on t:

                    p(t) = v0*   (if non-carry exists) 
                    p(t+1) = v1*   (if carry exists)

                And the relation between v0* and v1* must be one of the two: 
                    v1* = v0*+1   OR   v1* <= v0*   (and then the k condition is automatically satisfied? because k= v0* - v1* + 1 must be at least 1? and at most v0*? because v0*>=v1* and v1*>=1 -> then k>=1 and k<=v0*)

                But note: we must have k = v0* - v1* + 1, and k must be the number of trailing ones in t? How do we know that such a t exists?

                Actually, we can construct t:

                    Case 1: v1* = v0*+1 -> then we require a t such that p(t)=v0* and the last bit of t is 0 (so that when we add one, we flip the last bit: then popcount becomes v0*+1). How to construct? 
                         t must be ...0 (with the last bit 0) and the popcount of the rest is v0*. 

                    Case 2: v1* = v0* - k + 1 for some k in [1, v0*] -> then we require a t that has k trailing ones and total popcount v0*. How to construct?
                         t = ...01...1 (with k ones at the end) and the rest has popcount v0* - k. 

                Therefore, we can always construct such a t? 

            Therefore, the only constraints are:

                (1) The consecutive differences condition (already checked at the beginning) and the constraints on the trailing ones (k_i<=a[i]) for the negative differences.

                (2) The system of congruences is consistent (so the residue and modulus are computed without conflict).

                (3) For the computed residue r and modulus M, we define for each i in [0, n-1]:

                         base = r + i
                         if base < M: 
                             v_i = a[i] - p(base)   [must be nonnegative? and then we require that all these v_i are the same, say v0*]
                         else:
                             v_i = a[i] - p(base - M)   [and then all these v_i are the same, say v1*]

                (4) Then we require:

                    For the non-carry set: all v_i = v0* (if the set is nonempty) and for the carry set: all v_i = v1* (if the set is nonempty).

                    And then:

                         If both sets are nonempty: 
                             1 <= v1* <= v0*+1   [and note v0* and v1* are nonnegative integers]

                         But also, if the non-carry set is nonempty, then v0* must be nonnegative? and similarly for v1*.

                (5) Then we need to find the smallest nonnegative integer t that satisfies:

                    If the non-carry set is nonempty: p(t) = v0* 
                    If the carry set is nonempty: p(t+1) = v1* 

                    And if both are nonempty, then the relation between v0* and v1* must be satisfied: 
                         either v1* = v0*+1, and then we require that the last bit of t is 0? Actually, we don't care as long as the popcounts are satisfied? But note: we are free to choose any t as long as the popcounts are as required? 

                How to find the smallest t? 

                    We are to minimize x = t*M + r.

                    Since M is fixed and r is fixed, we minimize t.

                    Conditions:

                         If only non-carry: then we need the smallest t such that p(t)=v0*. The smallest t with popcount v0* is the number with the lowest v0* bits set: t_min = (1<<v0*) - 1? But if v0*=0, then t_min=0.

                         If only carry: then we need the smallest t such that p(t+1)=v1*. The smallest such t is the smallest number whose successor has popcount v1*. 

                            How? 
                                p(t+1)=v1*: the smallest t+1 with popcount v1* is (1<<v1*)-1, so t = (1<<v1*)-2? 

                            But wait: if v1*=1, then t+1=1 -> t=0 -> then p(0+1)=p(1)=1 -> works. 
                            If v1*=2: then the smallest t+1 with popcount 2 is 3? so t=2 -> then p(3)=2 -> works? 
                            But note: we can also have t+1= 0b101 -> 5? then t=4 -> p(5)=2. 
                            But 3 is the smallest? 

                            Actually, the smallest number with popcount v1* is (1<<v1*)-1? 

                            Then t_min = (1<<v1*)-1 - 1 = (1<<v1*)-2.

                         But wait: what if (1<<v1*)-2 is negative? if v1*=0: then we require p(t+1)=0 -> then t+1=0 -> t=-1 -> not nonnegative. So v1* must be at least 1? Actually, the popcount of a positive integer is at least 1? But 0 has popcount 0. However, note: t+1 is at least 1? because t is nonnegative? so t+1>=1, then p(t+1)>=1. Therefore, v1*>=1. So we are safe.

                    If both: 

                         We need the smallest t such that:

                             p(t)=v0* and p(t+1)=v1*

                         and the relation must hold: either v1*=v0*+1 or v1*<=v0*.

                         How to find the smallest t? 

                         We can iterate the possibilities? But t can be large? However, we are looking for the smallest t, and the smallest t is at most (1<<v0*) - 1? 

                         Actually, we can generate the numbers with popcount v0* in increasing order? But the smallest one is (1<<v0*)-1, then the next is (1<<v0*)-1 + 1? not necessarily. 

                         We can try:

                             Case 1: if v1* = v0*+1: 
                                 Then we need a number t with popcount v0* and the last bit is 0? Actually, we can have any representation? But we know that adding 1 will increase the popcount by 1 only if the last bit is 0. 

                                 Then the smallest t with popcount v0* and last bit 0: 
                                     t = (1<<v0*) - 1) << 1? -> that has popcount v0*, and the last bit is 0? But then the number is 2 * ((1<<v0*)-1). 

                                 However, we can do better: 
                                     set the last bit to 0, and then we have the remaining bits must form a number with popcount v0*. The smallest such number is to set the next v0* bits (starting from the next) to ones? 

                                 Actually, the smallest number with popcount v0* and last bit 0 is: (1<<v0*) - 1) << 1? 

                                 But then the next number is (1<<v0*) - 1)<<1 + 1 = (1<<v0*) - 1)*2 + 1 -> but wait: 
                                     t = (1<<(v0*+1)) - 2  -> which is (1<<v0*)*2 - 2.

                                 Then p(t)=? 
                                     t = 111...110 (v0* ones and a zero at the end) -> popcount = v0*.

                                 Then t+1 = 111...111 (v0* ones and then the last bit becomes one? and then we have v0*+1 ones? 

                                 Actually, if we set t = (1<<(v0*+1)) - 2, then:

                                     t = (2^(v0*+1) - 2) -> binary: (v0*+1) bits: 111...110 (v0* ones? actually: 2^(v0*+1)-2 = 111...110 (with v0* ones? no: for v0*=1: 2^2-2=2, which is 10 -> popcount=1 -> then t+1=3: 11 -> popcount=2 -> v1*=2 = v0*+1 -> works.

                                 But is that the smallest? 

                                 Consider: 
                                    v0*=1: 
                                        We want t with popcount=1 and last bit=0? Then the representation: ...10 -> the smallest is 2.

                                 How about a number with more than v0*+1 bits? 
                                    We can have: 0b1010...? but that would be larger than 2.

                                 So the smallest is (1<<(v0*+1))-2.

                         Case 2: if v1* <= v0*: 
                                 Then we require a number t with popcount v0* and such that when we add one, the popcount becomes v1*.

                                 How? 
                                    We know: p(t+1) = p(t) - k + 1, where k is the number of trailing ones in t.

                                 So we require: v1* = v0* - k + 1 -> k = v0* - v1* + 1.

                                 Then t must have k trailing ones, and the total popcount is v0*. 

                                 The smallest such t: 
                                    We set the last k bits to ones, and then we have to set the remaining v0* - k ones in the higher bits. The smallest way is to set the next bit to 1 and then the rest as compact as possible? 

                                 Actually, the number t must end with k ones, and then a zero? and then the rest. The total popcount is k + (popcount of the rest) = v0*, so the popcount of the rest is v0* - k.

                                 The rest is the number without the last k+1 bits? Actually, the rest is the bits from position k and above.

                                 We require the rest to have popcount v0* - k.

                                 The smallest such number is: 
                                    Set the bits from the (k)-th to (k + (v0*-k))-1 to ones? 

                                 Actually, the minimal representation: 
                                    t = ( (1 << (v0* - k)) - 1 ) << (k+1)  |  ((1<<k)-1)

                                 Then the popcount: 
                                    The lower k bits: ones -> popcount k.
                                    The higher: a block of (v0*-k) ones -> popcount v0*-k.
                                    Total: k + (v0*-k) = v0*.

                                 Then t+1 = ( (1 << (v0* - k)) - 1 ) << (k+1)  |  (1<<k)   [because adding one flips the trailing k ones to zeros and then sets the k-th bit to 1]

                                 Then the popcount of t+1: 
                                    The lower k bits: zeros -> popcount 0.
                                    The k-th bit: 1 -> popcount 1.
                                    The higher: (v0*-k) ones -> popcount v0*-k.
                                    Total: 1 + (v0*-k) = v0* - k + 1 = v1*.

                                 And the value of t: 
                                    t = ( ( (1 << (v0* - k)) - 1 ) << (k+1) ) + ((1<<k)-1)

                                 How to minimize? We want the smallest t. The expression above is the smallest number with k trailing ones and a block of v0*-k ones above? 

                                 Example: v0*=3, k=2 (then v1*=3-2+1=2) 
                                    Then: 
                                        v0*-k = 1.
                                        t = ( (1<<1)-1 ) << (2+1)  | ( (1<<2)-1 ) 
                                          = (1)<<3 | 3 
                                          = 8 | 3 = 0b1000 | 0b0011 = 0b1011 -> 11.

                                 But the number 11: 
                                    binary: 1011 -> popcount=3 -> v0*=3.
                                    then 12: 1100 -> popcount=2 -> v1*=2. -> works.

                                 Is there a smaller t? 
                                    We need a number with 3 ones and at least 2 trailing ones? 
                                    The numbers: 
                                        7: 0111 -> trailing ones=3 -> then t=7: then t+1=8: popcount=1 -> not 2.
                                        11: as above -> works.

                                 But what about 14? 1110 -> popcount=3, trailing ones= not? actually, the trailing ones count: 14 in binary: 1110 -> the last bit is 0 -> trailing ones count=0? -> not 2.

                                 So 11 is the smallest.

                                 But is there a number between 7 and 11? 
                                    8: 1000 -> popcount=1 -> not 3.
                                    9: 1001 -> popcount=2 -> not 3.
                                    10:1010 -> popcount=2 -> not 3.
                                    11:1011 -> popcount=3 -> works.

                                 So the expression gives the smallest.

                         Therefore, the smallest t in this case is:

                                 k = v0* - v1* + 1
                                 t = ( (1 << (v0* - k)) - 1 ) << (k+1) | ((1<<k)-1)

                                 = ( (1 << (v1* - 1)) - 1 ) << ( (v0* - v1* + 1) + 1 ) | ( (1<< (v0* - v1* + 1)) - 1 )

                                 But note: v0*-k = v0* - (v0* - v1* + 1) = v1* - 1.

                                 So: t = ( (1 << (v1* - 1)) - 1 ) << (v0* - v1* + 2) | ( (1<< (v0* - v1* + 1)) - 1 )

          Then, the candidate x is: x = t * M + r.

          And we want the smallest x? 

          But note: we must also consider that t could be 0? and we have the expression above might be negative? 

          Also, we have two cases for the both condition: 

            if only non-carry: t_min = (1<<v0*) - 1   [if v0*>0] and if v0*=0 then t_min=0.

            if only carry: t_min = (1<<v1*)-2   [because the smallest number with popcount v1* is (1<<v1*)-1, then t = (1<<v1*)-2]

          Then we take the minimum x = t_min * M + r.

          But note: we must check that the candidate x satisfies the entire sequence? 

          Actually, we have:

            We built the residue r from the congruences (which came from the trailing ones constraints) and the modulus M from the maximum modulus.

            Then we defined the value t_min as above.

            Then we set x = t_min * M + r.

            Then we must check that for every i in [0, n-1]: p(x+i) = a[i]? 

            Why? Because we only used the trailing ones constraints and the popcount constraints on the higher part? 

            But the congruences ensure the lower bits are fixed to satisfy the trailing ones patterns? 

            However, the condition for the trailing ones pattern was only for i from 0 to n-2? 

            And the popcount constraint for the entire sequence is enforced by the condition on the higher part? 

          But to be safe, we can verify? However, n can be up to 500000 and the numbers x can be huge? How to verify without iterating? 

          Actually, the problem says the total n is 500000, but we have to do it for each test case? and the total n is 500000, so we can do one verification per test case? 

          How to verify one x? 

            We have to compute p(x+i) for i=0 to n-1. But x can be huge (like 2^60) and n=500000, then x+i might be huge. How to compute popcount for huge numbers? 

            We can use the built-in bin(x).count('1')? But for n=500000, and each x+i is huge, and converting to a binary string might be O(60) per number? Then total 500000*60=30e6 which is acceptable? But 30e6 operations in Python? It might be acceptable in PyPy/C++ but in Python we have 2 seconds? 

            However, worst-case total n is 500000, so we can do 500000 * (number of bits) and the number of bits is about 60? Then 500000*60=30e6 -> in Python, 30e6 operations might be acceptable? 

          But note: the problem has t test cases, and the total n is 500000, so worst-case one test case with n=500000, then we do 500000 * 60 = 30e6, which in Python might run in about 1-2 seconds? 

          However, the sample input has a number 2305843009213693949, which is 2^61 - 3? 

          How to compute popcount for x+i? 

            We can do: 

                def popcount(x):
                    # x is an integer, nonnegative
                    return bin(x).count('1')

            But note: for large x, bin(x) creates a string of length about 60? So the cost is about 60 per number? Then 500000 * 60 = 30e6 -> which is acceptable in PyPy/C++ but in Python? We might need to use a faster method.

          Alternate popcount: 

            We can use bit-level operations? 

            We know that a_i is at most 60, so the numbers x+i might be huge but the popcount is small? Actually, the popcount is at most 60. But we are not given that the numbers are small.

          We can use:

            def popcount(x):
                # x is nonnegative integer
                c = 0
                while x:
                    x &= x - 1
                    c += 1
                return c

            But worst-case if x has 60 ones, then we do 60 iterations per number -> 500000*60 = 30e6 -> same.

          Therefore, we can do a verification in O(n * bits) = 30e6 for one test case? 

          But note: the total n across test cases is 500000, so worst-case one test case with n=500000 -> 30e6 operations -> in Python, we hope that it runs in 2 seconds? 

          However, we are also doing the same for multiple candidates? Actually, we only compute one candidate per test case.

          But wait: what if there are multiple residues? Actually, we compute one residue and modulus, then one candidate t_min, then one candidate x.

          Then we verify that candidate x? 

          However, what if the smallest t_min does not yield a solution? 

          Actually, we have derived the conditions that must be satisfied for the entire sequence to hold. Therefore, if the conditions (consistency of the residues in the congruences, and the popcount constraints on the higher part) are satisfied, then the candidate x should work? 

          But to be safe, we can verify.

          Steps for one test case:

            Step 1: Check the consecutive differences: 
                for i in range(n-1):
                    d = a[i+1]-a[i]
                    if d > 1:
                        return -1
                    if d <= 0:
                        k = 1 - d
                        if k > a[i]:
                            return -1

            Step 2: Build the system of congruences:

                modulus = 1
                residue = 0

                for i in range(n-1):
                    if a[i+1]-a[i]] == 1:
                        k_i = 0
                    else:
                        k_i = 1 - (a[i+1]-a[i]])

                    m_i = 1 << (k_i+1)   # = 2^(k_i+1)
                    r_i = ( (1 << k_i) - 1 - i ) % m_i   # make nonnegative modulo m_i

                    # Now combine the congruence: x ≡ residue (mod modulus) and x ≡ r_i (mod m_i)
                    # Let M0=modulus, R0=residue, M1=m_i, R1=r_i.

                    # Find the new modulus = LCM(M0, M1) = 2^max(b0, b1) and the residue in [0, LCM-1] that satisfies both.

                    # Since both moduli are powers of two, we can do:

                    g = min(modulus, m_i)   # actually, gcd = min? because they are powers of two: gcd = 2^min(b0,b1)

                    # Check consistency: residue mod g must equal r_i mod g.

                    if residue % g != r_i % g:
                        return -1

                    # Now combine: 
                    if modulus <= m_i:
                        # Solve: x = residue + t0 * modulus 
                        #        residue + t0 * modulus ≡ r_i (mod m_i)
                        # Since modulus divides m_i? (because modulus<=m_i and both powers of two) -> so modulus divides m_i? 
                        # Then we can write: 
                        #   t0 * modulus ≡ (r_i - residue) (mod m_i)
                        # But modulus divides m_i? -> then we can divide the equation by modulus? 
                        # Actually, we can set:
                        #   Let d = (r_i - residue) // modulus   (must be integer? because residue ≡ r_i (mod g) and g=modulus? because modulus<=m_i -> then g=modulus, so residue mod modulus = residue, and r_i mod modulus = residue? -> so (r_i - residue) is divisible by modulus? 
                        #   Then t0 = ( (r_i - residue) // modulus ) % (m_i // modulus)
                        #   Then the solution is: residue + modulus * t0, modulo m_i.

                        # But note: we can also compute:

                        t0 = ( (r_i - residue) // modulus ) % (m_i // modulus)
                        new_residue = residue + t0 * modulus
                        new_modulus = m_i   # because LCM = m_i

                        residue = new_residue % new_modulus
                        modulus = new_modulus

                    else: # modulus > m_i
                        # Then m_i divides modulus? 
                        # Actually, modulus and m_i are powers of two, and modulus>m_i, then m_i divides modulus? 
                        # Then the condition: residue ≡ r_i (mod m_i) -> which we already checked? 
                        # Then we don't change the residue? 
                        # But we don't need to change the modulus? 
                        # Actually, the LCM is modulus, so we keep modulus and residue.

                        # So nothing to do? 
                        pass

            Step 3: Now we have residue and modulus. 
                Then we compute:

                    # We need to compute for each i: 
                    #   base = residue + i
                    #   if base < modulus: 
                    #       v_i = a[i] - popcount(base)
                    #   else:
                    #       v_i = a[i] - popcount(base - modulus)

                Then we check:

                    Let v0 = None, v1 = None
                    For i in range(n):
                        base = residue + i
                        if base < modulus:
                            pc = popcount(base)
                            v = a[i] - pc
                            if v < 0: 
                                return -1   # invalid
                            if v0 is None:
                                v0 = v
                            else:
                                if v != v0:
                                    return -1
                        else:
                            pc = popcount(base - modulus)
                            v = a[i] - pc
                            if v < 0:
                                return -1
                            if v1 is None:
                                v1 = v
                            else:
                                if v != v1:
                                    return -1

                # Now, if we have both v0 and v1 defined, then we require that:
                #   v1 is either v0+1 or (v1<=v0 and v1>=1)
                #   but note: we don't require that if only one is defined? 
                #   Actually, we need to check the existence of t for the conditions.

                Also, we require that if v0 is defined, then v0>=0? (if v0 is negative, we returned above) and similarly for v1.

                Then we consider:

                    If the non-carry set is nonempty (so v0 is defined) and the carry set is nonempty (so v1 is defined), then we require that v1 is in the range [1, v0+1]? 

                    But note: we also require that the relation between consecutive integers in the higher part holds? Actually, we don't need to check the relation? because we are going to find a t that satisfies both? and we know that such a t exists if the values are in the valid range? 

                However, we require that the values are nonnegative and the constraints on the range.

                Then we find the smallest t:

                    If only non-carry: 
                         t_min = (1 << v0) - 1   if v0>0, or 0 if v0==0.

                    If only carry:
                         t_min = (1 << v1) - 2   # because the smallest number with popcount v1 is (1<<v1)-1, so t = (1<<v1)-2

                    If both:
                         if v1 == v0+1:
                             t_min = (1 << (v0+1)) - 2   # = (1<<(v0+1))-2
                         else: # v1 <= v0
                             # then k = v0 - v1 + 1
                             k = v0 - v1 + 1
                             # v0-k = v1-1
                             # The minimal t: 
                             #   t_min = ( (1 << (v1-1)) - 1 ) << (k+1) | ((1<<k)-1)
                             #         = ( ( (1<<(v1-1)) - 1 ) * (1<<(k+1)) ) + ( (1<<k) - 1 )
                             # But note: if v1-1==0, then (1<<0)-1=0, then the term is 0.
                             # Example: v0=3, v1=2: then k=3-2+1=2, v1-1=1 -> then (1<<1)-1 = 1, then shift by k+1=3: 1<<3=8, then | ( (1<<2)-1 ) = 3 -> 8|3 = 11 -> as above.
                             part1 = (1 << (v1-1)) - 1
                             part1_shifted = part1 << (k+1)
                             part2 = (1 << k) - 1
                             t_min = part1_shifted | part2

                Then x = t_min * modulus + residue

            Step 4: However, we must verify that the computed x satisfies the entire sequence? 
                We do:

                    for i in range(n):
                        y = x + i
                        if popcount(y) != a[i]:
                            # But we derived it to work? 
                            # Maybe due to an error? 
                            # Then we return -1? 
                            return -1   # but we already checked the conditions? 

                Actually, we can skip the verification if we are confident? 

                But the problem requires the smallest x. And our candidate is the smallest in the residue class? 

                However, what if there is a smaller t that we did not consider? 

                We derived the minimal t for the constraints? 

                Therefore, we can return x.

            But note: what if the residue class does not have a solution? Our candidate is the minimal t that satisfies the popcount constraints for the higher part? 

            However, we must also ensure that the residue r is nonnegative and the entire x is nonnegative.

          Step 5: But what if the system of congruences did not yield any residue? Actually, we built it step by step.

          However, note: the residue r we have is in [0, modulus-1]. Then x = t_min * modulus + r is nonnegative.

          And we must check that x is nonnegative? 

          But we require the smallest nonnegative x? 

          If t_min=0, then x=r, which is in [0, modulus-1] (so nonnegative).

          If t_min>0, then x>0.

          Therefore, we output x.

          But if we found a candidate x, we output it; else if at any step we found an inconsistency, we output -1.

          However, note: the modulus might be huge? and t_min might be huge? and x might be huge? that is acceptable.

          Example: the third sample: 
              2
              60 60

          Then n=2, a=[60,60]

          Step 1: 
              i=0: d = a[1]-a[0] = 0 -> then k=1-0=1.
              Then k=1 <= a[0]=60 -> valid.

          Step 2: 
              For i=0: 
                 k_i=1 -> m_i = 2^(1+1)=4.
                 r_i = (2^1 - 1 - 0) % 4 = (2-1-0)=1 %4 = 1.

              Initialize: modulus=1, residue=0.
              Combine: 
                 g = min(1,4)=1.
                 residue %1 = 0 %1=0, r_i%1=1%1=0? -> 0==0 -> consistent.
                 Then since modulus<=m_i: 
                    t0 = ( (1 - 0) // 1 ) % (4//1) = 1 % 4 = 1.
                 new_residue = 0 + 1*1 = 1.
                 modulus=4.

          Step 3: 
             Compute for i=0: base = residue+0 = 1 -> <4 -> popcount(1)=1 -> v0 = 60 - 1 = 59.
             i=1: base = 1+1=2 -> <4 -> popcount(2)=1 -> v0 = 60 - 1 = 59 -> same.

             Then we have only non-carry? so t_min = (1<<59) - 1.

             Then x = ((1<<59)-1)*4 + 1 = (2^59-1)*4+1 = 2^61 - 4 + 1 = 2^61-3.

          But the sample output is 2305843009213693949.

          What is 2^61? 
               2^61 = 2305843009213693952
               2305843009213693952 - 3 = 2305843009213693949 -> matches.

          Therefore, we output 2305843009213693949.

          However, note: we did not check the popcount for x and x+1? 
            x = 2305843009213693949
            x+1 = 2305843009213693950

          How many bits? 61 bits? 
            x: 2305843009213693949 = 2^61 - 3
            binary: 
               2^61-1: 61 ones.
               2^61-3: 60 ones? because subtract 2: 
                  ...111 - 11 = ...1100? 
                Actually: 
                  2^61-3 = (2^61-1) - 2 -> so the binary has 59 ones? 

          Let me compute: 
            2^61-1 is 61 ones -> popcount=61.
            Then 2^61-3 = (2^61-1) - 2 -> 
                subtract 2: 
                   ...11111111 (61 ones)
                   minus 2: 
                   ...11111101

            Then the popcount: we removed one one? -> 60.

          But we expected a[0]=60 -> works.

          Then x+1 = 2^61-2: 
            2^61-2: ...11111110 -> popcount=60.

          So both 60.

          Therefore, it works.

          But note: the minimal t_min? 
            We had v0=59, so t_min = (1<<59)-1.

          Then x = t_min * 4 + 1 = (2^59-1)*4+1 = 2^61 - 4 + 1 = 2^61-3.

          So it is minimal? 

          How about a smaller t? 
            t_min must be at least the minimal number with popcount 59, which is (1<<59)-1.

          Therefore, we have the algorithm.

          However, note: what if the entire sequence has length 1? 

            Then n=1: 
              Step 1: no consecutive differences -> skip.
              Step 2: no constraints -> then residue=0, modulus=1.
              Step 3: for i=0: base=0+0=0, which is <1 -> popcount(0)=0 -> v0 = a[0] - 0 = a[0].
              Then t_min = (1<<a[0])-1   (if a[0]>0) or 0 if a[0]==0.

              Then x = t_min * 1 + 0 = t_min.

              Then we verify: p(x) = p(t_min) = a[0]? 
                 if a[0]>0: then t_min = (1<<a[0])-1 -> popcount = a[0] -> works.
                 if a[0]==0: then t_min=0 -> popcount(0)=0 -> works.

          So that's correct.

          But what if a[0]=0? then x=0.

          But note: the problem: nonnegative integer x.

          Therefore, we have:

          Implementation:

            Precompute a popcount function for integers (using bin(x).count('1') or a faster method? but for numbers that are at most modulus? modulus is the LCM of the moduli, which is at most 2^(max_k_i+1). The max_k_i? k_i = 1 - d, and d=a[i+1]-a[i] is at least ? d can be as low as? a[i] is at most 60, so d can be as low as -59? then k_i = 1 - d = 1 - (-59)=60? then modulus=2^(61) -> which is about 2^61, which is too big to iterate? But we don't iterate over modulus, we use it as a number? 

            However, in Python, integers are big, but 2^61 is about 2e18, which is representable.

            But in the expression for t_min: 
               If v0 is 59, then (1<<59) is about 5e17, which is acceptable.

            But if v0=60, then (1<<60) is about 1e18 -> acceptable.

          Therefore, we code accordingly.

          But note: the modulus might be huge? and the residue as well? but we are storing them as integers.

          We also note: the residue r is in the range [0, modulus-1]. 

          Steps:

            We'll write:

                t = number of test cases.

                for each test case:
                    n = int(input())
                    a = list(map(int, input().split()))

                    # Step 1: check consecutive differences and trailing ones constraints.
                    valid = True
                    for i in range(n-1):
                        d = a[i+1] - a[i]
                        if d > 1:
                            valid = False
                        elif d <= 0:
                            k = 1 - d
                            if k > a[i]:
                                valid = False
                    if not valid:
                        print(-1)
                        continue

                    # Step 2: build the system of congruences.
                    mod = 1   # modulus
                    res = 0    # residue
                    # If n==1, then we skip the loop.
                    for i in range(n-1):
                        if a[i+1] - a[i] == 1:
                            k_i = 0
                        else:
                            k_i = 1 - (a[i+1]-a[i])
                        m_i = 1 << (k_i+1)   # 2^(k_i+1)

                        # r_i = (2^k_i - 1 - i) mod m_i
                        base_val = (1 << k_i) - 1 - i
                        r_i = base_val % m_i
                        if r_i < 0:
                            r_i += m_i   # ensure nonnegative

                        # Combine: 
                        g = min(mod, m_i)
                        # Check: res % g == r_i % g?
                        if res % g != r_i % g:
                            valid = False
                            break

                        # Update the residue and modulus
                        if mod <= m_i:
                            # Solve: res + t0 * mod ≡ r_i (mod m_i)
                            # Since mod divides m_i? Actually, because mod and m_i are powers of two and mod<=m_i, then mod divides m_i? 
                            #   But note: if mod=2, m_i=4 -> yes.
                            # How to solve? 
                            #   Let diff = r_i - res
                            #   Then we need: t0 * mod ≡ diff (mod m_i)
                            #   But note: because mod divides m_i, then we can write: 
                            #        t0 ≡ (diff // mod) (mod (m_i // mod))
                            #   But first, we need to reduce diff modulo m_i? and we know that diff mod mod is 0? because res ≡ r_i (mod g) and g=mod? 
                            #   Actually, we have res % mod = res (because res is in [0,mod-1]) and r_i % mod = res? because we checked mod divides the gcd? 
                            #   So (r_i - res) is divisible by mod? 
                            #   Then we can compute: 
                            diff = r_i - res
                            #   Now, we can reduce diff modulo m_i? but we don't need to? 
                            #   We want t0 in [0, m_i//mod - 1] such that: 
                            #        t0 = (diff // mod) mod (m_i//mod)
                            t0 = (diff // mod) % (m_i // mod)
                            new_res = res + t0 * mod
                            mod = m_i
                            res = new_res % mod
                        else:
                            # mod > m_i: then the constraint res (mod m_i) is already satisfied? 
                            # So we don't change res, and mod remains the same? 
                            # Actually, we don't change anything? 
                            pass

                    if not valid:
                        print(-1)
                        continue

                    # Step 3: Check the entire sequence and compute v0 and v1.
                    # Precompute: 
                    #   For i in [0, n-1]:
                    #       base = res + i
                    #       if base < mod: 
                    #           pc = popcount(base)
                    #           v = a[i] - pc
                    #       else:
                    #           pc = popcount(base - mod)
                    #           v = a[i] - pc
                    #
                    #   And then check that within non-carry indices, v is the same, and within carry indices, v is the same.

                    # We'll define:
                    v0_set = set()
                    v1_set = set()
                    v0 = None
                    v1 = None
                    for i in range(n):
                        base_val = res + i
                        if base_val < mod:
                            # no carry
                            # Compute popcount of base_val
                            pc = bin(base_val).count('1')
                            v_val = a[i] - pc
                            if v_val < 0:
                                valid = False
                                break
                            if v0 is None:
                                v0 = v_val
                            elif v0 != v_val:
                                valid = False
                                break
                        else:
                            # carry: base_val >= mod
                            base_val2 = base_val - mod
                            pc = bin(base_val2).count('1')
                            v_val = a[i] - pc
                            if v_val < 0:
                                valid = False
                                break
                            if v1 is None:
                                v1 = v_val
                            elif v1 != v_val:
                                valid = False
                                break

                    if not valid:
                        print(-1)
                        continue

                    # Now, we have v0 and/or v1.

                    # If there is at least one non-carry index, then v0 is set; similarly for carry.

                    # If both v0 and v1 are set, then we need to check the relation: 1<=v1<=v0+1? and also v1>=1? 
                    if v0 is not None and v1 is not None:
                        if not (1 <= v1 <= v0+1):
                            valid = False
                    # Also, if v0 is set, then we require that there exists a t with popcount v0? (always) and similarly for v1? 
                    # But note: if only v0 is set, then we require v0>=0? (already from the subtraction we had nonnegative)
                    # Similarly, if only v1 is set, then we require v1>=0? and also we know that the minimal t for v1 is (1<<v1)-2, which requires v1>=1? 
                    if v1 is not None and v0 is None:
                        # only carry
                        if v1 < 1:
                            valid = False
                    # But note: v0 can be 0? 

                    if not valid:
                        print(-1)
                        continue

                    # Now, compute the minimal t.
                    if v0 is not None and v1 is None:
                        # only non-carry
                        if v0 == 0:
                            t_min = 0
                        else:
                            t_min = (1 << v0) - 1
                    elif v0 is None and v1 is not None:
                        # only carry
                        # smallest t such that p(t+1)=v1? 
                        # The smallest number with popcount v1 is (1<<v1)-1, so t = (1<<v1)-2
                        t_min = (1 << v1) - 2
                    else:
                        # both
                        if v1 == v0+1:
                            t_min = (1 << (v0+1)) - 2
                        else: # v1 <= v0
                            k = v0 - v1 + 1
                            # Then the minimal t: 
                            #   t_min = ( (1<<(v1-1)) - 1 ) << (k+1) | ((1<<k)-1)
                            if v1 == 0:
                                # then k = v0+1, but then v1>=1? so this case shouldn't happen? 
                                t_min = 0 # but we break by v1>=1? 
                            else:
                                part1 = (1 << (v1-1)) - 1
                                part1_shifted = part1 << (k+1)
                                part2 = (1 << k) - 1
                                t_min = part1_shifted | part2

                    # Then x = t_min * mod + res
                    x_candidate = t_min * mod + res

                    # Step 4: Verification? 
                    # We'll verify the entire sequence? 
                    #   But the problem says the total n is 500000, so we can do one verification per test case? 
                    #   However, worst-case one test case with n=500000 -> 500000 * 60 = 30e6, which might be borderline in Python? 
                    #   But we can try? 

                    # Alternatively, we can trust the conditions? 

                    # Since the problem constraints are heavy, we skip verification? 

                    # But the problem says: if it exists, compute the smallest x. 

                    # We have built x_candidate as the smallest candidate from our residue class? 

                    # However, note: the residue class modulo mod is fixed, and we chose the smallest t that satisfies the popcount constraints? 

                    # And the conditions we checked should guarantee that the entire sequence matches? 

                    # Therefore, we output x_candidate.

                    # But the sample: 
                    #   first sample: n=5, a=[3,3,4,1,2] -> x_candidate=13? 
                    #   We have to check: 
                    #       13: 1101 -> 3
                    #       14: 1110 -> 3
                    #       15: 1111 -> 4
                    #       16: 10000 -> 1
                    #       17: 10001 -> 2 -> works.

                    # So we output x_candidate.

                    print(x_candidate)

          However, note: we must consider the possibility that the minimal t we computed might not be the only candidate? But we computed the minimal t? 

          But note: the residue class is fixed, and we are looking for the smallest x in that residue class? 

          Therefore, we output x_candidate.

          But what if the problem has no solution even after passing the initial checks? 

          For example: 
                n=2
                a=[1,1]

          Step 1: 
               d = 0 -> k=1, then k<=a[0]=1 -> valid.

          Step 2: 
               k_i=1 -> m_i=4.
               r_i = (2^1-1-0) %4 = (2-1)%4=1.
               Then residue=0, modulus=1 -> combine: 
                    g = min(1,4)=1 -> 0%1=0, 1%1=0 -> consistent.
               Then update: 
                    mod<=4 -> 
                         diff = 1-0=1
                         t0 = (1//1) % (4//1) = 1 % 4 = 1.
                    new_res = 0+1=1.
                    mod=4.

          Step 3: 
               i=0: base=1<4 -> popcount(1)=1 -> v0 = 1-1=0.
               i=1: base=1+1=2<4 -> popcount(2)=1 -> v0=1-1=0 -> same.

               Then t_min = (1<<0)-1 = 0? -> then x_candidate = 0*4+1=1.

          Then we check: 
               x=1: then p(1)=1 -> a0=1 -> ok.
               x+1=2: p(2)=1 -> a1=1 -> ok.

          So output 1? 

          But is there a smaller x? 
              x=0: 
                 p(0)=0 -> not 1.
              x=1 is the smallest.

          Therefore, correct.

          But the problem says: output the smallest x.

          However, what if there is a solution with the same residue modulo mod but a smaller t? 

          We computed the minimal t that satisfies the popcount condition? 

          Therefore, we have the minimal x in the residue class? 

          But note: the residue class is modulo mod, and we are free to choose t, but t must be nonnegative? and we started from t_min=0? 

          Therefore, we output x_candidate.

          But what if the residue class has a solution with a negative t? -> we don't consider because x must be nonnegative.

          Therefore, we output the candidate.

          However, we must be cautious: the modulus might be very large, and the minimal t we computed might be very large? But that's the problem.

          We'll run the sample test cases.

          Sample 2: 
               3
               2 1 2

          Step 1: 
              i0: d= a[1]-a[0]=1-2=-1 -> k=1-(-1)=2 -> check: k=2<=a[0]=2 -> valid.
              i1: d= a[2]-a[1]=2-1=1 -> k=0.

          Step 2: 
              For i0: k_i=2 -> m_i=2^3=8.
                     r_i = (2^2-1-0) %8 = (4-1)%8=3.
              Initialize: mod=1, res=0.
              Combine: 
                 g = min(1,8)=1 -> 0%1=0, 3%1=0 -> consistent.
                 Then update: mod<=8 -> 
                     diff = 3-0=3
                     t0 = (3 // 1) % (8//1) = 3 % 8 = 3.
                 new_res = 0+3=3, mod=8.

              For i1: k_i=0 -> m_i=2^1=2.
                 r_i = (2^0-1-1) %2 = (1-1-1) %2 = (-1)%2=1.
                 Now: current mod=8, m_i=2.
                 g = min(8,2)=2.
                 Check: res=3 %2 = 1, r_i=1 -> 1==1 -> consistent.
                 Then since mod>m_i: we do nothing.

          Step 3: 
              i0: base=3+0=3 <8 -> popcount(3)='11' -> 2 -> v0 = 2-2=0.
              i1: base=3+1=4 <8? 4<8 -> popcount(4)=1 -> v0 = 1-1=0 -> same.
              i2: base=3+2=5<8 -> popcount(5)=2 -> v0=2-2=0.

              Then only non-carry -> t_min = (1<<0)-1 = 0? if v0=0 -> then 0? 
              Then x_candidate = 0*8+3=3.

          Then check: 
              x=3: 11 -> popcount=2 -> a0=2.
              x+1=4: 100 -> popcount=1 -> a1=1.
              x+2=5: 101 -> popcount=2 -> a2=2.

          So output 3.

          The sample output is 3.

          Therefore, we are confident.

          Let's run the last sample: 
                2
                8 0   -> output -1.

          Step 1: 
                d = 0-8 = -8 -> k=1-(-8)=9.
                Check: k=9<=a[0]=8 -> fails.

          So we output -1.

          Therefore, we code accordingly.

          However, note: we have to be cautious for the case when v0 is set to 0? then t_min=0.

          We'll code the popcount with bin(x).count('1') for the values in the range [0, mod-1]? and mod is at most 2^61? but the numbers base_val = res+i might be huge? 

          Actually, in the non-carry case: base_val = res+i < mod, and mod is at most 2^max_k_i? and max_k_i<=60? Actually, k_i=1-d, and d>=? d can be as low as -59? then k_i=60? so mod=2^61? then base_val < 2^61, which is about 2e18 -> which is a big integer, but in Python we can compute bin(x).count('1')? 

          However, the cost: the number of bits in base_val is about 61, so bin(x) will create a string of length about 61? Then the cost per number is 61? Then for n=500000: 500000 * 61 = 30.5e6 -> which is acceptable? 

          But worst-case one test case with n=500000 -> 30e6 operations -> in PyPy/C++ it's acceptable, in Python we hope 2 seconds? 

          Alternatively, we can use a faster popcount? 

          We can use:

            def popcount(x):
                # for x in [0, 2^61] 
                # use bit-level tricks? 
                c = 0
                while x:
                    c += 1
                    x &= x-1
                return c

          This will take at most 61 iterations per number? same as the string conversion? 

          But we try the string conversion: for numbers with 60 bits, the string conversion might be faster? 

          We'll use the bin(x).count('1') as it is straightforward.

          But note: we are using it in the inner loop for i in [0, n-1]? and the total n is 500000? and the total n across test cases is 500000, so worst-case one test case with n=500000 -> 500000 * (cost of bin(x) for x<2^61) -> which is 500000 * 60 operations? 

          We'll code it and hope it passes.

          Let me code.

          But note: in the carry case: base_val2 = base_val - mod, and base_val is in [mod, mod+n-1]? then base_val2 is in [0, n-1]? so we can compute popcount for small numbers? 

          Actually, base_val2 is small: at most n-1? and n<=500000, so base_val2<=500000? Then we can precompute the popcounts for numbers up to 500000? 

          How? 

            We can precompute an array popcount_arr for numbers from 0 up to max_n (which is 500000) for each test case? 

          But we have multiple test cases? and the total n is 500000, so worst-case one test case with n=500000? then we can precompute an array for [0, 500000]? 

          Alternatively, we can compute with bin(x).count('1') for numbers up to 500000? which has about 19 bits -> cost 19 per number? then total 500000*19 = 9.5e6 per test case? 

          But note: we have two cases: 
              non-carry: base_val = res+i, which might be huge? (up to mod-1, which is 2^61) -> we use bin(x).count('1') for huge numbers? 
              carry: base_val2 is small -> we can use a precomputed array? 

          But we don't know which test case is which? 

          We can precompute the popcount for numbers up to 500000 for the entire program? 

          However, the total n across test cases is 500000, but the numbers base_val in the non-carry case might be huge? 

          We decide to use:

            For base_val in the non-carry case: we use bin(x).count('1') for x in the range [0, mod-1] (which might be huge) -> but we do it only for the indices i such that base_val = res+i < mod? and mod might be huge? but the values of base_val are at most mod-1? which is huge? 

          But note: mod is the LCM of the moduli, which is a power of two. And we only do it for n numbers? 

          Therefore, we use bin(x).count('1') for the non-carry numbers? 

          Alternatively, we can use the same method for both: bin(x).count('1')? 

          We'll do:

            popcount_func = lambda x: bin(x).count('1')

          But we note: for x=0, bin(0) is "0" -> count gives 0? correct.

          We'll code accordingly.

          However, note: in the non-carry case, base_val = res+i, which might be a huge integer? and converting to a string might be O(61) which is acceptable? 

          Therefore, we code.

          Summary of the code for one test case:

            n = int(input().strip())
            a = list(map(int, input().split()))

            # Step 1: Check consecutive differences.
            valid = True
            for i in range(n-1):
                d = a[i+1] - a[i]
                if d > 1:
                    valid = False
                    break
                elif d <= 0:
                    k = 1 - d
                    if k > a[i]:
                        valid = False
                        break
            if not valid:
                print(-1)
                continue

            # Step 2: Build the system of congruences for i in range(n-1)
            mod = 1
            res = 0
            # If n==1, skip the loop.
            for i in range(n-1):
                if a[i+1] - a[i]] == 1:
                    k_i = 0
                else:
                    k_i = 1 - (a[i+1]-a[i]])
                m_i = 1 << (k_i+1)   # 2^(k_i+1)

                # Compute r_i = ( (1<<k_i) - 1 - i ) mod m_i
                base_val = (1 << k_i) - 1 - i
                r_i = base_val % m_i
                if r_i < 0:
                    r_i += m_i

                # Combine with the current (mod, res)
                g = min(mod, m_i)
                if (res % g) != (r_i % g):
                    valid = False
                    break

                # Update the residue
                if mod <= m_i:
                    # Solve: res + t0 * mod = r_i (mod m_i) for t0 in [0, m_i//mod - 1]
                    # Note: (r_i - res) is divisible by g? and g=mod? -> so divisible by mod? 
                    #   Actually, we have res % g = r_i % g, and g=min(mod, m_i)=mod (since mod<=m_i) -> so res % mod = res (because res in [0,mod-1]) and r_i % mod = res? 
                    #   Therefore, (r_i - res) is divisible by mod? 
                    diff = r_i - res
                    # We want t0 such that: t0 = (diff // mod) mod (m_i // mod)
                    # Because mod divides m_i, then the modulus for t0 is (m_i // mod)
                    step_size = m_i // mod
                    # diff is divisible by mod? 
                    #   If not, then we have a problem? 
                    #   But we know that diff % mod == 0? 
                    if diff % mod != 0:
                        # This should not happen? 
                        valid = False
                        break
                    t0 = (diff // mod) % step_size
                    res = res + t0 * mod
                    mod = m_i
                    # Reduce res modulo mod? 
                    res %= mod
                else:
                    # mod > m_i: then the current residue already satisfies the congruence? 
                    # Do nothing: mod remains mod, res remains res.
                    pass

            if not valid:
                print(-1)
                continue

            # Step 3: Check the entire sequence and compute v0 and v1.
            # We are going to iterate for each i and compute the popcount for base = res+i (if base < mod) or base - mod (if base>=mod)
            v0 = None
            v1 = None
            for i in range(n):
                base_val = res + i
                if base_val < mod:
                    # no carry
                    pc = bin(base_val).count('1')
                    v_val = a[i] - pc
                    if v_val < 0:
                        valid = False
                        break
                    if v0 is None:
                        v0 = v_val
                    elif v0 != v_val:
                        valid = False
                        break
                else:
                    base_val2 = base_val - mod
                    pc = bin(base_val2).count('1')
                    v_val = a[i] - pc
                    if v_val < 0:
                        valid = False
                        break
                    if v1 is None:
                        v1 = v_val
                    elif v1 != v_val:
                        valid = False
                        break

            if not valid:
                print(-1)
                continue

            # If we have both v0 and v1, check the relation.
            if v0 is not None and v1 is not None:
                if not (1 <= v1 <= v0+1):
                    print(-1)
                    continue
            # If only v1 is set, then we require v1>=1? 
            if v1 is not None and v0 is None:
                if v1 < 1:
                    print(-1)
                    continue

            # Now, compute the minimal t.
            if v0 is not None and v1 is None:
                if v0 == 0:
                    t_min = 0
                else:
                    t_min = (1 << v0) - 1
            elif v0 is None and v1 is not None:
                t_min = (1 << v1) - 2
            else:
                if v1 == v0+1:
                    t_min = (1 << (v0+1)) - 2
                else:
                    k = v0 - v1 + 1
                    # If v1==0, then skip? but we know v1>=1 by the check above? 
                    # Compute: 
                    part1 = (1 << (v1-1)) - 1   # a number with (v1-1) ones? 
                    part1_shifted = part1 << (k+1)  # shift left by k+1 bits
                    part2 = (1 << k) - 1
                    t_min = part1_shifted | part2

            x_candidate = t_min * mod + res
            print(x_candidate)

          But note: we must check that x_candidate is nonnegative? 

          Since t_min>=0, mod>0, res>=0, then x_candidate>=0.

          We'll run the provided examples.

          Example 1: n=5, a=[3,3,4,1,2] -> we did by hand: 13.

          Example 2: n=3, a=[2,1,2] -> 3.

          Example 3: n=2, a=[60,60] -> 2305843009213693949.

          Example 4: n=2, a=[8,0] -> -1.

          We output accordingly.

          However, note: the modulus and residue might be huge? and the multiplication might be huge? but we are using Python integers.

          We hope it passes.

          Let me run the sample with a=[60,60] in code:

            Step 1: 
                d = 0 -> k=1-0=1 -> valid (1<=60)
            Step 2: 
                k_i=1 -> m_i=4.
                base_val = (1<<1)-1 - 0 = 1 -> r_i = 1 %4 = 1.
                Then: mod=1, res=0 -> combine: 
                    g = min(1,4)=1 -> 0%1=0, 1%1=0 -> consistent.
                    Then: mod<=m_i: 
                         diff = 1-0=1
                         step_size = 4//1=4
                         t0 = (1//1) %4 = 1
                    new_res = 0+1=1, mod=4.

            Step 3: 
                i0: base_val=1+0=1 -> popcount(1)=1 -> v0 = 60-1=59.
                i1: base_val=1+1=2 -> popcount(2)=1 -> v0=59 again.

                Then only non-carry: t_min = (1<<59)-1.

                x_candidate = ((1<<59)-1)*4 + 1 = (2^59-1)*4+1 = 2^61 - 4 + 1 = 2^61-3 = 2305843009213693949.

          Therefore, it matches.

          We'll code accordingly.

          But note: the popcount for the non-carry case for base_val might be expensive? We are doing bin(x).count('1') for x that is in the range [0, mod-1]? and mod might be 2^61? but the numbers base_val = res+i are at most mod-1? and there are n=500000 numbers? 

          However, the numbers base_val for non-carry are consecutive? and we are doing n popcounts of numbers that are large? 

          But the numbers are consecutive? and we can compute the popcount for consecutive numbers by simulating the addition? 

          However, we already have a method that uses bin(x).count('1')? and for one number with 60 bits, it's 60 operations? then 500000 * 60 = 30e6 -> acceptable.

          We'll code and hope.

          Note: We must be cautious for the case when n=0? but n>=1.

          Let me run the sample n=1: a=[0] -> 
            Step 1: no consecutive, so skip step1 and step2.
            Step3: 
                i0: base_val = 0+0=0 -> <1? (mod=1) -> so non-carry: 
                    pc = bin(0).count('1') = 0 -> v0 = 0-0=0.
                Then only non-carry: t_min = (1<<0)-1 = 0 -> x_candidate=0.

          Output:0.

          Also, a=[1]: 
                base_val=0 (if residue=0) -> then pc=0 -> v0=1 -> then t_min = (1<<1)-1 = 1.
                x_candidate = 1*1+0=1.

          Then p(1)=1 -> works.

          Therefore, we output the code.

          But note: the problem says the smallest nonnegative integer x? 

          We have computed the smallest x? 

          However, what if there is a solution with the same residue mod mod but a smaller t? 

          We computed the minimal t that satisfies the popcount constraint? 

          But note: t is the quotient, and we are free to choose any t that satisfies the popcount constraint? and we take the smallest t? 

          Therefore, we have the smallest x in the residue class? 

          And since the residue class is fixed, we have the smallest x.

          We'll submit.

          But note: the problem constraints: total n<=500000, so worst-case one test case with n=500000, and we do 500000 * (popcount for one number) and popcount for numbers up to 2^61? which is 61 per number? then 500000*61=30500000, which is 30.5e6 -> in Python, we hope 2 seconds? 

          We'll run locally with worst-case: 
                t=1, n=500000, a = [0]*500000   -> then we have to check the consecutive differences: 
                  d=0 for all -> k=1-0=1 for each? 
                Then the modulus will become 2^ (max_k_i+1) = 2^ (max(1)+1)=4? 
                Then residue will be ... 
                Then we compute for each i: base_val = res+i, which is at most 4+500000? so we are in the non-carry case? 
                Then we compute popcount for each i in the range [res, res+n-1]? which is 500000 numbers? 

          But note: the numbers are consecutive and increasing? and we can compute the popcounts for consecutive numbers in a more efficient way? 

          However, we are using bin(x).count('1') for each number? 

          But the numbers are small? (at most 500000) so we can precompute the popcounts for numbers from 0 to 500000? 

          How? 

            We can precompute an array for popcount for numbers from 0 to max_val, where max_val = max(res+n-1, ...) but in the non-carry case, base_val = res+i < mod, and mod might be 4? then the numbers are at most 4+500000? but we don't know mod? 

          Alternatively, we can do:

            if mod is small (say <= 1000000), then we precompute the popcounts for numbers from 0 to mod+n? 

          But mod can be as large as 2^61, so we cannot precompute for that.

          Therefore, we do:

            if mod <= some threshold (say 10**6) then we precompute an array for popcounts for [0, mod+n]? 
            else: we use bin(x).count('1') for each number.

          However, we note that in the non-carry case, the numbers base_val are in [res, res+n-1] and res < mod, so the numbers are at most mod+n-1, which might be huge? 

          But if mod is huge, then the numbers base_val are huge? and we have to use bin(x).count('1')? 

          But we hope that in the worst-case the modulus is huge? and the non-carry case will be the entire sequence? then we do 500000 * (popcount for huge numbers) -> 500000*61=30.5e6 -> acceptable.

          We'll leave it as bin(x).count('1').

          Let me test with n=500000 and a=[0]*500000: 
            Step1: 
                for i in range(499999): 
                    d=0 -> k=1 -> valid? 
                Then step2: 
                    We do 499999 iterations: 
                      each: k_i=1 -> m_i=4 -> base_val = (1<<1)-1 - i = 1 - i -> which is negative? 
                      then r_i = (1-i) % 4 -> which we do: 
                         r_i = (1-i) % 4 -> then we combine.

            This might be heavy? 

          Actually, the modulus starts at 1 and then becomes 4, and then remains 4? because 4 is the LCM for the entire sequence? 

          Then in step2: 
             for the first iteration: i0: 
                 k_i=1, m_i=4, base_val=1-0=1 -> r_i=1 %4=1.
                 Then combine: 
                     g = min(1,4)=1 -> 0%1=0, 1%1=0 -> then update: 
                         t0 = (1-0)//1 % (4//1)=1 %4=1 -> new_res=0+1=1, mod=4.
             for i from 1 to 499998:
                 k_i=1 -> m_i=4.
                 base_val = 1 - i (for i>=1, negative) 
                    r_i = (1-i) % 4 -> 
                    e.g., i=1: (1-1)=0 %4=0.
                    Then g = min(4,4)=4.
                    Check: res=1 %4=1, r_i=0 %4=0 -> 1 !=0 -> invalid? 

          But wait: we have a sequence of 500000 zeros? 
            Condition: 
               We need x such that p(x+i)=0 for i=0 to 499999.

            But p(x+i)=0 implies x+i=0? 
            Then x=0, then x+0=0 -> p(0)=0 -> works, but then x+1=1 -> p(1)=1 -> not 0.

            So no solution? 

          Therefore, we break in step2: at i=1, we get residue=1 and r_i=0 -> not congruent mod 4? -> output -1.

          So we don't get to step3.

          Therefore, it's correct.

          We'll run locally with the worst-case of a=[0]*500000: it should break in step2.

          We'll code accordingly.

          We'll submit.

          Note: we must be cautious for the modulus update: 
            In the step2 loop, if mod > m_i, we do nothing? 

          But in the example above: 
            After the first iteration: mod=4, res=1.
            Then for i=1: 
                k_i=1 -> m_i=4.
                r_i = (1<<1)-1 - 1 = 1-1=0 -> 0%4=0.
                Then g = min(4,4)=4.
                Then check: res %4 = 1, r_i%4=0 -> 1 !=0 -> break.

          Therefore, we output -1.

          So the code is as follows.

          We'll write the code accordingly.

          Note: We use the same popcount function for the small and large numbers: bin(x).count('1').

          Let me write the complete code.

          We note: we must not do the step3 if step2 breaks.

          We'll do:

            for the step2 loop: if we break due to inconsistency, then output -1.

          And we break out of the loop.

          We hope it passes the sample and the constraints.

          We'll run the sample test cases.

          Sample 1: n=5, a=[3,3,4,1,2] -> we did by hand.

          We'll run in code:

            a = [3,3,4,1,2]

            Step1:
                i0: d=0 -> k=1-0=1 -> 1<=3 -> valid.
                i1: d=1 -> k_i=0 -> then skip? but note: we do k_i=0 for the next step.
                i2: d=-3 -> k_i=1-(-3)=4 -> check: 4<=4? -> valid.
                i3: d=1 -> k_i=0.

            Step2:
                i0: k_i=1 -> m_i=4 -> r_i = (1<<1)-1 -0 = 1 %4=1.
                    mod=1, res=0 -> g=min(1,4)=1 -> 0%1=0, 1%1=0 -> consistent.
                    Then update: mod<=4 -> 
                         diff = 1-0=1
                         step_size = 4//1=4
                         t0 = 1 %4=1
                    new_res = 0+1=1, mod=4.

                i1: k_i=0 -> m_i=2 -> r_i = (1<<0)-1 -1 = 1-1-1 = -1 %2 = 1 (since -1 %2 =1 in Python? -> yes)
                    g = min(4,2)=2.
                    Check: res=1 %2=1, r_i=1 %2=1 -> consistent.
                    Then since mod>m_i: do nothing.

                i2: k_i=4 -> m_i= 1<<5 =32
                    r_i = (1<<4)-1 -2 = 15-2=13 %32=13.
                    g = min(4,32)=4.
                    Check: res=1 %4=1, r_i=13 %4=1 -> 1==1 -> consistent.
                    Then since mod<=32: 
                         diff=13-1=12
                         step_size=32//4=8
                         t0 = (12//4) %8 = 3 %8=3
                    new_res = 1 + 3*4 = 13, mod=32.

                i3: k_i=0 -> m_i=2
                    r_i = (1<<0)-1-3 = 1-1-3 = -3 %2 = 1 (because -3 %2=1 in Python)
                    g = min(32,2)=2.
                    Check: res=13 %2=1, r_i=1 -> consistent.
                    Then mod>m_i: do nothing.

            Then step3: 
                i0: base_val=13+0=13 <32? -> yes -> bin(13)='1101' -> count=3 -> v0=3-3=0.
                i1: base_val=14 -> '1110' -> count=3 -> v0=0? -> 3-3=0 -> same.
                i2: base_val=15 -> '1111' -> count=4 -> v0=4-4=0 -> same.
                i3: base_val=16 -> 16>=32? no -> then non-carry? 16<32 -> '10000' -> count=1 -> v0=1-1=0 -> same.
                i4: base_val=17 -> '10001' -> count=2 -> v0=2-2=0 -> same.

                Then only non-carry: t_min = (1<<0)-1 = 0? 
                Then x_candidate = 0*32+13=13.

            Output:13.

          Therefore, correct.

          We'll code accordingly.

          We'll run the sample with a=[2,1,2] as above? 

          We did by hand: x_candidate=3.

          We'll run:

            a=[2,1,2]

            Step1:
                i0: d=1-2=-1 -> k=1-(-1)=2 -> valid (2<=2)
                i1: d=2-1=1 -> k=0.

            Step2:
                i0: k_i=2 -> m_i=8 -> r_i = (1<<2)-1 -0 = 4-1=3 %8=3.
                    mod=1, res=0 -> g=min(1,8)=1 -> 0%1=0, 3%1=0 -> consistent.
                    update: mod<=8 -> 
                         diff=3-0=3
                         step_size=8//1=8
                         t0=3 %8=3
                    new_res=0+3=3, mod=8.
                i1: k_i=0 -> m_i=2 -> r_i = (1<<0)-1-1 = 1-1-1 = -1 %2=1.
                    g=min(8,2)=2.
                    Check: res=3 %2=1, r_i=1 -> consistent -> then do nothing.

            Step3:
                i0: base_val=3+0=3<8 -> bin(3)='11' -> popcount=2 -> v0=2-2=0.
                i1: base_val=4<8 -> bin(4)='100' -> popcount=1 -> v0=1-1=0 -> same.
                i2: base_val=5<8 -> bin(5)='101' -> popcount=2 -> v0=2-2=0 -> same.

            Then x_candidate = 0*8+3=3.

          Correct.

          We'll submit.

          Note: We must be cautious for the case when the modulus is 0? but we start at 1 and then update to a power of two, so modulus>=1.

          We'll write the code.

          We note: the modulus update: 
            In the step for combining, we do:

                if mod <= m_i:
                    ... then update mod to m_i and update res to (res + t0*mod_old) % m_i.

          But note: we do:

                step_size = m_i // mod   # integer division
                t0 = (diff // mod) % step_size
                res = res + t0 * mod
                mod = m_i
                res %= mod   # to keep in [0,mod-1]

          This is correct.

          We'll code accordingly.

          We hope it passes.

          We'll write the code in Python.

          Note: We must use // for integer division.

          Let's code.

          IMPORTANT: In the step2 loop, we break if we find an inconsistency. Then we output -1.

          We'll now code.