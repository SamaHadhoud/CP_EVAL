 We are guaranteed that the total sum of n^2 across test cases is <= 10000, so we can safely do O(n^2) per test case.

 Steps:
 1. For each test case, read n and the matrix.
 2. Identify bad rows: a row is bad if it has all distinct values (and since the values are between 1 and n, having n distinct values means it's a permutation).
 3. Similarly, identify bad columns: a column is bad if it has all distinct values.

 4. The minimum number of modifications is max(|bad_rows|, |bad_cols|). However, we can use a strategy:
    - We can fix one bad row and one bad column by changing one cell at their intersection (if we change it to break both, we break the permutation in both).
    - Then, if there are leftover bad rows, we fix each by changing one cell in that row (we can change any cell, but we must avoid making the column become a permutation? Actually, note: we are allowed to break the row without necessarily breaking the column again? But we must be cautious: we don't want to create a new bad column.

 However, note: after the initial step, we have to fix the remaining bad rows and bad columns independently. But we must be cautious: when we fix a bad row by changing a cell, we might break a column that was already good? Actually, the problem does not require that we preserve the goodness of already good rows and columns. However, we must not turn a good column into a bad one? Actually, we can: because if a column had duplicates, and we change one element, it might become distinct? But note: we are changing one element. However, if the column had duplicates, then even if we change one element, it might still have duplicates? Not necessarily: if the duplicate was at two positions and we change one of them, then the duplicate is gone? 

 But note: the conditions only require that each row and column *contains* duplicates (i.e., at least one duplicate). This does not require that the entire set has duplicates for every element. Only that there is at least one repeated value.

 However, the problem is that we might accidentally fix a bad row by creating a duplicate in that row, but then the column that we changed might become bad? Actually, it's possible.

 Alternate approach from editorial guidelines: 
   - The minimum number of modifications is the maximum of the number of bad rows and bad columns. Why?
     Because one modification can fix one bad row and one bad column simultaneously (if placed at their intersection). Then any remaining bad rows or columns must be fixed individually.

 But note: if we change a cell that is at the intersection of a bad row and a bad column, then we break both? 
   - Before: the row was a permutation, and the column was a permutation. After changing one cell, the row is no longer a permutation (because we broke one value) and the column is no longer a permutation. So yes.

 Therefore, we can do:
   Let r = len(bad_rows), c = len(bad_cols)
   We need at least max(r, c) modifications.

 How to assign?
   We can pair bad rows and bad columns: for the first min(r, c) pairs, we change the cell at (bad_row[i], bad_col[i]).
   Then for the remaining bad rows (if any), we change a cell in that row arbitrarily (but we must avoid making a column become a permutation? Actually, we can change a cell that is in a column that is not bad? Or even if it's bad, we are going to fix it later? But note: we have already fixed the min(r,c) pairs, and the remaining bad columns (if any) will be fixed by changing a cell in that column. However, the remaining bad rows and bad columns are independent.

 But caution: we are going to change a cell that might lie in a column that is not bad? Then that column might become bad? For example, if a column was good because it had two 1's and we change one of the 1's to a 2, then if the 2 is already present in the column? Then we break the duplicate? Actually, we might. However, note: a column that is not bad already has duplicates. Changing one element might break that duplicate? But then we must choose the new value so that we don't break the duplicate? Or if we break one duplicate, we might create another? 

 Actually, the condition is only that the column must contain at least one duplicate. So even if we break one duplicate, if there is still at least one duplicate elsewhere, then it's okay. However, we don't know. Therefore, to be safe, we can do:

   For a remaining bad row (after the pairs), we change an entry in that row to a value that already exists in that row? But then we create a duplicate in the row? But wait: if we change an element to a value that is already in the row, then we break the permutation (we create a duplicate). However, we must also consider the column: we want the column to remain non-bad (if it was good) or if it was bad then we are going to fix it later? Actually, the remaining bad rows are fixed independently and the remaining bad columns independently? But we are not going to fix the same cell twice.

 However, note: the problem does not require that we don't break a good column? Actually, we are allowed to modify as many times as we want (with minimum total). But we must ensure that after all modifications, every row and every column has duplicates.

 How about: after we fix the pairs, the remaining bad rows are fixed by changing the first column? But then the first column might become bad? Then we fix the remaining bad columns by changing the first row? But if we change the first row and the first column multiple times, we might break the first row again? 

 Therefore, the editorial guideline suggests:

   For the pairs: change the intersection to 1 (if not 1) or 2 (if 1) to break both.

   For a remaining bad row i: change the first column (column0) in that row. We choose the new value to be a value that is already present in column0 (so that the column does not become all distinct). But note: if we change the element at (i,0) to a value that is already present in column0, then we are creating a duplicate in column0? Actually, if the value we choose is already present in column0, then after the change, column0 will have that value at least twice (because we are replacing one element by a value that was already there). So column0 will not be a permutation. Therefore, we are safe.

   Similarly, for a remaining bad column j: change the first row (row0) in that column. We choose the new value to be one that is already present in row0? Then row0 will have a duplicate? Actually, we are changing row0 at column j. If we set it to a value that is already in row0, then row0 will have that value at least twice? But wait: if the value we choose was already in row0 at a different column, then yes. So row0 becomes non-permutation.

 However, what if the entire row0 is distinct? Then after the change, if we set it to a value that was already in row0, then we have a duplicate? But if we set it to a value that is already present in row0, then yes. But note: row0 might be bad? Then we are going to fix it in the pair step? Actually, if row0 is bad, it would be in bad_rows and then we would have fixed it in the pair step. So if we are at the remaining bad column step, then row0 must not be bad (because we have fixed min(r,c) pairs). Therefore, row0 is not bad -> it already has a duplicate. Therefore, if we change one element to a value that is already in row0, then row0 still has a duplicate? Actually, if we change one element to a value that already appears in row0, then that value becomes at least two? But note: if the value we choose was already in row0 at a different position, then the duplicate remains. However, if we remove an occurrence of a value and set it to a value that already exists, then we break one duplicate (if the value we removed was part of a duplicate) and create a new duplicate? But we are not concerned: we only care that row0 still has at least one duplicate. Actually, row0 was not bad (so it already had at least one duplicate) and we are changing one element. We must ensure that after the change, row0 still has at least one duplicate. How? 

   We can choose the new value for the cell (0, j) to be a value that appears at least twice in row0? But wait: we are about to change the value at (0,j). So the current row0 has a duplicate. Let the current row0 be [a0, a1, ..., a_{n-1}]. Since it is not bad, there exists at least one duplicate. We are changing a0j to v. We want that in the new row0, there is at least one duplicate.

   We can do: 
      Let S = set of values in row0 (excluding the one we are going to change? Actually, we are going to change the element at (0,j)). 
      Then if we set the new value to a value that is in S, then the duplicate condition is preserved? Not exactly: if the value v was already in S, then after the change, the frequency of v becomes (previous frequency of v) + 1 (if the element we are replacing was not v) or the same (if it was). 

   Actually, we can avoid breaking the row0 by:
      Let the current value at (0,j) be a. We are going to change it to v.
      Consider row0 without the element at j: then we have a set T (which is row0 without the element at column j). 
      Since row0 originally had a duplicate, if we remove one element, we might break the duplicate? But note: if the duplicate was at two positions and we remove one of them, then the duplicate is gone? 

   Therefore, we must be careful: we want to choose v such that either:
      - v is already in T (then after putting v at (0,j), the row0 will have v at two different positions: one in T and one at j) -> so duplicate is preserved? Actually, if v was already in T, then after the change, v appears at least twice: once in T and once at j? But wait: the element we are replacing was a. So if a was v? Then we are not changing the set. Then we don't break the duplicate? Actually, if a==v, then the row doesn't change? So that's no good.

   Actually, we are allowed to break the row0? But row0 was fixed in the pair step? So it is no longer bad. However, we must not make it bad? But if we break the duplicate and make it a permutation, then row0 becomes bad again? And we don't want that.

   Therefore, we must ensure that after changing (0,j) to v, row0 still has at least one duplicate. How?

   Let the current row0: R = [r0, r1, ..., r_{n-1}]
   We are going to change r_j (which is a) to v.

   The new row: R' = [r0, ..., r_{j-1}, v, r_{j+1}, ...]

   We want R' to have duplicates.

   We can choose v such that v is already present in the rest of the row (i.e., in R without the j-th element). Then v appears at least twice: at j and at some other position. So that creates a duplicate.

   But note: if we choose v that is not in the rest of the row, then we have a row of distinct values? Then we break row0.

   Therefore, we must choose v from the rest of the row? But what if the rest of the row is already distinct? Then we cannot choose such v? Then we have to break the row? Actually, that should not happen because row0 was not bad (so it already had a duplicate) and we are removing one element. So if the rest of the row has n-1 elements and they are distinct, then the duplicate must have been the element we removed? Then the rest of the row has no duplicates? Then we must choose v to be one of the values in the rest of the row? Then we create a duplicate? 

   Example: 
        row0 = [1, 2, 2, 3]   (n=4). This has a duplicate (the two 2's). 
        We are going to change the element at column j=0 (which is 1) to a value v. 
        The rest of the row: [2,2,3] -> has duplicates (the two 2's). 
        Then if we set v=2, then the new row = [2,2,2,3] -> has duplicates (the three 2's). 
        If we set v=3, then the new row = [3,2,2,3] -> has duplicates (the two 2's and the two 3's).

   But what if the duplicate was exactly the element we are removing? 
        row0 = [1,1,2,3]   (duplicate at the two 1's). 
        We are going to change the first element (at column0). 
        The rest of the row: [1,2,3] -> distinct. 
        Then we must choose v to be one of {1,2,3}. 
        If we choose v=1: then new row = [1,1,2,3] -> still has duplicate (the two 1's). 
        If we choose v=2: then new row = [2,1,2,3] -> has duplicate (the two 2's).
        Similarly, v=3: then new row = [3,1,2,3] -> has duplicate (the two 3's).

   Therefore, in any case, if we choose v from the rest of the row, we are safe? Because the rest of the row has at most n-1 distinct values? Actually, no: the rest of the row might have n-1 distinct values? But note: the entire row originally had a duplicate, so the distinct count was at most n-1. Then when we remove one element, the distinct count might remain the same or become one less? But the rest of the row has n-1 elements. The distinct count of the rest of the row is at most n-1? But actually, it can be n-1? 

   However, if the rest of the row has n-1 distinct values, then the entire row originally had at least two of one value. The element we removed was one of the duplicates? Then the rest of the row still has at least one of that duplicate? Then the distinct count of the rest of the row is at most n-2? Actually, no: 
        Example: [1,2,3,1] -> distinct values: 1,2,3 -> three distinct. Then if we remove the first element (1), then the rest is [2,3,1] -> distinct? Then distinct count is 3 (which is n-1 for n=4). 

   But then the entire row originally had two 1's. After removing the first 1, we have only one 1. Then the rest of the row has distinct values? Then we have to choose v from the rest of the row? Then we set the first element to 2, then we get [2,2,3,1] -> duplicates? Actually, the two 2's. So it's safe.

   Therefore, we can always choose any value from the rest of the row? But we must avoid the current value? Actually, we don't have to avoid the current value? But note: if we set it to the same value, we do nothing? So we don't want that.

   Actually, we are going to change the value. So we want a value that is in the rest of the row? Then we can choose any value that appears in the rest of the row? 

   Similarly for the column: for a remaining bad column, we change the first row element of that column. We choose the new value to be a value that is already present in the rest of the column (excluding the element we are changing). Then the column will have a duplicate.

   However, what if the entire column is distinct? Then the rest of the column (n-1 elements) must have n-1 distinct values? Then we choose one of them? Then we set the top to that value, and then the column will have two of that value? Then it becomes non-permutation.

   But note: the column was bad? Then it was a permutation. After we change the top element to a value that is already in the rest of the column, then that value appears twice -> so it is no longer a permutation. Therefore, it becomes good? Actually, it becomes having a duplicate -> so it satisfies the condition.

   Therefore, the plan:

     Step 1: Identify bad_rows and bad_cols.

     Step 2: k = min(len(bad_rows), len(bad_cols))
        For i in range(k):
            row_i = bad_rows[i], col_i = bad_cols[i]
            We change X[row_i][col_i] to a value that breaks the permutation? Actually, we can choose any value that is not the current one? But we are constrained to 1..n. However, we can choose arbitrarily.

            But note: we must avoid making the row become a permutation? Actually, we break the permutation by introducing a duplicate? How? By setting the value to one that already exists in the row? But we don't know the row? Alternatively, we can set it to 1 if the current value is not 1, or 2 if the current value is 1? Then we are sure that we break the permutation? Actually, if we set it to 1, and 1 is already in the row? Then we create a duplicate? If 1 is not in the row? Then we break the permutation? Actually, no: if we set it to 1 and 1 was not in the row, then we break the permutation? Actually, the row becomes having 1 twice? No: we set one element to 1. If 1 was not in the row, then we have introduced a new distinct value? Then we break the permutation? Actually, we break the permutation because the row was a permutation (all distinct) and now we have set an element to 1 which was missing? Then the row becomes having 1 and all others? Then it becomes having all distinct values? Then we didn't break the permutation? 

        Correction: 
            The row was a permutation: all distinct and covering 1..n. Then if we set one element to 1, and 1 was already in the row? Then we create a duplicate? If 1 was not in the row? That cannot happen because the row is a permutation of 1..n. So 1 must be in the row. Similarly, if we set it to 1, then we have two 1's? Then the row is no longer a permutation? Actually, it is not a permutation because it has a duplicate? So we break the row.

            But if the current value is 1, then we set it to 2? Then we have two 2's? Because 2 is already in the row? Then we break the row? Yes.

        Therefore, the plan for the pair: 
            if X[bad_row[i]][bad_col[i]] != 1:
                set it to 1.
            else:
                set it to 2.

        Then the row will have two 1's (if we set to 1) or two 2's (if we set to 2). So the row is fixed? And similarly the column? The column was a permutation. Then we set one element to 1 (if the original was not 1) or 2 (if the original was 1). Then the column will have two 1's or two 2's? So the column is fixed? 

        Therefore, this modification breaks both the row and the column.

     Step 3: For the remaining bad rows (if any): 
        For each such row r, we change the element at (r, 0) (the first column) to a value that is already present in the rest of the column? Actually, we want to break the row? But we also want to preserve the condition for the column? 

        Actually, we are going to break the row by creating a duplicate? How? We change one element to a value that is already in the row? But we don't know the row? 

        However, we can also use the same idea: we change the element to 1 if the element is not 1, or 2 if the element is 1? Then we break the row? But what about the column? The column (column0) might become a permutation? We don't want that.

        Therefore, we do as the editorial: we choose a value that is already present in the column (column0) excluding the element we are changing? Then the column remains non-bad? But note: the column might have been bad? Then we are going to fix it? Actually, we have already fixed the bad columns that we could with the pairs. The remaining bad columns are fixed in the next step? So we are changing a cell that might be in a bad column? Then we break the bad column? Actually, we break the bad column by creating a duplicate? 

        Therefore, we can do:

          Let the element at (r,0) be a.
          We want to set it to a value v such that the column0 (after change) has a duplicate? Actually, we don't care how we break the row, but we must not break the column condition? Actually, we must make sure that column0 is not bad after the change? Or we are going to fix it? But note: we are going to fix the remaining bad columns independently? So if we break a bad column, that's good? But we are not going to fix the same column twice? 

        Actually, if we are in the remaining bad rows step, then we are not going to fix the columns again? So if we break a bad column (by making it non-bad) that is good. But if we break a good column (by making it bad) that is bad.

        Therefore, the safe way: 
          For the remaining bad rows, we change an element in the row that is in a column that is not bad? But we don't know which columns are bad? 

        Alternatively, we can do: 
          We change the first column (column0) of the bad row. Then for the column0, we choose the new value to be a value that is already present in column0? Then we ensure that column0 remains non-bad? 

        How to get a value that is already present in column0? 
          Let col0 = [X[i][0] for i in range(n)]   (we don't need the entire, but we can consider without the current element? Actually, we are going to change the element at (r,0). 
          Let current_col0 = [X[i][0] for i in range(n)]
          Remove the element at row r: then we have the set S = set(current_col0) without the element at row r? Actually, we can do:

          Let S = set()
          for i in range(n):
              if i == r: continue
              S.add(X[i][0])

          Then we choose any value in S? Then after changing, the column0 will have that value at two different rows? Then duplicate? Then non-bad.

          But note: if the entire column0 is distinct? Then S has n-1 distinct values? Then we can choose any? Then we set X[r][0] to one of those? Then we have two of that value? Then the column becomes non-bad? 

          However, what if the column0 was bad? Then it was distinct. Then we are setting one element to a value that is already in the column? Then we break the distinctness? Then the column becomes non-bad? So that's good.

        Therefore, we can do:

          v = any element from S? But we have to pick one. We can pick the smallest? Or the first? 

        However, what if the current value a is in S? Then if we set to a value that is in S, we are safe? Actually, we are changing the element from a to v. Then the new column0 has v at row r and also at some other row? So duplicate.

        What if a is not in S? Then we set to any value in S? Then we are safe.

        But note: we must break the row? We don't care how we break the row? Actually, we break the row by changing one element? But the row was a permutation? Then if we change one element, we break the permutation? Because we set it to a value that might be already in the row? 

        Actually, the row might have the value v already? Then we create a duplicate? Then we break the row? 

        But what if the row does not have the value v? Then we break the permutation? Actually, the row becomes having two distinct sets: one missing the value a and having v? And since v was not in the row? Then we break the permutation? Actually, we break the permutation because we introduce a value that was missing? Then the row becomes having n distinct values? Then it remains a permutation? Then we didn't fix the row? 

        Therefore, we must set the element to a value that is already in the row? 

        How? 
          We want to break the row: we must create a duplicate. So we set the element to a value that is already in the row? 

          Let row_r = X[r] 
          Without the element we are changing (which is at column0), we have a set T = set(X[r][1:])   [if we are changing column0, then the rest is columns 1..n-1]

          Then we choose v from T? Then the row will have two of v? Then we break the row? 

        But we also want the column0 to remain non-bad? 

        Therefore, we require that v is in T (the rest of the row) and also in S (the rest of the column0)? 

        But what if T ∩ S is empty? 

        Example: 
          row_r = [1, 2, 3, 4]   (and we are changing the first element: 1) -> T = {2,3,4}
          column0 = [1, 5, 6, 7]   -> S = {5,6,7} (if we remove the first row which is 1) -> then T ∩ S is empty.

        Then what? 

        We have two choices: 
          We can break the row by setting to a value in T (say 2) -> then the row becomes [2,2,3,4] -> duplicate? Then row fixed. But then column0 becomes [2,5,6,7] -> distinct? Then if the column0 was originally bad, then we break it? Then we fixed it? Actually, if the column0 was bad, then we break it by making it non-distinct? Actually, we made it distinct? Then we made it bad? 

        Therefore, we must avoid making column0 become bad? 

        Actually, if the column0 was originally bad, then we break it by making it non-distinct? How? 
          Before: column0 was distinct and covering 1..n? 
          After: we changed one element to 2. Then if 2 was not in the rest of the column0? Then the column0 becomes distinct? Then it remains bad? 

        Therefore, we must set to a value that is already in the rest of the column0? Then we break the distinctness? 

        So we require v in S. Then the column0 becomes having two v's? Then non-bad? 

        But we also require that the row becomes non-bad? To break the row, we can set v to a value that is in the rest of the row? Then the row becomes having two v's? 

        Therefore, we require v in T and in S.

        But what if T ∩ S is empty? Then we cannot satisfy both? 

        Then we have to break one condition? 

        Actually, note: the problem does not require that we break the row and the column in one move? We are only required to break the row? The column we are going to fix later? But we are going to fix the remaining bad columns? However, if we break the column0 by making it bad? Then we will fix it in the next step? But then we fix it by changing the first row of column0? Then we change the same cell again? But we are only allowed to change one cell per modification? And we are going to output the modifications? So we cannot change the same cell twice? 

        Therefore, we must avoid making column0 become bad? 

        How about: 
          We break the row by setting to a value that is already in the row (so we choose v from T). Then we break the row. 
          Then we don't care about the column? Because we will fix the entire matrix at the end? But if we break the row and break the column (by making it bad) then we have to fix that column? 

        But we are going to fix the remaining bad columns? So if column0 becomes bad, then we will fix it in the next step? Then we change the first row of column0? Then we change the element (0,0) to a value that is in the rest of the column0? 

        However, note: we are going to change a different cell? 

        But if we change the same cell? Then we are modifying it twice? Then the first modification is overwritten? 

        Therefore, we can do:

          For the remaining bad rows: we change the element at (r,0) to a value that is in T (the rest of the row) to break the row. 
          Then if column0 becomes bad, we will fix it in the remaining bad columns step? 

        How do we fix a remaining bad column? We change the element at (0, j) for column j? So if j=0? Then we change (0,0). But note: we might have already changed (0,0) if the first row was bad? 

        Actually, the remaining bad rows step and the remaining bad columns step are independent? 

        Therefore, we must avoid using the same cell for two modifications? 

        How about: for the remaining bad rows, we change the element at (r,0) to a value in T (to break the row). Then for the remaining bad columns, we change the element at (0, j) for j in the remaining bad columns? 

        Then if j=0 is in the remaining bad columns, then we change (0,0). But (0,0) might be in a row that was fixed? Then if we change (0,0) to a value that is in the rest of row0? Then we break the column0? and we break row0? 

        But note: row0 might have been fixed? Then we break row0 again? 

        Actually, we must not break a fixed row? 

        Therefore, to avoid complications, we can choose for the remaining bad rows a column that is not the first column? But the editorial says to change the first column? 

        Alternatively, we can change any column? Then we choose a column that is not bad? Then we can break the row without affecting the column? 

        But we don't know which columns are bad? 

        Actually, we know: bad_cols is the list of bad columns. Then for the remaining bad rows, we can avoid columns that are bad? But note: we have already fixed min(r,c) bad columns? The remaining bad columns are the ones that we are going to fix? So we have to avoid changing a bad column? Because if we change a bad column by setting a duplicate? Then we break the bad column? Then we remove it from the bad_cols? Then we have to update? 

        This becomes complicated.

     Therefore, we stick to the editorial: 
        For a remaining bad row: change the element at (r,0) to a value that is already present in the column0 (excluding the element we are changing). Then column0 becomes non-bad (if it was bad, then we break it; if it was not bad, then we preserve non-badness). 
        But we also want to break the row? How? 

        Actually, we break the row by the change? We change one element? But we don't know if the row becomes non-bad? 

        How to break the row? 
          We change the element at (r,0) to v. 
          The row: we have the original row which was a permutation. 
          We change one element. Then the row becomes having n distinct values? Then it remains bad? Or becomes non-bad? 

        Actually, if we change the element to a value that is already in the row? Then we create a duplicate? Then the row becomes non-bad? 

        But we don't know if v is in the row? 

        Therefore, we require that v is in the rest of the row? 

        How to achieve both? 
          We want v to be in the rest of the row (to break the row) and in the rest of the column0 (to break the column0 if it was bad, or to preserve non-badness if it was not).

        But what if there is no such v? 

        Then we have to choose v arbitrarily? 

        However, note: the values are in 1..n. The row has n distinct values? Then the rest of the row (n-1 elements) has n-1 distinct values. The column0 (without the element we are changing) has n-1 elements? But if the column0 was bad, then it had n distinct values? Then the rest has n-1 distinct values? Then the set of values in the rest of the row is of size n-1, and the set of values in the rest of the column0 is of size at least n-2 (if it was bad) or less (if it was not)? Actually, if it was not bad, then the rest of the column0 has duplicates? Then we can choose a value that appears in both? 

        Actually, the sets: 
          A = set(rest of the row)   -> size n-1 (because the row was bad: distinct and covering 1..n, so without the element at (r,0) we have n-1 distinct values? Actually, we have n-1 distinct values? Because the row is a permutation? Then the rest of the row has n-1 distinct values? 
          B = set(rest of the column0) -> size at least 1 and at most n-1.

        Then the union of A and B is at least n-1? Then the intersection? 

        But note: |A ∪ B| <= n, but |A ∩ B| = |A| + |B| - |A ∪ B| >= (n-1) + |B| - n = |B| - 1.

        Since |B| can be as small as 1? Then the intersection might be empty? 

        Example: 
            n=3, 
            row_r: [1,2,3] -> we are changing the first element (1). Then A = {2,3}
            column0: [1,4,5] (but values must be in 1..n? Then n=3, so values in 1..3? Then we cannot have 4 or 5? 

        Therefore, the values are constrained to 1..n. 

        Then the rest of the column0: values in 1..n. The rest of the row: values in 1..n? 

        Then A has size n-1 = 2, and B has size at most n-1 = 2? 

        How big is the intersection? 

          |A| + |B| <= n + (n-1) = 2n-1? 
          But |A ∪ B| <= n? 
          Then |A ∩ B| = |A| + |B| - |A ∪ B| >= 2 + (|B|) - n? 

        Actually, we know that |A| = n-1, |B| = m (which is at most n-1). 
          |A ∩ B| >= (n-1) + m - n = m - 1.

        But if m=1, then |A ∩ B| >= 0? So it can be 0? 

        Example: 
            n=3, 
            row_r = [1,2,3] -> A = {2,3}
            column0 (without row r) = [1,1] -> then B = {1} -> then A ∩ B = empty.

        Then we cannot choose a value that is in both? 

        Therefore, we must break one condition? 

        Actually, we can do two modifications? But we are only allowed to do one per row? 

        However, the problem says the minimum number of modifications is max(r,c). We are already doing max(r,c) modifications? Then we cannot do more? 

        Therefore, we must find a way to do one modification that breaks the row and does not break the column (if the column was good) and if the column was bad, then we break it? 

        How? 

        We break the row by setting the element to a value in A (the rest of the row). Then we create a duplicate in the row? Then the row is fixed? 

        But what about the column? 
          If the column was bad: then we set the element to a value in A that is not in B? Then the column becomes having distinct values? Then it remains bad? Then we will fix it in the next step (remaining bad columns)? 

          Then in the next step, we fix the column by changing the first row of the column? Then we change the element (0,0) to a value that is in the rest of the column? 

          Then we break the column? 

          But note: we are changing two cells in the same column? That's acceptable.

        However, we are doing two modifications for one row and one column? But we are counting the row modification and the column modification separately? And the total is max(r,c)? 

        Actually, we are already counting the row modification for the row and the column modification for the column? 

        Therefore, it is acceptable? 

        But what if the column was good? Then we break the column by making it distinct? Then we turn it into a bad column? Then we have to fix it? 

        Therefore, we must avoid making a good column become bad? 

        How? 
          If the column was good, then it already has a duplicate. Then if we change one element to a value that is not in the rest of the column? Then we might break the duplicate? 

          Example: 
            column0 = [1,1,2] -> good (duplicate 1). 
            We change the element at row r (which is 2) to 3? Then column0 becomes [1,1,3] -> still duplicate (the two 1's). So it remains good. 

          Therefore, we can set the element to any value? As long as we don't break the duplicate? 

          How to ensure we don't break the duplicate? 
            We don't have to worry: if the column has a duplicate, then even if we change one element, as long as we don't break the duplicate? 

          Actually, if the duplicate is at two positions and we change one of them? Then we break the duplicate? 

          Example: 
            column0 = [1,1,2] -> duplicate at the two 1's. 
            We change the last element (which is 2) to 3: then the column becomes [1,1,3] -> still has two 1's -> duplicate? Then good. 
            But if we change one of the 1's to 2: then the column becomes [1,2,2] -> duplicate (the two 2's) -> good. 
            But if we change one of the 1's to 3: then the column becomes [3,1,2] -> distinct? Then bad. 

          Therefore, we must ensure that we don't break the existing duplicate? 

          How? 
            Let the column0 have a duplicate at value x. We are changing an element that is not x? Then we don't break the duplicate? 
            Or if we are changing an element that is x, but there is at least one other x? Then after change, we still have at least one x? 

          Actually, if we change an occurrence of x to y, then we require that there is still at least two x's? 
            Then we require that there are at least three x's? 
            Or if we change an occurrence of x to y, and there is at least one other x, then we still have at least two x's? 

          So if the frequency of x is at least 3, then we are safe. 
          If the frequency of x is 2, then if we change one of them, then we break the duplicate? 

          Therefore, to preserve the duplicate, we can only change an element that is not part of a duplicate that has frequency exactly 2? 

          But we don't know the frequencies? 

        This is getting complicated.

     Given the constraints (n<=100, and total n^2 <=10000) we can try to find a value v that satisfies:

        Option 1: v is in the rest of the row (to break the row) and v is in the rest of the column (to break the column if it was bad, or to preserve non-badness? Actually, we don't care about the column if it was good? We only care that after the change, the column is not bad? 

        But if the column was good, then we only care that it remains good? How to ensure that? 
          We can check: 
             Let col0 = [X[i][0] for i in range(n)] 
             We are going to change the element at row r from a to v. 
             Then new_col0 = [ ... , v at row r]
             Then if new_col0 has a duplicate, then good.

        How to check quickly? 
          We can simulate: 
             freq = [0]*(n+1)
             for i in range(n):
                 if i != r:
                    freq[X[i][0]] += 1
             Then freq[v] >= 1   => then after change, we will have at least one duplicate? Actually, after change: 
                 freq[v] becomes at least 1? Then we add one at row r: then freq[v] becomes at least 2? Then we have a duplicate? 

          Therefore, if we choose v such that freq[v] >= 1, then after change, the column0 will have at least two v's? Then non-bad? 

        And to break the row: we require that v is in the rest of the row? 

          Let rest_row = X[r][1:]   [if we are changing column0, then the rest is columns 1..n-1]
          Then if v in rest_row, then the row will have two v's? Then non-bad? 

        Therefore, we require v such that:
            v in set(rest_row) and 
            v in set(col0 without row r)   [i.e., there is at least one occurrence of v in the column0 at rows other than r]

        Then we can choose such v? 

        What if no such v exists? 

          Then we choose v that breaks the row (v in rest_row) and then hope that the column0 remains good? But we have to ensure the column0 remains good? 

          Actually, if the column0 was good originally, then it has a duplicate. After change, if we break that duplicate? Then it becomes bad? 

        Therefore, we must avoid that. 

        How about: 
          If we cannot find v in the intersection, then we choose v in rest_row arbitrarily? And then we hope that the column0 does not become bad? 

        But if the column0 becomes bad, then we will fix it in the next step? 

        And we are allowed to fix it in the next step? 

        Then the total modifications is max(r,c) which is at least the number of bad rows plus the number of bad columns minus min(r,c) for the pairs? Then we do the remaining bad rows and then the remaining bad columns? 

        But if we create a new bad column? Then we have to fix it? 

        How many new bad columns can we create? 
          We are doing len(bad_rows) - min(r,c) modifications for bad rows. Each modification might create a new bad column? Then we have to fix them? 

        Then the total modifications would be: min(r,c) + (len(bad_rows)-min(r,c)) + (len(bad_cols)-min(r,c)) + (number of new bad columns)) 
          = len(bad_rows) + len(bad_cols) - min(r,c) + (number of new bad columns)

        But we want max(r,c) = min(r,c) + max(len(bad_rows)-min(r,c), len(bad_cols)-min(r,c)) 
          = min(r,c) + max(r-min(r,c), c-min(r,c)) 
          = min(r,c) + max(r,c) - min(r,c) = max(r,c)

        So if we create new bad columns, we go over the minimum? 

        Therefore, we must not create new bad columns? 

        So we must choose v such that the column0 remains good? 

        How to ensure that? 
          Let a = X[r][0] (the current value)
          Let new_col0 = the current column0 but with a replaced by v.

          We need new_col0 to have at least one duplicate.

          How to check without v? 

          We know the current column0 has at least one duplicate? But if we remove a and add v, then:
             If a was part of a duplicate that had frequency 2, then after removing a, that duplicate is broken. Then we rely on v to create a new duplicate? 
             Specifically, if v appears at least once in the rest of the column0, then after adding v, we have at least two v's? Then duplicate. 

          Therefore, if v is in the rest of the column0, then we have duplicate. 

          But we already tried to choose v in the rest of the column0? 

        Therefore, we require v in the rest of the column0? 

        And v in the rest of the row? 

        But what if there is no such v? 

        Then we can try to break the row and not worry about the column? And then fix the column later? But then we create a new bad column? 

        But then the total number of modifications would be more than max(r,c)? 

        Therefore, we must find a way to choose v that is in the rest of the row and in the rest of the column0? 

        But we proved that it is possible? 

        Claim: there exists a value v in {1,2,...,n} such that v is in the rest of the row and in the rest of the column0? 

        Proof: 
          Let A = set(rest of the row) -> size n-1.
          Let B = set(rest of the column0) -> size? 
          The current column0 might be bad (then B has size n-1) or good (then B has size <= n-1). 

          The intersection A ∩ B: we need to know if it is non-empty.

          The set A has size n-1. The set B has size at most n-1. The union A ∪ B is contained in {1,2,...,n} which has size n. 
          Then |A ∪ B| = |A| + |B| - |A ∩ B| <= n.
          => n-1 + |B| - |A ∩ B| <= n
          => |B| - |A ∩ B| <= 1
          => |A ∩ B| >= |B| - 1.

          But we want |A ∩ B| >= 1. 
          If |B| >= 2, then |A ∩ B| >= 1. 
          What if |B| = 1? 
             Then |A ∩ B| >= 0, which doesn't guarantee 1.

          Therefore, if |B| = 1, then the intersection might be empty.

        Example: 
          n=3, rest of the row = {2,3} (size=2), rest of the column0 = {1} (size=1), then intersection empty.

        Then what? 

        In that case, we can choose v = a value in the rest of the row arbitrarily, and then accept that the column0 will become bad? Then we will fix it in the next step? 

        But then we have to do one extra modification? 

        But we are not allowed to exceed max(r,c) modifications? 

        Therefore, we must not create new bad columns? 

        How about: we change the element to a value that is in the rest of the row and then also in the rest of the column0 is not possible, then we change it to a value that is in the rest of the row and then additionally change the first row of the column0 to a value that is in the rest of the column0? But that would be two modifications? 

        This is not allowed.

     Given the complexity, and the fact that the total n^2 is only 10000, we do the following fallback:

        For a remaining bad row r:
          Let col_index = 0   (we try column0 first, then if that column0 becomes bad and we cannot find a good v, then we try next column until we find one)
          We try columns j from 0 to n-1:
              Let a = X[r][j]
              Let rest_row = X[r] without the element at j: then set_A = set(X[r]) but without the element at j? Actually, we can do: 
                  set_A = set(X[r][:j] + X[r][j+1:])
              Let rest_col = [X[i][j] for i in range(n) if i != r]
              set_B = set(rest_col)

              If there exists a value v in set_A that is also in set_B, then we choose that v. Then we break the row and the column j remains non-bad? 

              If there is no such v, then we choose any value in set_A (to break the row) and then hope that the column j remains non-bad? But we check the column j after the change:
                 new_col = rest_col + [v]   -> then if this new_col has duplicates, then good. Otherwise, we continue to next j.

          If we find a j such that after the change, the column j is not bad, then we do it.

          If we try all j and none works, then we choose j=0 and v = the first value in set_A, and then we will fix the column j in the next step (remaining bad columns) if it becomes bad.

        Similarly for bad columns.

     But the editorial says to use the first column. And the sample input is small.

     Given the constraints (n<=100, total n^2<=10000), and the number of test cases t<=1000 but the sum of n^2<=10000, we can afford to do O(n^2) per modification for the remaining bad rows and columns? 

     However, the number of remaining bad rows is at most n, and the number of columns is n, so O(n^2) per bad row, total O(n^3) per test case? n<=100, then 100^3=1e6, and the total n^2 is 10000, so the total n across test cases is at most sqrt(10000)=100? Actually, the total n^2 is 10000, so the total n is about 100? And the number of test cases: the sum of n^2<=10000, and each test case has n>=3, so the maximum number of test cases t is 10000/(3^2)= about 1000, but the sum of n^2<=10000, so the number of test cases is at most 10000/9 = 1111, but the problem says t<=1000.

     Therefore, we can try for each remaining bad row to iterate over columns.

     But the editorial says to use the first column. And the sample output uses the first column.

     Let's trust the editorial and hope that using the first column works with the following:

        For a remaining bad row r:
          j = 0
          a = X[r][0]
          set_A = set(X[r][1:])   # the rest of the row
          set_B = set(X[i][0] for i in range(n) if i != r)

          If set_A ∩ set_B is not empty, then choose any v in set_A ∩ set_B.
          Else, choose any v in set_A.

        Then for the remaining bad columns, similarly:
          i = 0
          a = X[0][j]   (j is the bad column)
          set_A = set(X[0][:j] + X[0][j+1:])   # the rest of the row0
          set_B = set(X[i][j] for i in range(1, n))   # the rest of the column j

          If set_A ∩ set_B is not empty, then choose any v in set_A ∩ set_B.
          Else, choose any v in set_A.

        Then if in the remaining bad rows step we create a new bad column, we will fix it in the bad columns step? 

        But note: the bad columns step will process the column and change the first row of that column. Then if the column0 became bad, we will change (0,0) to a value that is in the rest of the column0? 

        But we already changed (r,0) to v. Then the rest of the column0 (excluding row0) includes row r? Then set_B for column0 includes the v we set at row r? 

        Then if we change (0,0) to v, then the column0 will have two v's? Then non-bad? 

        Therefore, it works.

     Therefore, the algorithm for a test case:

        bad_rows = [i for i in range(n) if len(set(X[i]))==n]
        bad_cols = [j for j in range(n) if len(set(X[i][j] for i in range(n)))==n]

        r = len(bad_rows)
        c = len(bad_cols)
        k = min(r, c)

        modifications = []

        # Step 1: fix the k pairs
        for i in range(k):
            i_row = bad_rows[i]
            j_col = bad_cols[i]
            a = X[i_row][j_col]
            if a != 1:
                v = 1
            else:
                v = 2
            modifications.append((i_row, j_col, v))
            # Update the matrix for further checks? But we are not using the updated matrix for the next steps? 
            # We are not, because we only use the original matrix to compute bad_rows and bad_cols? 
            # But for the remaining bad rows and columns, we are not going to use the updated matrix? 
            # However, the remaining bad rows and columns were computed from the original matrix? 
            # But the conditions might change? For example, if we change an element in a bad row, then that row might become non-bad? 
            # But we are not updating the matrix. 
            # Therefore, the remaining bad rows and columns are still the original ones? 
            # But we fixed one bad row and one bad column? 

            # This is a flaw: we should update the matrix? 
            # Or recompute bad_rows and bad_cols for the remaining ones? 
            # But the problem: the modifications are not applied sequentially in the matrix? We are only storing the modifications. 
            # And the conditions for the remaining steps rely on the original matrix? 

            # This might cause: we fix a row and a column, but then in the remaining bad rows we use the original matrix? 

            # How to resolve? 
            # We are not updating the matrix, so the checks for the remaining steps will be done on the original matrix? 
            # But the sample: 
            #   We change one cell, so in the same row and column, the values change? 

            # Therefore, we should update the matrix? 

            # But note: the conditions for the remaining bad rows and columns: 
            #   For a remaining bad row, we only care about the row and the column0? And we are not using the value at the cell we fixed? 
            #   Specifically, for a bad row that was not fixed in the pair step, it remains bad? 
            #   But what if the change in the pair step fixed a bad row that is in the bad_rows list? 

            # We will have fixed the first min(r,c) bad rows and bad cols. The remaining are the ones after the first min(r,c). 

            # So we do not update the matrix because we are only going to use the original matrix for the remaining steps? 

            # Actually, the remaining bad rows are the ones in bad_rows[k:], and we are going to change them regardless of the current state? 

            # But the change in the pair step might have fixed one of the remaining bad rows? 

            # Example: 
            #   bad_rows = [0,1], bad_cols=[0,1]
            #   k=2, so we do two changes: 
            #        change (0,0) and (1,1)
            #   Then after the change, the row0 might not be bad anymore? 
            #   But we are not updating the matrix, so when we go to the remaining bad rows (none) we skip. 
            #   But actually, the row0 might still be bad? 
            #   How? 
            #        Suppose row0 was [1,2,3] and we change (0,0) to 1: then row0 becomes [1,2,3] -> still distinct? 
            #        But we changed the first element to 1, and if the row0 originally had 1 at another position? 
            #        In this case, if the row0 had 1 at the first element originally, then we change it to 2? 
            #        Then row0 becomes [2,2,3] -> not distinct. 

            #   But in the example above, if the row0 was [1,2,3] and we change (0,0) to 1, then we have two 1's? Only if there was a 1 elsewhere? But there was a 1 at the first element originally, and then we set it to 1 again? 

            #   Actually, we set it to 1 if the current value is not 1? Or if the current value is 1, we set to 2. 

            #   Therefore, we break the row0. 

            #   So the change in the pair step definitely breaks the row0? 

            #   Then the row0 is no longer bad. 

            #   But our list bad_rows was computed from the original matrix? 

            #   Then we will not include it in the remaining steps? Because we are using the list bad_rows and we only take bad_rows[k:]. 

            #   How many bad_rows are there after the pair step? 
            #   We have fixed the first k bad rows? 

            #   Therefore, we do not need to update the matrix for the remaining steps? 

        # Step 2: fix the remaining bad rows: from index k to the end in bad_rows
        for i in range(k, r):
            i_row = bad_rows[i]
            j_col = 0
            a = X[i_row][j_col]
            rest_row = X[i_row][1:]   # columns 1 to n-1
            set_A = set(rest_row)
            rest_col0 = [X[ii][0] for ii in range(n) if ii != i_row]
            set_B = set(rest_col0)
            common = set_A & set_B
            if common:
                v = next(iter(common))
            else:
                v = next(iter(set_A))
            modifications.append((i_row, j_col, v))

        # Step 3: fix the remaining bad columns: from index k to the end in bad_cols
        for j in range(k, c):
            j_col = bad_cols[j]
            i_row = 0
            a = X[i_row][j_col]
            rest_row0 = X[0][:j_col] + X[0][j_col+1:]
            set_A = set(rest_row0)
            rest_col = [X[ii][j_col] for ii in range(1, n)]   # exclude row0
            set_B = set(rest_col)
            common = set_A & set_B
            if common:
                v = next(iter(common))
            else:
                v = next(iter(set_A))
            modifications.append((i_row, j_col, v))

        # Output: 
        m = len(modifications)
        output_lines.append(str(m))
        for (i, j, v) in modifications:
            output_lines.append(f"{i+1} {j+1} {v}")

     But note: the sample input might be small.

     Let's test with the sample input:

        "3
         1 3 1
         2 1 3
         3 2 2"

        n=3

        Rows:
          row0: [1,3,1] -> set: {1,3} -> not bad (size=2) -> not bad? Actually, bad row means permutation -> distinct and size n? So no.
          row1: [2,1,3] -> distinct? and size=3 -> bad.
          row2: [3,2,2] -> not distinct -> not bad.

        bad_rows = [1]   (index1)

        Columns:
          col0: [1,2,3] -> distinct -> bad.
          col1: [3,1,2] -> distinct -> bad.
          col2: [1,3,2] -> distinct? [1,3,2] -> distinct -> bad.

        bad_cols = [0,1,2]

        r=1, c=3, k = min(1,3)=1.

        Step1: fix the first pair: bad_row[0]=1, bad_col[0]=0.
            i_row=1, j_col=0: X[1][0]=2 -> not 1? then v=1.
            modifications: (1,0,1)

        Step2: remaining bad rows: from index1 to end: none.

        Step3: remaining bad cols: from index1 to end: bad_cols[1:]=[1,2]
           For j=1: j_col=1, i_row=0: 
                a = X[0][1] = 3
                rest_row0 = X[0][:1] + X[0][2:] = [1] + [1] = [1,1] -> set_A = {1}
                rest_col1 = [X[1][1] (which is 1) and X[2][1] (which is 2)] -> [1,2] -> set_B = {1,2}
                common = {1} ∩ {1,2} = {1} -> v=1.
                modifications: (0,1,1)

           For j=2: j_col=2, i_row=0:
                a = X[0][2]=1
                rest_row0 = [1,3] (because we remove the element at j_col=2) -> [1,3] -> set_A = {1,3}
                rest_col2 = [X[1][2]=3, X[2][2]=2] -> set_B = {2,3}
                common = {1,3} ∩ {2,3} = {3} -> v=3.
                modifications: (0,2,3)

        Total modifications: 3.

        Then the matrix becomes:
           row0: [1, 1, 3]   -> has two 1's -> duplicate? good.
           row1: [1, 1, 3]   -> has two 1's -> good.
           row2: [3,2,2]     -> has two 2's -> good.

        Columns:
           col0: [1,1,3] -> good.
           col1: [1,1,2] -> good.
           col2: [3,3,2] -> good.

        But the sample output for this test case is:
            3
            2 1 3   -> wait, the sample output is:
                3
                2 1 3
                2 2 3
                3 3 3

        Why is our solution different? 

        The sample input:
            "3
             1 3 1
             2 1 3
             3 2 2"

        The sample output for the second test case is:
            3
            2 1 3
            2 2 3
            3 3 3

        Our solution: 
            (1,0,1)  -> row1+1, col0+1 -> (2,1) -> 2nd row, 1st column: change to 1? 
            (0,1,1)  -> 1st row, 2nd column: change to 1.
            (0,2,3)  -> 1st row, 3rd column: change to 3.

        But the sample output changes:
            "2 1 3": 2nd row, 1st column to 3 -> then row1 becomes [3,1,3] -> duplicate? and col0 becomes [1,3,3] -> duplicate.
            "2 2 3": 2nd row, 2nd column to 3 -> then row1 becomes [3,3,3] -> duplicate? and col1 becomes [3,3,2] -> duplicate.
            "3 3 3": 3rd row, 3rd column to 3 -> then row2 becomes [3,2,3] -> duplicate? and col2 becomes [1,3,3] -> duplicate.

        Both solutions are valid. 

        But our solution uses 1 and 3, and the sample uses 3's. 

        The problem allows any solution.

     However, the sample input also has:

        "5
         1 1 1 1 1
         1 1 1 1 1
         1 1 1 1 1
         1 1 1 1 1
         1 1 1 1 1"

        This has no bad rows and no bad columns? 
          Each row: [1,1,1,1,1] -> has duplicates -> not bad.
          Each column: all 1's -> duplicates -> not bad.

        Then modifications = 0.

     And the next:

        "3
         1 1 2
         2 2 1
         2 3 2"

        Let's compute:
          Rows:
            row0: [1,1,2] -> not distinct -> not bad.
            row1: [2,2,1] -> not distinct -> not bad.
            row2: [2,3,2] -> not distinct -> not bad.
          Columns:
            col0: [1,2,2] -> not distinct -> not bad.
            col1: [1,2,3] -> distinct? -> bad.
            col2: [2,1,2] -> not distinct -> not bad.

          bad_cols = [1] -> index1

          bad_rows = [] -> so r=0, c=1, k=0.

          Step1: skip.
          Step2: skip.
          Step3: j=0 (from k=0 to end: [1]) -> j_col=1, i_row=0.
              a = X[0][1]=1.
              rest_row0 = [1] (from col0) and [2] (from col2) -> [1,2] -> set_A = {1,2}
              rest_col1 = [X[1][1]=2, X[2][1]=3] -> set_B = {2,3}
              common = {1,2} ∩ {2,3} = {2} -> v=2.

          modifications: (0,1,2)

          Then output: 
              1
              1 2 2

          But the sample output for this test case is:
               1
               1 2 2

     And the last:

        "3
         1 1 3
         3 2 1
         3 1 3"

        Rows:
          row0: [1,1,3] -> not distinct -> not bad.
          row1: [3,2,1] -> distinct? -> bad.
          row2: [3,1,3] -> not distinct -> not bad.

        bad_rows = [1]  -> index1

        Columns:
          col0: [1,3,3] -> not distinct -> not bad.
          col1: [1,2,1] -> not distinct -> not bad.
          col2: [3,1,3] -> not distinct -> not bad.

        Then bad_cols = [].

        Then k=0, then we only do step2: for i in range(0,1) (since r=1, c=0) -> i_row=1, j_col=0.
          a = X[1][0]=3.
          rest_row1 = [2,1] -> set_A = {1,2}
          rest_col0 = [X[0][0]=1, X[2][0]=3] -> set_B = {1,3}
          common = {1,2} ∩ {1,3} = {1} -> v=1.

        modifications: (1,0,1)

        Then output: 
           1
           2 1 1   -> which is the sample output.

     Therefore, we trust the algorithm.

     However, note: in the sample input the first test case:

        "4
         3 2 1 1
         2 1 3 4
         1 3 3 1
         4 4 4 2"

        We do:

        bad_rows: 
          row0: [3,2,1,1] -> not distinct -> skip.
          row1: [2,1,3,4] -> distinct? -> bad.
          row2: [1,3,3,1] -> not distinct -> skip.
          row3: [4,4,4,2] -> not distinct -> skip.

        bad_cols:
          col0: [3,2,1,4] -> distinct? -> bad.
          col1: [2,1,3,4] -> distinct? -> bad.
          col2: [1,3,3,4] -> not distinct? [1,3,3,4] -> duplicate? -> skip.
          col3: [1,4,1,2] -> distinct? [1,4,1,2] -> not distinct? skip.

        Then bad_rows=[1], bad_cols=[0,1] -> k=min(1,2)=1.

        Step1: fix (1,0): 
            X[1][0]=2 -> not 1 -> v=1.

        Then remaining bad_cols: [1] (index1 in bad_cols: j=1)

        Step3: for j_col=1, i_row=0:
            a = X[0][1]=2.
            rest_row0 = [3,1,1] -> set_A = {1,3}
            rest_col1 = [X[1][1]=1, X[2][1]=3, X[3][1]=4] -> set_B = {1,3,4}
            common = {1,3} ∩ {1,3,4} = {1,3} -> choose 1? or 3? 
            Let's choose 1? then change (0,1) to 1.

        Then output: 
            2
            2 1 1   -> (row1+1=2, col0+1=1 -> 2,1,1) but wait: our indexing: 
                Step1: (1,0,1) -> row index1 (0-indexed) is the second row, column0: so (row2, col1) in 1-indexed? 
                Actually, we output 1-indexed: 
                   (1,0,1) -> (1+1,0+1,1) = (2,1,1) -> but the sample output is "2 1 1" and "4 2 3"

            Then step3: (0,1,1) -> (0+1,1+1,1) = (1,2,1) -> but sample output has "4 2 3"

        This does not match.

        Why? 
          The sample output is:
             2
             2 1 1
             4 2 3

        But in our solution for the remaining bad column we changed (0,1) to 1? 

        How about we change (0,1) to 3? then we output (1,2,3) in 1-indexed.

        But the sample output has "4 2 3": that is row4, col2, value 3.

        How did they get that?

        The sample input matrix:

          3 2 1 1
          2 1 3 4
          1 3 3 1
          4 4 4 2

        They change:
          (2,1) to 1 -> then row1: becomes [1,1,3,4] -> not distinct? 
          (4,2) to 3 -> then row3: becomes [4,3,4,2] -> has two 4's? 

        Then the matrix:

          3  2  1  1
          1  1  3  4   -> changed the first element to 1 -> then col0: [3,1,1,4] -> has two 1's? 
          1  3  3  1
          4  3  4  2   -> changed the second element to 3 -> then col1: [2,1,3,3] -> has two 3's? 

        Then rows:
          row0: [3,2,1,1] -> duplicate (1's) -> good.
          row1: [1,1,3,4] -> duplicate (1's) -> good.
          row2: [1,3,3,1] -> duplicate (1's and 3's) -> good.
          row3: [4,3,4,2] -> duplicate (4's) -> good.

        Columns:
          col0: [3,1,1,4] -> duplicate (1's) -> good.
          col1: [2,1,3,3] -> duplicate (3's) -> good.
          col2: [1,3,3,4] -> duplicate (3's) -> good.
          col3: [1,4,1,2] -> duplicate (1's) -> good.

        So it works.

        How did they choose (4,2)? 

        In our algorithm, we fixed the remaining bad column j=1 by changing (0,1) to 1 or 3? 

        But the sample fixed (4,2) to 3? 

        Why (4,2)? 

        The sample has two modifications: 
          first: (2,1,1) -> that is our pair step: bad_row index1 (which is row1) and bad_col index0 (which is col0) -> then (1,0,1) -> and output as (2,1,1) in 1-indexed.

          then the remaining bad_cols: [1] -> which is col1. 
          Then we should change (0,1) (because the first row) to a value? 

        But the sample changed (4,2) -> which is row3, col1 (0-indexed: row3, col1) -> why?

        The editorial for the remaining bad columns says: change the first row of the column? 

        But the sample changed the last row? 

        Actually, the editorial says: for a remaining bad column j, change the element at (0, j). 

        Why did they change (3,1)? 

        They did not: they changed (4,2) -> that is row4, column2? 

        In the matrix:

          row0: row1? 
          row1: row2?
          row2: row3?
          row3: row4?

        The sample input:

          row0: 3 2 1 1
          row1: 2 1 3 4
          row2: 1 3 3 1
          row3: 4 4 4 2

        So row0: first row, row3: last row.

        The modification (4,2,3) -> that is the fourth row (row index3) and second column (col index1).

        Why did they not change the first row? 

        Looking at the sample output, they did not change the first row? 

        Therefore, the editorial guideline does not specify which row to change for the remaining bad columns? It says "the first row", but the sample solution changes a different row? 

        Actually, the problem does not require a particular solution. 

        But our solution for the first test case is:

          Step1: (1,0,1) -> (row1, col0) -> output (2,1,1) in 1-indexed.

          Step3: for the remaining bad column j=1 (which is col1), we change (0,1) (the first row, second column) to either 1 or 3? 
          We choose arbitrarily. We can choose 3? then output (1,2,3) in 1-indexed.

        Then the solution:

          2
          2 1 1
          1 2 3

        But the sample output for the first test case is:

          2
          2 1 1
          4 2 3

        Why did they change a different cell? 

        How did they achieve minimum modifications? 

        They fixed the remaining bad column by changing a cell in that column? But not the first row? 

        But the problem: we can change any cell. 

        Therefore, we are free to change any cell in the column? 

        How about in the remaining bad columns, we change the last row? 

        Then we would do:

          For j in range(k, c):
            j_col = bad_cols[j]
            i_row = n-1   # last row
            ... 

        But the editorial says the first row.

        To match the sample output, we might need to change the row index for the remaining bad columns? 

        However, the problem does not require a particular cell. 

        But the sample output for the first test case has a modification at (4,2) -> which is the last row, second column.

        Why might we prefer the last row? 

        We might avoid interference? 

        Given the freedom, we can change any row in the column? 

        How about we change the last row for the remaining bad columns? 

        Then for the first test case:

          Step3: j_col=1 (the second column) -> i_row = n-1 = 3 (0-indexed)
          a = X[3][1] = 4
          rest_row3 = [4,4,2]  (without the element at col1) -> set_A = {4,2}? 
          rest_col1 = [X[0][1]=2, X[1][1]=1, X[2][1]=3] -> set_B = {1,2,3}
          common = {2,4} ∩ {1,2,3} = {2} -> v=2? 
          But then the column1: 
             [2,1,3,2] -> has two 2's -> good.

          But then the row3: 
             originally: [4,4,4,2] -> change the second element to 2: [4,2,4,2] -> has two 4's and two 2's -> good.

          Then modifications: (3,1,2) -> output (4,2,2) in 1-indexed? 

        But the sample output has (4,2,3). 

        Why 3? 

        In the sample solution: they set to 3.

        How about we set to 3? 
          Then the column1: [2,1,3,3] -> has two 3's -> good.
          The row3: [4,3,4,2] -> has two 4's -> good.

        And 3 is in the rest of the column1? and in the rest of the row3? 
          rest_row3: [4,4,2] -> set_A = {4,2} -> 3 is not in set_A.
          Then we cannot choose 3 by our rule (common first) because common was {2}. 

        But if there is no common, then we choose any value in set_A? then we would choose 4 or 2? 

        But the sample chose 3, which is not in set_A? 

        Then they broke the row by creating a duplicate? 

        Actually, by setting to 3, the row3: [4,3,4,2] -> no duplicate? 
          But 4 appears twice? 

        It does: 4 at col0 and col2. 

        So it breaks the row? 

        Therefore, to break the row, we only require that the value we choose is in the rest of the row? 

        In our algorithm for the remaining bad columns, we require that the value is in the rest of the row0? 
          But we are using the last row now? 

        So for the remaining bad column, we are changing the last row. Then we require that the value is in the rest of the last row? 

        In the last row (row3): 
           Without the element at column1: [4, (skip), 4, 2] -> set_A = {4,2}
        Then if we choose 3, it is not in set_A? then the row3 becomes [4,3,4,2] -> which has two 4's? then duplicate? 
          Yes, the two 4's are at col0 and col2? 

        So the row3 is fixed? 

        But we did not use the condition that the new value is in the rest of the row? 

        The condition to break the row is: 
            We change one element? Then if the new value is already in the row (anywhere) then we have a duplicate? 
            But note: the row might have the new value elsewhere? 

        Therefore, to break the row, we require that the new value appears at least once in the row (excluding the changed position)? 

        How about we do:

          Let the row = X[i_row] (the row we are changing)
          Let the new value = v.
          Then if there exists an index jj != j_col such that X[i_row][jj] == v, then the row has a duplicate.

          So we can choose any v that appears at least once in the row (at a position different from j_col).

        And to ensure the column is fixed: we require that the new value v appears at least once in the column (excluding the changed row) to have a duplicate in the column.

        Therefore, we can do:

          For a remaining bad column j_col:
             for i_row in [0,1,...,n-1]:   # we try to find a row such that there exists a value v that is in the rest of the row and in the rest of the column (excluding the cell (i_row, j_col))
                 Let a = X[i_row][j_col]
                 Let rest_row = the row i_row without the element at j_col -> then set_A = set(rest_row)
                 Let rest_col = the column j_col without the element at i_row -> set_B = set(rest_col)
                 Then if there exists v in set_A such that v in set_B? then choose that row and v? 
             if found, break.

          But to minimize the number of modifications, we only do one per bad column.

        But the total n<=100, and the number of bad columns is at most n, and the number of rows is n, so O(n^3) per test case? 100^3=1e6, and the total n^2<=10000, so the total n across test cases is about 100? Then the worst-case test case n=100, then 100^3=1e6, and we have about 10000/(100^2)=1 test case? Then it is acceptable.

        But the sum of n^2<=10000, so the maximum n is 100, but only one test case has n=100? Then 100^3=1e6, which is acceptable in Python? 

        But the problem says the sum of n^2 across test cases is 10000, so the largest test case: 
            n^2 <= 10000 -> n<=100, and the total n^2=10000, so the number of test cases is 1? because 100^2=10000.

        Actually, the problem: "the sum of n^2 across all test cases in one input file does not exceed 10,000"

        So we can do:

          For each remaining bad column j_col, we iterate over rows from 0 to n-1, and for each row, we do:
              set_A = set(X[i_row][0:j_col] + X[i_row][j_col+1:])
              set_B = set(X[i][j_col] for i in range(n) if i != i_row)

              Then if set_A and set_B have common element, then choose one and break the row and column.
              If we don't find one, then we choose a row and a value that is in set_A arbitrarily (to break the row) and then hope the column will be fixed later? But we are only allowed one modification per bad column.

          But if we don't find a row that allows a common element, then we choose a row and a value in set_A arbitrarily? 

        This would be more robust.

        But the editorial says to use the first row. 

        And the sample output for the first test case might be obtained by:

          For the remaining bad column j_col=1, we try rows:

            row0: 
               rest_row0 = [3,1,1] (without col1) -> set_A = {1,3}
               rest_col1 = [1,3,4] (without row0) -> set_B = {1,3,4}
               common = {1,3} -> we can choose 1 -> then modification (1,2,1) in 1-indexed: (row1, col2,1) -> but wait: row0 is row1 in 1-indexed? 

            row1: we already changed row1? 
            row2: 
               rest_row2 = [1,3,1] (without col1) -> set_A = {1,3}
               rest_col1 = [2,3,4] (without row2) -> set_B = {2,3,4} -> common={3} -> choose 3 -> then modification (3,2,3) in 1-indexed: (row3, col2,3) -> which is (4,2,3) in 1-indexed? 

          Then we choose row2? 

        But then we output for the bad column j_col=1: (2,1,3) in 0-indexed -> row2, col1, value3.

        Then the total modifications: 
             (1,0,1) -> (2,1,1) in 1-indexed.
             (2,1,3) -> (3,2,3) in 1-indexed? 

        But the sample output is (2,1,1) and (4,2,3) -> which is row4, col2, value3.

        How is row4? n=4, then rows: 0,1,2,3 -> row3 is the last row.

        So we want to change row3, col1? 

        Therefore, we try rows in increasing order, and we pick the first row that works? 

        But in the first test case, we try row0: it works (common element 1) -> then we change row0, col1 to 1? 

        Then we output (1,2,1) in 1-indexed: row1, col2, value1.

        But the sample output has (4,2,3).

        The problem allows any solution. 

        Therefore, we can choose any row. 

        To mimic the sample output, we might choose the last row? 

        How about we try rows in reverse order? 

        For the remaining bad column, we try from last row to first row? 

        Then for the first test case, j_col=1:
            row3: 
                rest_row3 = [4,4,2] (without col1) -> set_A = {4,2}
                rest_col1 = [2,1,3] (without row3) -> set_B = {1,2,3} -> common={2} -> choose 2? then modification (4,2,2) in 1-indexed? 
            row2: 
                rest_row2 = [1,3,1] -> set_A={1,3}
                rest_col1 = [2,1,4] (without row2) -> set_B={1,2,4} -> common={1} -> choose 1? then modification (3,2,1) in 1-indexed? 
            row1: already changed? 
            row0: 
                rest_row0 = [3,1,1] -> set_A={1,3}
                rest_col1 = [1,3,4] (without row0) -> set_B={1,3,4} -> common={1,3} -> choose 1? then modification (1,2,1) in 1-indexed.

        We pick the first row in reverse order that works? row3: common 2 -> then we choose row3 and v=2.

        But the sample output has (4,2,3) for the second modification.

        How about we choose a value that is in set_A arbitrarily if we cannot find common? and we choose the last row? 

        In the sample output, they chose value 3 for row3? 
           In row3: set_A = {4,2} -> 3 is not in set_A.
        Then we would not choose 3 by our rule (we require in set_A to break the row).

        Therefore, we must choose a value in set_A.

        The sample output chose 3 and it breaks the row by creating a duplicate with the 4's? But 3 is not 4? 
           The row3: [4,3,4,2] -> has two 4's? 
           So they break the row by having the new value 3 and the existing 4's? 
        But the new value 3 is not in the rest of the row? 

        How can they break the row? 
           The row has two 4's: one at col0 and one at col2. 
           So the duplicate is the two 4's, not involving the new value? 

        Therefore, to break the row, we do not require that the new value appears in the rest of the row? 
           We only require that the row has at least one duplicate. 

        And the row3 originally had three 4's. After changing the second element to 3, it still has two 4's? 

        So the row is not broken by the new value, but by the remaining 4's. 

        Therefore, we do not require that the new value is in the rest of the row? 
          We only require that the row, after the change, has a duplicate. 

        This can be an existing duplicate that is not touched, or a new duplicate involving the new value. 

        How to ensure the row has a duplicate after change? 
          Let freq = frequency of each value in the row, excluding the changed cell.
          We change a from the cell to v.
          Then new_freq = 
             for value a: we reduce by 1.
             for value v: we increase by 1.
          Then if there is any value that has frequency>=2 in the new row, then good.

        But we don't want to simulate for all v in 1..n? 

        Given time, we can do:

          For a fixed row i_row and column j_col, we can try values v in the range 1..n:
             Let new_row = the row i_row with the element at j_col changed to v.
             If len(set(new_row)) < n: then the row has duplicate? -> good.
             Also, for the column j_col: 
                 new_col = the column j_col with the element at i_row changed to v.
                 If len(set(new_col)) < n: then the column has duplicate? -> good.

          Then we can choose v that satisfies both.

        And there is always one? 

        How to find it fast? 

          For the row: 
             Let A = the row i_row without the element at j_col.
             The row has a duplicate if either:
                 (i) v is in A, or 
                 (ii) A has a duplicate by itself (i.e., there is a value that appears at least twice in A)

          Similarly, for the column:
             Let B = the column j_col without the element at i_row.
             The column has a duplicate if either:
                 (i) v is in B, or 
                 (ii) B has a duplicate by itself.

          Therefore, we can choose v such that:
             either v is in A, or v is in B, or (A has a duplicate) or (B has a duplicate).

          Since the row and column are not used in the same condition, we can choose any v if (A has a duplicate) and (B has a duplicate)? 

          But note: we want both conditions.

          We require that the row has a duplicate AND the column has a duplicate.

          So if A has a duplicate by itself (even if we remove the cell, there is a duplicate) and B has a duplicate by itself, then any v works.

          If A has a duplicate by itself, and B does not, then we require that v is in B (to create a duplicate in the column).
          If B has a duplicate by itself, and A does not, then we require that v is in A.
          If neither, then we require that v is in A and in B.

          Therefore, we can do:

             if there exists a duplicate in A and a duplicate in B:
                 then we can choose v arbitrarily? (say 1)

             else if there is a duplicate in A and no duplicate in B:
                 then we require v in B.

             else if there is a duplicate in B and no duplicate in A:
                 then we require v in A.

             else: 
                 then we require v in A and in B.

          And then choose the smallest v that satisfies.

        But this is complicated.

 Given the complexity and the small constraints, and the fact that the total number of modifications is max(r,c) which is small, we are not going to do this.

 Instead, we will change the last row for the remaining bad columns and hope that by choosing a value that is in the rest of the row (to break the row) and in the rest of the column (to break the column) if possible, and if not, then we choose a value that breaks the row and hope that the column is broken by the new value? 

 But how to know if the column will be broken? 
    We know the column without the cell: if it has a duplicate, then after change it might still have a duplicate? 
    But if it does not have a duplicate, then we rely on the new value to create a duplicate (by being in the rest of the column).

    So to ensure the column is broken, we require that either the rest of the column has a duplicate or the new value is in the rest of the column.

    This is the same as the condition for the column to have a duplicate after the change.

    So we can do:

        For a remaining bad column j_col, we iterate over rows in reverse order (from last to first) and for the current row i_row, we consider:

            Let A = the row i_row without the element at j_col.
            Let B = the column j_col without the element at i_row.

            condition_row = (there is a duplicate in A) or (v will be in A)  -> we will choose v later.
            But we haven't chosen v.

            Instead, we can check: 
               The row will have a duplicate if (len(A) < len(set(A))+1) then there is a duplicate in A? -> no, that's not. 
               Actually, the row will have a duplicate after change if either there is a duplicate in A (which is independent of v) or if the new value v is in A.

            Similarly, the column will have a duplicate after change if either there is a duplicate in B or if v is in B.

            Therefore, we can choose v from 1 to n such that:
               if there is a duplicate in A, then the row condition is satisfied (regardless of v) and if there is a duplicate in B, then the column condition is satisfied.
               if not, then we require that v in A and v in B.

            And we can always find such v? 
               Because the row condition is satisfied if there is a duplicate in A or if we choose v in A.
               Similarly for the column.

            How to find v? 
               if there is a duplicate in A and there is a duplicate in B: then any v works.
               if there is a duplicate in A and not in B: then we require v in B.
               if there is a duplicate in B and not in A: then we require v in A.
               if not in both: then we require v in A and in B.

            And since A is the rest of the row, size n-1, and B is the rest of the column, size n-1, and they are within 1..n, then the sets A and B are non-empty? 

            In the case: not in both, then we require v in A ∩ B.

            And we know that if there is no duplicate in A, then A has size n-1 (distinct) -> and similarly B has size n-1. 
            Then |A ∪ B| = |A| + |B| - |A∩B| <= n
            => (n-1)+(n-1) - |A∩B| <= n
            => 2n-2 - |A∩B| <= n
            => |A∩B| >= n-2.

            And n>=3, so n-2>=1. Therefore, A∩B is not empty.

            Therefore, we can always find v.

        Then we can do for the remaining bad column j_col and for a row i_row (we try in reverse order):

            Let a0 = X[i_row][j_col]
            A = the list of values in the row i_row without the cell at j_col.
            B = the list of values in the column j_col without the cell at i_row.

            Let has_dup_A = (len(A) != len(set(A)))
            Let has_dup_B = (len(B) != len(set(B)))

            if has_dup_A and has_dup_B:
                v = 1   # any value, but we choose 1, if 1 is not the current a0? 
                if a0==1:
                    v=2
                else:
                    v=1
            elif has_dup_A and not has_dup_B:
                # then v must be in B
                # choose the smallest value in B
                v = min(set(B))
            elif not has_dup_A and has_dup_B:
                v = min(set(A))
            else: 
                # v in A and in B
                v = min(set(A) & set(B))

            then we set the modification (i_row, j_col, v) and break the row loop.

        This is for the remaining bad columns.

        Similarly for the remaining bad rows: we iterate over columns in reverse order? 
            For a bad row i_row, we iterate over columns j from n-1 downto 0:

            Let a0 = X[i_row][j]
            Let A = the row i_row without the element at j.
            Let B = the column j without the element at i_row.
            has_dup_A = (len(A)!=len(set(A)))
            has_dup_B = (len(B)!=len(set(B)))

            and choose v similarly.

        But then we might not choose the first column.

        Given the time, we will do it for the first test case: 
          bad_cols remaining: [1] -> j_col=1.
          try rows: [3,2,1,0] in reverse order.

          row3: 
             A = [4,4,2] (row3 without col1) -> has_dup_A = (len([4,4,2]) = 3, set size=2 -> True)
             B = [2,1,3] (col1 without row3) -> has_dup_B = (3 values? distinct? -> False)
             then we require v in B. 
             B = {2,1,3} -> choose v=1.
             Then we change (3,1) to 1? 
                 then row3: [4,1,4,2] -> has two 4's? good.
                 col1: [2,1,3,1] -> has two 1's? good.

          So we output (4,2,1) in 1-indexed.

        But the sample output has (4,2,3) -> which also works.

        Therefore, any v in B works.

        To match the sample output, we might choose 3? 

        So we can choose the largest in B, or we can choose the most frequent in B, or any. 

        We'll choose the smallest.

        So for the first test case, we would output (4,2,1) and the sample output has (4,2,3), both work.

        Therefore, we will implement for the remaining bad rows and bad columns by iterating over columns/ in reverse order and choose the first row that we can find a v (using the rule above) and then break.

        But note: we are for a given bad row/column, only do one modification.

        Summary for the entire solution for a test case:

          Step0: read n and matrix.

          Step1: compute bad_rows and bad_cols from the original matrix.

          Step2: 
             r = len(bad_rows), c = len(bad_cols)
             k = min(r, c)
             modifications = []

          Step3: for i in range(k):
             i_row = bad_rows[i]
             j_col = bad_cols[i]
             a = matrix[i_row][j_col]
             if a != 1:
                 v = 1
             else:
                 v = 2
             modifications.append((i_row, j_col, v))

          Step4: for the remaining bad rows (indices from k to r-1), iterate over columns from n-1 downto 0:
             for i in range(k, r):
                 i_row = bad_rows[i]
                 found = False
                 for j in range(n-1, -1, -1):   # try columns from last to first
                    a0 = matrix[i_row][j]
                    # get A: the row i_row without the element at j
                    list_A = []
                    for jj in range(n):
                        if jj == j: continue
                        list_A.append(matrix[i_row][jj])
                    # get B: the column j without the element at i_row
                    list_B = []
                    for ii in range(n):
                        if ii == i_row: continue
                        list_B.append(matrix[ii][j])

                    has_dup_A = (len(list_A) != len(set(list_A)))
                    has_dup_B = (len(list_B) != len(set(list_B)))

                    if has_dup_A and has_dup_B:
                        if a0 != 1:
                            v = 1
                        else:
                            v = 2
                        modifications.append((i_row, j, v))
                        found = True
                        break
                    elif has_dup_A and (not has_dup_B):
                        # choose any v in set_B, choose the smallest.
                        set_B = set(list_B)
                        v = min(set_B)
                        modifications.append((i_row, j, v))
                        found = True
                        break
                    elif (not has_dup_A) and has_dup_B:
                        set_A = set(list_A)
                        v = min(set_A)
                        modifications.append((i_row, j, v))
                        found = True
                        break
                    else:
                        set_A = set(list_A)
                        set_B = set(list_B)
                        common = set_A & set_B
                        if common:
                            v = min(common)
                            modifications.append((i_row, j, v))
                            found = True
                            break
                 if not found:
                    # This should not happen, but fallback: 
                    j = 0
                    a0 = matrix[i_row][0]
                    list_A = matrix[i_row][1:]
                    set_A = set(list_A)
                    v = next(iter(set_A))
                    modifications.append((i_row, 0, v))

          Step5: for the remaining bad_cols (indices from k to c-1), iterate over rows from n-1 downto 0:
             for j in range(k, c):
                 j_col = bad_cols[j]
                 found = False
                 for i in range(n-1, -1, -1):   # try rows from last to first
                    a0 = matrix[i][j_col]
                    # get A: the row i without the element at j_col
                    list_A = []
                    for jj in range(n):
                        if jj == j_col: continue
                        list_A.append(matrix[i][jj])
                    # get B: the column j_col without the element at i
                    list_B = []
                    for ii in range(n):
                        if ii == i: continue
                        list_B.append(matrix[ii][j_col])

                    has_dup_A = (len(list_A) != len(set(list_A)))
                    has_dup_B = (len(list_B) != len(set(list_B)))

                    if has_dup_A and has_dup_B:
                        if a0 != 1:
                            v = 1
                        else:
                            v = 2
                        modifications.append((i, j_col, v))
                        found = True
                        break
                    elif has_dup_A and (not has_dup_B):
                        set_B = set(list_B)
                        v = min(set_B)
                        modifications.append((i, j_col, v))
                        found = True
                        break
                    elif (not has_dup_A) and has_dup_B:
                        set_A = set(list_A)
                        v = min(set_A)
                        modifications.append((i, j_col, v))
                        found = True
                        break
                    else:
                        set_A = set(list_A)
                        set_B = set(list_B)
                        common = set_A & set_B
                        if common:
                            v = min(common)
                            modifications.append((i, j_col, v))
                            found = True
                            break
                 if not found:
                    i = 0
                    a0 = matrix[0][j_col]
                    list_A = matrix[0][:j_col] + matrix[0][j_col+1:]
                    set_A = set(list_A)
                    v = next(iter(set_A))
                    modifications.append((0, j_col, v))

          Step6: output the modifications.

 Given the constraints and the total n^2<=10000, and the worst-case for one test case: n<=100, and the nested loops: 
      for the remaining bad rows (at most n) and for each we try at most n columns, and for each column we do O(n) to extract the lists -> O(n^2) per bad row, total O(n^3) per test case.
   And the worst-case test case: one test case with n=100, then 100^3 = 1e6, which is acceptable in Python.

 Let's hope.

 But note: the sum of n^2 across test cases is 10000, so the total number of elements is 10000.
   And the number of test cases t is at most 1000, but the sum of n^2 is 10000, so the maximum n is about 100, and there is at most 1 test case with n=100? 
   But also, the number of bad rows and bad columns might be small.

   In the worst-case, there are n bad rows and n bad columns, then we do:

        Step3: O(1) for each pair: n pairs? -> no, k = min(n,n)=n, so we do n pairs: each O(1) -> total O(n).

        Step4: for the remaining bad rows: none.
        Step5: for the remaining bad columns: none.

   Or if there are no pairs, then the remaining bad rows might be n, and then we do O(n) * O(n) * O(n) = O(n^3) = 1e6.

   And there is one test case with n=100? then 1e6.

   And the next test case: if the next test case has n=1? then not possible (n>=3). 

   The total n^2=10000, so one test case with n=100: n^2=10000, then only one test case.

   Therefore, the worst-case is one test case with n=100, and then we do step4 and step5: 
        The number of bad rows and bad columns can be up to 100.
        Step4: for the bad rows (say 100) and for each we iterate over 100 columns, and for each column we do O(100) for extracting the lists -> 100*100*100 = 1e6, which is acceptable.

   Therefore, we implement accordingly.

     However, note: we are not updating the matrix as we store the modifications. We are using the original matrix for the lists.

     This is acceptable because the modifications are not applied, and the conditions for the rows and columns are computed from the original matrix.

     But the changes in the pair step might have fixed the row and column? 
        We are not updating the matrix, so for the remaining steps, we use the original matrix.

     This is by design: the bad rows and columns are the original ones.

     And the remaining steps are applied to the original matrix.

     This should be fine.

     Let's hope.

     We'll run the sample test cases.

     Due to the complexity, we output the code.

     Note: we must not do an expensive set if we can do without, but n=100, so set of 99 elements is O(99).

     We'll do as described.

     Let's code accordingly.