 We are guaranteed that the graph of N nodes and N edges (each node has one outgoing edge) is connected and has no mutual edges (no i and j such that A_i = j and A_j = i). Therefore, the graph is a pseudotree (one cycle and trees attached to the cycle).

 Steps:
 1. Build the graph and compute the degree of each node.
 2. Use a queue to remove leaves (degree 1) until we are left with the cycle. This classifies edges: non-cycle (removed) and cycle.
 3. For each edge (represented by (min(u, v), max(u, v))), we store the original representation (u, v) and the list of materials.
 4. Precompute for each material, the list of workers that know that material.
 5. For each edge (both non-cycle and cycle), compute the list of workers that can work on that edge (by checking the materials of the edge against the material_to_workers mapping).

 6. We must assign workers to at least n-1 edges to form a spanning tree. Actually, we have two sets: non-cycle edges (which are bridges and must be included) and cycle edges (we need at least L-1 of them, where L is the cycle length).

 However, note: the problem allows us to skip some roads? Actually, we are not forced to build all roads. We can build a spanning tree with n-1 edges. But note: we are allowed to build more if we have extra workers? The problem says: assign each worker to construct a road (or not) such that the graph is connected. So we can build at most k roads, and we need at least n-1.

 Approach:

 We have two sets of edges: non-cycle (must be built because they are bridges) and cycle (we can skip one to break the cycle).

 Steps for matching:

 a) First, match all non-cycle edges. If we cannot assign a worker to every non-cycle edge, output -1.
    - We have |non-cycle| = n - L (because total edges n = non_cycle + L, so non_cycle = n - L).
    - Therefore, we need at least n - L workers for non-cycle edges.

 b) Then, we need to cover the cycle: we need at least L-1 edges from the cycle. So we must assign at least L-1 workers to the cycle edges (that are not already used for non-cycle).

 How to do:

 We can do bipartite matching in two steps:

 Step 1: Match non-cycle edges arbitrarily. We have a list of non-cycle edges. For each non-cycle edge, we try to assign a worker (from the list of workers that can build it) that has not been taken.

 Step 2: For the cycle edges, we try to assign workers that are left (not assigned in step 1). We need at least L-1 cycle edges to be built.

 But note: we might assign a worker that can build a cycle edge even if that worker could also build a non-cycle edge? However, step 1 already used some workers.

 However, our matching for non-cycle edges is done arbitrarily. We can try to match cycle edges with the remaining workers.

 But what if a worker can build both a non-cycle edge and a cycle edge? We have to assign it to a non-cycle edge first because non-cycle edges are mandatory.

 Steps:

  - Precompute for each edge (by key) the list of workers that can build it.

  - We do matching for non-cycle edges: we try to assign each non-cycle edge to a worker. We use DFS (or a greedy matching) for the bipartite graph: left side is non-cycle edges, right side is workers. We can use a DFS for each non-cycle edge.

  - Then, for cycle edges: we do another matching for the cycle edges, but we skip the workers that are already taken. We need at least L-1 matches.

  - However, note: if we have k workers and we have used n-L for non-cycle, then we have k - (n-L) workers left. We need at least L-1 from cycle. So if k - (n-L) < L-1, then we fail? Actually, k must be at least (n-L) + (L-1) = n-1. And we already checked k>=n-1? Actually, we check at the beginning: if k < n-1, then output -1.

 But note: the problem states k>=1 and n>=3, so we can check:

    if k < n-1: print -1 and return.

  - Now, after matching non-cycle edges, we have k' = k - (n-L) workers left. We then try to match as many cycle edges as possible, but we require at least L-1.

 However, there is a catch: we might not need to assign L-1 cycle edges if we can assign the entire cycle? Actually, no: we can break the cycle by skipping one edge. So we need to build at least L-1 cycle edges. But note: we are allowed to build the entire cycle? That would be L edges. Then we have a graph with n edges? But then we have a cycle and the non-cycle edges, so the entire graph? Actually, the entire graph is connected. So we have two options:

    Option 1: Build the entire graph (if we have enough workers and we can match all cycle edges). Then we use n edges (which is n-1+1? Actually n-1 for the spanning tree plus one extra doesn't break connectivity). But note: we have n edges and n nodes -> one cycle and the rest trees. It's connected.

    Option 2: Build a spanning tree: we skip one cycle edge arbitrarily.

 How to decide?

  - We must build all non-cycle edges (n-L) and at least L-1 cycle edges. So total edges built: at least n-1.

  - We can build up to k edges.

  Possibility:

    If we have k >= n, then we can try to build all n edges? But only if we can match all n edges. If we can, then we build the entire graph. Otherwise, we build a spanning tree.

    But note: the problem does not require building the entire graph? It only requires connectivity.

    However, we have two constraints:

      - We must build all non-cycle edges (they are bridges) to avoid disconnecting the graph? Actually, if we skip a non-cycle edge, then the graph becomes disconnected? Because non-cycle edges are bridges? How do we know? Actually, in the process of leaf removal, we remove all edges that are not in the cycle. Therefore, each non-cycle edge is a bridge: if removed, the graph becomes disconnected. So we must build every non-cycle edge.

    For the cycle: we can skip exactly one edge arbitrarily? Actually, we can skip any one edge in the cycle and the rest of the cycle plus the non-cycle edges form a spanning tree.

    Therefore, the minimal set is: all non-cycle edges and any L-1 cycle edges.

    So the minimal number of edges is n-1 (which is (n-L) + (L-1)).

    But we are allowed to build more? Yes, as long as we assign the worker to a road that the city proposed. And building more doesn't break connectivity.

    However, note: we have to assign each worker to at most one road. So if we have more than n-1 workers, we can build up to min(n, k) roads? But note: we have n proposed roads.

    So:

      Option A: Build the entire graph (all n edges) if we can match all n edges? But we only have k workers. So we need k>=n and we can assign all n edges.

      Option B: Build a spanning tree: we build all non-cycle edges and L-1 cycle edges (so n-1 edges). Then the remaining k - (n-1) workers can be assigned arbitrarily? But note: we are required to assign each worker to a road? Actually, the problem says: if a worker does not construct any road, output 0 0. So we can leave workers idle.

    However, we are constrained: each road can only be built by a worker that knows the material and each road can be built at most once.

    So the plan:

      Step 1: Match all non-cycle edges (n-L edges). If we cannot, output -1.

      Step 2: Try to match as many cycle edges as possible (with the remaining workers). Let M_cycle = number of cycle edges we matched.

      Now, we require M_cycle >= L-1. Otherwise, we cannot form a spanning tree? Because we must have at least L-1 cycle edges to go along with the non-cycle edges.

      Then, how do we output?

        If we have M_cycle >= L-1, then we can form a spanning tree by skipping one cycle edge arbitrarily? Actually, we can skip any one cycle edge that we did not assign? But note: if we matched exactly L-1 cycle edges, then we skip the unmatched cycle edge. If we matched L cycle edges, then we have built the entire cycle. Then we can skip none? Actually, we don't have to skip if we built the entire cycle? Because the entire graph is connected? Yes, but note: we built all non-cycle edges and the entire cycle -> the entire graph is connected. So we don't need to break the cycle.

        However, we have built n edges (if we built all). But if k is exactly n, then we have built n edges. If k>n, we can build at most n edges (because we have only n roads) and the rest workers are idle? Actually, we have n roads. So we can build at most n edges.

        Therefore, we can build:

          - All non-cycle edges: n-L
          - Some cycle edges: at least L-1 and at most L.

        How to choose which cycle edge to skip? 

          We skip one cycle edge only when we have built exactly L-1 cycle edges? Or we skip one even if we built L? 

          Actually, if we built L cycle edges, then we don't skip any. But if we built L cycle edges and we are only required to have connectivity, that is okay. However, we must note: we are going to output k assignments. We have to assign:

            n-L non-cycle edges and L cycle edges -> total n edges? But what if k > n? Then we have k-n workers that are idle. But we are allowed to output 0 0 for them.

          But the problem says: we may output any assignment as long as the graph is connected. So building the entire graph is connected.

        However, if we built the entire cycle, we don't skip any. But what if we built L cycle edges and we have k>=n? Then we output:

          all non-cycle edges and all cycle edges.

        But if we built L cycle edges and we have k < n? That is impossible because k>=n-1 and we built n edges only when k>=n.

        Therefore, we have:

          If we have k >= n and we matched all cycle edges (M_cycle == L), then we build all.

          Else, we build the non-cycle edges and L-1 cycle edges (so total n-1). We skip one cycle edge arbitrarily? But which one? We skip an unmatched cycle edge. If there is more than one unmatched? Actually, we only require at least L-1. So we skip one arbitrarily? But note: we might have matched L-1 cycle edges, then we skip the unmatched one. If we matched L, then we skip one arbitrarily? Actually, we don't need to skip if we built L? Then we have built n edges. But if k < n, then we cannot build n edges. So we must build exactly n-1 edges? How?

        Actually, the minimal requirement is n-1 edges. But if we have k>=n and we can build all n, then we do. Otherwise, we build n-1.

        How to skip one cycle edge?

          We skip one cycle edge arbitrarily? But we must decide which one to skip. We can skip an edge that we did not assign? Or if we assigned all cycle edges, then we must skip one arbitrarily? But then we have to break an assignment? 

          Actually, the problem does not require building a spanning tree necessarily. It requires connectivity. The entire graph is connected. So if we built all n edges, that's fine.

          However, if k < n, then we cannot build all n. Then we must build n-1 edges. How?

          We have already matched:

            non-cycle: n-L (must)
            cycle: M_cycle (which is at least L-1 and at most L)

          But if k < n, then we cannot assign all n edges. So we must not assign one of the cycle edges? But we have already assigned M_cycle cycle edges. How many edges are we building? n-L + M_cycle.

          We require: n-L + M_cycle = n-1? Then M_cycle must be L-1. So if we have k = n-1, then we must have M_cycle = L-1.

          Therefore, if we have k = n-1, then we have:

            non-cycle: n-L
            cycle: L-1 -> total: n-L + L-1 = n-1.

          So we skip one cycle edge: the one that we did not assign.

          But what if we have k >= n? Then we can build n edges? But only if we matched all cycle edges? What if we only matched L-1? Then we skip one and we have built n-1. But we have extra workers that can build that skipped edge? Then we don't have to? Actually, we can leave them idle.

          However, if we have matched L-1 cycle edges, then we skip the unmatched one. Then we have built n-1 edges. Then the remaining workers (k - (n-1)) are left idle.

          But if we have matched L cycle edges, then we build all n edges? Then we have built n edges, and the remaining k-n workers are idle.

        How do we know which cycle edge to skip? 

          We skip exactly one cycle edge: we can choose any? But we must break the cycle? Actually, we can skip any one edge in the cycle to break the cycle? But we cannot skip a non-cycle edge.

          So:

            If we built all cycle edges (M_cycle == L) and k>=n, then we skip none? Then we build all n edges.

            If we built L-1 cycle edges, then we skip the unmatched cycle edge.

          But wait: what if we built L cycle edges and k>=n, then we build all. Then we don't skip any.

          However, what if we built L cycle edges and k < n? That cannot happen because we built n-L (non-cycle) + L (cycle) = n edges, and we require k>=n? Actually, we only assign workers to n edges if k>=n. If k < n, we cannot assign all n edges. Therefore, in step 2, we are matching cycle edges with the remaining workers (which are k - (n-L)), so the maximum cycle edges we can match is min(L, k - (n-L)). Therefore, if k < n, then we cannot match all cycle edges. So M_cycle might be less than L.

          Actually, we require at least L-1, so we are safe if we matched at least L-1.

        Therefore, the algorithm:

          Step 1: Check if k < n-1 -> output -1.

          Step 2: Match non-cycle edges. If we cannot match all, output -1.

          Step 3: Match cycle edges: we try to match as many as possible (with workers that are not taken). Let M_cycle = number of matched cycle edges.

          Step 4: If M_cycle < L-1, output -1.

          Step 5: Now we have two possibilities:

            Possibility A: We skip one cycle edge arbitrarily. We choose one cycle edge that is not assigned? But note: we might have matched L-1 cycle edges, then there is one unmatched. We skip that unmatched.

            Possibility B: We skip one cycle edge even if we matched all? Actually, if we matched all cycle edges and k>=n, then we don't skip. But if we matched all cycle edges and k==n, then we build all? Then we don't skip. However, if we have k>n, we can build all and leave the rest idle? But we are building exactly n edges? Then the rest are idle.

          But note: we are allowed to build the entire graph? Then we don't have to break the cycle? The entire graph is connected.

          Therefore, we skip a cycle edge only when we built exactly L-1 cycle edges? Actually, no: we skip a cycle edge if we are building a spanning tree? Actually, we don't have to skip if we built the entire cycle? Then the entire graph is connected.

          So:

            We skip a cycle edge if we are not building the entire cycle? Actually, we skip one cycle edge if we built L-1. But if we built L, then we don't skip.

          How to represent:

            skip_edge_index = None
            if M_cycle == L and k >= n:
                # we built all cycle edges, so we don't skip any.
                skip_edge_index = None
            else:
                # we skip one cycle edge: we choose one that is not matched? 
                # But if we matched L-1, then there is one unmatched. We skip that unmatched.
                # If we matched L, but k < n? Actually, we cannot have matched L when k < n because we require n workers for n edges? Then we would have matched only k - (n-L) cycle edges, which is k - (n-L) <= L? And k < n -> k - (n-L) = k - n + L <= L-1? Actually, we require at least L-1, and we matched at least L-1. So we skip one arbitrarily? Actually, we skip one that we didn't assign? Or we break one of the assignments? 

                # Actually, we built n-L + M_cycle edges. We require n-1. So we skip one edge arbitrarily? But we have to remove one cycle edge to break the cycle? And we are not building that edge. So we skip an edge that we did not build? But we might have built all cycle edges? Then we cannot skip? Then we don't need to skip.

            Actually, we skip an edge only if we built L-1? Then we skip the unmatched one.

            But if we built L, then we don't skip.

          However, what if we built L cycle edges but then we don't have enough workers to build the entire graph? Actually, we built n edges? Then we require n workers. And we have k>=n? Then we build all. Otherwise, we built L cycle edges and k>=n? Then we build all.

          But if k < n, we cannot build all n. Then we must build exactly n-1. So we skip one cycle edge arbitrarily? But we already matched M_cycle cycle edges? How do we choose which one to skip? 

          Actually, we can skip any one cycle edge. We don't care? But we must break an assignment? 

          Let me reexamine:

            We have matched non-cycle edges: n-L (fixed) and cycle edges: M_cycle (which is at most k - (n-L)). Since k < n, then k - (n-L) < L. So we cannot have matched all L cycle edges? Therefore, M_cycle < L. Then we skip an unmatched cycle edge.

          Therefore, we skip:

            If we built M_cycle cycle edges (which is less than L) and we require to skip one cycle edge to break the cycle? Actually, we skip one cycle edge that we did not build? Then we don't assign any worker to that edge. That is automatic: we didn't assign it.

          But then why do we need to explicitly skip? We don't. We just output the assignments we have.

          However, note: the graph we built: non-cycle edges (n-L) and M_cycle cycle edges. We require that the graph is connected. The graph is connected if and only if we have built at least L-1 cycle edges? Why?

            The non-cycle edges form trees attached to the cycle. The cycle has L nodes. If we build M_cycle cycle edges, then the cycle becomes a tree? Actually, if we build M_cycle = L-1, then the cycle becomes a path? So the entire graph is connected? Yes.

            But if we build less than L-1? Then the cycle is broken into multiple connected components? Then the graph is disconnected? So we require at least L-1.

          Therefore, we only skip by not building one edge? And we are not building exactly one cycle edge? Then the graph is connected.

          So in summary:

            We assign:

              non-cycle edges: all (n-L) -> they are built.

              cycle edges: we build M_cycle (which is at least L-1) edges. Then we skip the remaining L - M_cycle cycle edges? Actually, we skip by not building them.

          Therefore, we don't have to do anything extra? Then we output:

            For each non-cycle edge: we output the worker assigned to it.

            For each cycle edge: if we assigned a worker to it, then output that assignment; otherwise, skip (meaning we don't output for that edge).

          But note: we have k workers. We output for each worker:

            either the road (u, v) that the worker builds, or 0 0.

          How do we map the worker to the road?

            We have:

              non_cycle_edges: list of edges. For each non_cycle edge i, we have match_non[i] = worker_id assigned to that edge.

              cycle_edges: list of edges. For each cycle edge i, we have match_cycle[i] = worker_id assigned to that edge? But note: we did two separate matchings? Actually, we have:

                In step 1: we matched non-cycle edges and set match_worker for each worker to the non-cycle edge index (if assigned) or -1.

                In step 2: we did a matching for cycle edges only on workers that were not taken? And we stored in match_cycle for the cycle edge index the worker id? And in match_worker_cycle? Actually, we stored in match_worker_cycle for a worker the cycle edge index? But we also have match_worker for non-cycle.

          Actually, in the code we have:

            match_worker: array of size k, for worker i, if assigned to a non-cycle edge, then the index of the non-cycle edge? Otherwise -1.

            Then for cycle edges, we only consider workers that are not taken? And we did a separate array for cycle: match_cycle for each cycle edge index -> worker id? And also an array for workers for cycle? Actually, we have:

              match_worker_cycle: array of size k, for worker i, if assigned to a cycle edge, then the index of the cycle edge? Otherwise -1.

          Then for output:

            We create an array `res` of size k, initially all "0 0".

            For each non-cycle edge index i:
                worker_id = match_non[i]   [which is the worker assigned to non-cycle edge i? Actually, we stored in step1: for non-cycle edge i, we set match_non[i] = worker_id, and also set match_worker[worker_id] = i? Actually, we set match_worker[worker_id] = i? But note: we have:

                    match_non[i] = worker_id   (if matched)
                    match_worker[worker_id] = i   (so that we know that worker_id is taken by non-cycle edge i)

            Then for each cycle edge index i:
                worker_id = match_cycle[i]   [if we matched it?]
                Then we set res[worker_id] = the road for that cycle edge.

          But what if we want to skip one cycle edge? We don't assign any worker to that edge? Then it is not built? And we don't output it? So we don't set any worker to build it.

          However, we have already skipped it in the matching? Because we only matched M_cycle cycle edges? Then we don't assign that edge.

          Therefore, we don't have to do anything? Then why in the sample output the fifth worker builds (4,2) which is a cycle edge? And the fourth worker builds nothing.

          But note: the sample input has:

            n=4, k=5.

            non-cycle edges: none? Actually, let's see:

              Cities: 1->2, 2->3, 3->4, 4->2.

              The graph: 
                1: connected to 2 (edge1)
                2: connected to 1, 3, 4 (edge1, edge2, edge4)
                3: connected to 2, 4 (edge2, edge3) -> wait, city3 proposes to connect to 4? Then edge (3,4). 
                4: connected to 3 and 2 (edge3 and edge4)

              How to remove leaves:

                Start with node 1: degree1=1 -> remove edge (1,2). Then node2: now becomes degree 2 (because we remove one edge) -> not leaf? Then we remove node? Actually, the algorithm:

                  deg[1]=1 -> remove edge (1,2): then deg[1]=0, deg[2] becomes 2 (from 3).
                  Then we look for leaves: node3: connected to 2 and 4 -> deg=2? node4: connected to 3 and 2 -> deg=2. So we stop.

                Then the remaining cycle: nodes 2,3,4 with edges (2,3), (3,4), (4,2). So non-cycle edge: (1,2). Cycle edges: (2,3), (3,4), (2,4).

                Actually, the sample output:

                  worker1: (1,2) -> non-cycle
                  worker2: (2,3) -> cycle
                  worker3: (3,4) -> cycle
                  worker5: (4,2) -> cycle

                Then they built all non-cycle and all cycle? So 4 edges? Then the graph is the entire graph? which is connected.

                The fourth worker is idle.

          Therefore, our algorithm:

            Step 1: Check k>=n-1? Yes, k=5>=3.

            Step 2: Match non-cycle edge (1,2). We have one non-cycle edge. We assign a worker that can build material in B1? B1: [1,2]. The workers: [1,2,3,4,5]. So worker1: material1 -> matches. Then we assign worker0 (index0) to non-cycle edge0.

            Step 3: Then we have workers [1,2,3,4] left. Now we try to match cycle edges: (2,3), (3,4), (2,4). Materials:

                For (2,3): from city2: [2,3] -> so workers: material2: worker1? but worker1 is index1 -> material2? no, the workers materials: [1,2,3,4,5]. So:

                  (2,3): materials [2,3] -> workers: worker1 (material2) and worker2 (material3) -> so two workers.

                  (3,4): materials [3,4] -> worker2 (material3) and worker3 (material4) -> two workers.

                  (2,4): materials [4,5] -> worker3 (material4) and worker4 (material5) -> two workers.

            How to match? We do a DFS for each cycle edge? We can match:

              edge (2,3) with worker1 (material2) -> index1.
              edge (3,4) with worker2 (material3) -> index2.
              edge (2,4) with worker3 (material4) -> index3? But wait: worker3 has material4, which is in [4,5]? yes.

            Then we matched all cycle edges? M_cycle=3, which is L=3. So we skip none.

            Then we output:

              worker0: non-cycle edge (1,2) -> "1 2"
              worker1: cycle edge (2,3) -> "2 3"
              worker2: cycle edge (3,4) -> "3 4"
              worker3: cycle edge (2,4) -> "2 4" but note: the representation: (min(2,4), max(2,4)) is (2,4). However, the original representation from city4: (4,2) -> but we stored the original representation? Actually, we stored for each key the original representation? 

            How we stored:

              For edge (1,2): from city1: (1,2) -> stored as (1,2) in original_rep.

              For edge (2,3): from city2: (2,3) -> stored as (2,3) in original_rep? Actually, we did:

                for i=1 to n:
                  u = i, v = A[i]
                  key = (min(u,v), max(u,v))

                Then original_rep[key] = (u, v) -> but note: for city2: u=2, v=3 -> so (2,3). Similarly, for city3: u=3, v=4 -> (3,4). For city4: u=4, v=2 -> so (4,2). Then when we store for key (2,4) (which is the same as (4,2)): we stored the last one? Actually, we overwrite? 

            How do we avoid? Actually, we stored:

              for i=1 to n:
                key = (min(i, A[i]), max(i, A[i]))
                original_rep[key] = (i, A[i])   -> but if we do for i=4: key = (min(4,2), max(4,2)) = (2,4) -> and we set original_rep[(2,4)] = (4,2). Then if we do for i=2: when A[2]=3, so key=(2,3) -> original_rep[(2,3)] = (2,3). For i=3: key=(3,4) -> (3,4). Then for i=4: key=(2,4) -> (4,2).

            Then when we output:

              For edge (2,4): we have stored (4,2). So we output "4 2".

            Therefore, the fifth worker (index4) is not assigned? Then output "0 0" for worker4? But the sample output for the fifth worker is "4 2"? Actually, no: the fifth worker is index4? And we assigned worker3 to (2,4)? Then worker4 (index4) is not assigned? But the sample output:

                worker0: "1 2"
                worker1: "2 3"
                worker2: "3 4"
                worker3: "0 0" -> no, wait: the sample output:

                  1 2
                  2 3
                  3 4
                  0 0
                  4 2

            The fifth worker is the last one (index4) and we output "4 2". But we assigned (2,4) to worker3? Then why worker4? 

            Actually, the workers input: [1,2,3,4,5]. The worker list: worker0: material1, worker1: material2, worker2: material3, worker3: material4, worker4: material5.

            We assigned:

              non-cycle edge (1,2): material1 -> worker0 (index0) -> output first worker: "1 2"

              cycle edge (2,3): material2 -> worker1 (index1) -> output second: "2 3"
              cycle edge (3,4): material3 -> worker2 (index2) -> output third: "3 4"
              cycle edge (2,4): material4 -> worker3 (index3) -> output fourth: "4 2"? But the sample output fourth worker is "0 0", and fifth is "4 2".

            Why? Because the problem says: output in the same order as input.

            Our output for worker0: first worker -> "1 2"
            worker1: second worker -> "2 3"
            worker2: third worker -> "3 4"
            worker3: fourth worker -> we output "4 2" -> but the sample output fourth worker is "0 0", and fifth worker is "4 2".

            What's the problem? We assigned worker3 to the cycle edge (2,4) -> which we stored as (4,2). Then we output for worker3 (the fourth worker) the string "4 2". Then the fifth worker (worker4) is not assigned -> output "0 0".

            But the sample output for the fourth worker is "0 0" and the fifth is "4 2". 

            Why the sample output is:

                1 2
                2 3
                3 4
                0 0
                4 2

            This implies that the fifth worker built the road (4,2). That worker has material5. The road (4,2) has materials [4,5]? So material5 is allowed. Then we can assign the fifth worker to that road? But we already assigned the fourth worker (with material4) to that road? Then we cannot assign two workers to the same road.

            Therefore, the sample output is inconsistent? Actually, the problem says: each worker can only construct at most one road. And each road can be constructed by at most one worker.

            So the sample output must assign each road at most one worker.

            How the sample input describes:

                The first worker constructs a road connecting city 1 and city 2.
                The second worker constructs a road connecting city 2 and city 3.
                The third worker constructs a road connecting city 3 and city 4.
                The fourth worker does not construct any road.
                The fifth worker constructs a road connecting city 4 and city 2.

            This uses two cycle edges: (2,3) and (3,4) and (4,2) are all built? Then the entire cycle is built? And the non-cycle edge (1,2) is built. Then the entire graph is built? But then why assign the fifth worker to (4,2)? That road is built by one worker? And the fourth worker is idle.

            But wait: the sample input says the road (4,2) can be built with materials [4,5]. Then we can assign either a worker with material4 or material5. The fourth worker has material4? and the fifth worker has material5? Then we could assign the fifth worker to (4,2) and leave the fourth worker idle? That is valid.

            Therefore, we must not fix the assignment arbitrarily? We must be able to choose which worker builds which road? 

            How did we assign? In the cycle edge matching, we did a DFS that might assign arbitrarily? We did:

              for each cycle edge index, we try workers that are not taken? and we take the first available? 

            But we did:

              for edge in cycle_edges_list: we try workers in the list? The list of workers for edge (2,4) is [worker3 (material4), worker4 (material5)]? Then we might assign worker4? Then the output for worker4 would be (4,2) and worker3 would be idle? 

            How to control? We want to output in the same order as workers? Actually, the problem does not require that we assign the worker to the road arbitrarily? We just have to output for each worker (in input order) the road they build.

            We have:

              We have assigned:

                non-cycle: worker0 -> edge0: (1,2)
                cycle: 
                  (2,3): worker1 -> because we tried worker1 first? 
                  (3,4): worker2 -> because we tried worker2 first?
                  (2,4): we try worker3 and worker4: we might assign worker3? 

            Then we output:

              worker0: (1,2)
              worker1: (2,3)
              worker2: (3,4)
              worker3: (2,4) -> which we output as (4,2) because we stored the representation from city4: (4,2). But note: we stored the representation from the city with the higher index? Actually, we stored the representation from the city i: so (i, A_i). For (2,4): we stored (4,2) because the last time we encountered the edge (2,4) was from city4.

            How do we know which representation? We stored the last one? Actually, we do:

              for i=1 to n: 
                 key = (min(i, A_i), max(i, A_i))
                 original_rep[key] = (i, A_i)

            So for edge (2,4): we store the representation from the last city that has this edge? Since we iterate from 1 to n, city4 is the last? So we get (4,2). 

            Then we output for worker3: "4 2". But the sample output assigns the fifth worker to "4 2". 

            To get the sample output, we must assign the fifth worker to (4,2) and leave worker3 (the fourth worker) idle.

            How to achieve that? We can change the order of trying workers? We try workers with higher index first? Then for edge (2,4): we try worker4 first? Then assign worker4? Then worker3 is left.

            But the problem does not require a particular assignment? It says: "You may output any assignment as long as any pair of cities are connected by a sequence of constructed road."

            However, the sample output is one valid assignment. We can output:

                worker0: 1 2
                worker1: 2 3
                worker2: 3 4
                worker3: 0 0
                worker4: 4 2

            How? In the matching for cycle edges, we try workers in reverse order? Or we can sort the worker_list for an edge by worker index? And then try from high index to low index? Then we assign the last worker? Then the higher index worker is taken? Then the lower index worker is left? But we want to leave worker3 (index3) and take worker4 (index4). So we try higher index first.

          Therefore, in the worker_list for an edge, we sort by worker index? And then we try in descending order? Then when we do DFS for the cycle edges, we try the workers with higher index first? Then we assign worker4 to edge (2,4) and then worker3 is free.

          But note: the DFS for matching in cycle edges: we are doing a greedy DFS? We can change the order of iteration.

          However, the DFS for bipartite matching: the order of iterating the workers might affect which worker we assign. We want to assign the highest index worker? So that we free lower index workers for other edges? Actually, we want to assign the worker that is least likely to cause conflict? But we don't care? We just want to maximize the number of matches.

          But for output: we want to leave a lower index worker idle? Then we assign the higher index worker to the road? Then the lower index worker becomes idle and we output 0 0 for that worker.

          How? We can sort the list of workers for each edge by worker index in descending order? Then we try the higher index worker first.

          Therefore, in the code:

            For each edge, when we build worker_list, we can sort it? But note: the list might be unsorted? We can sort in descending order? Then in the DFS, we iterate the list in that order.

          But note: the problem does not require a particular assignment? So we can choose arbitrarily? But to match the sample output, we do descending order.

          Alternatively, we can do: for the cycle edges, we do the matching in the order of the cycle edges? and for each edge, we try workers in descending order? Then we assign the highest available worker.

          But the sample output requires the fifth worker to build the last edge? So we must assign worker4 to the edge (2,4). Then worker3 is left.

          Therefore, we change the cycle matching: 

            In the function dfs_cycle, we try workers in descending order? 

          Actually, we can sort the worker_list for each edge by worker index in descending order? Then when we iterate, we try from highest to lowest.

        However, the problem does not require the same output as the sample, but any assignment. So we can do either. But to be safe and avoid blocking a worker that is needed for a later edge? Actually, we don't care? We just need to match as many as possible.

        But the problem: if we assign a low index worker to an edge, then a high index worker might be left idle? Then we output the low index worker as building a road and the high index worker as idle? Then the output for the high index worker is 0 0? That is acceptable.

        However, the sample output has the idle worker in the middle? The fourth worker is idle and the fifth worker is assigned? So we must output:

          worker0: road
          worker1: road
          worker2: road
          worker3: 0 0
          worker4: road

        How? We must assign the worker4 to a road and leave worker3 idle? Then we must avoid assigning worker3 to any road? How? 

          In the matching for cycle edges, we must skip worker3? But how? We did: for each edge, we try the workers that are not taken? And we try arbitrarily? 

          Actually, we can do:

            For the cycle edge (2,4), we have two workers: [3,4] (if we stored in ascending order by worker index). Then we try worker3 first? Then we assign worker3? Then worker4 is not assigned? Then we output worker4 as idle? Then the fourth worker (index3) is assigned and the fifth (index4) is idle? Then output:

              worker3: "4 2"
              worker4: "0 0"

            But the sample output has the fourth worker idle and the fifth worker assigned.

          Therefore, to get the sample output, we must assign worker4 to (2,4) and leave worker3 idle? Then we should try worker4 first? 

        How: sort the worker_list for each edge by worker index in descending order? Then for edge (2,4), we try worker4 first? Then we assign worker4? Then we break.

        Therefore, we add:

          For each edge, after building worker_list, sort it in descending order? 

          But note: we are storing the worker_list for each edge. Then in the DFS for cycle edges, we iterate over worker_list in the order we stored? So we can sort each worker_list in descending order.

        However, we did the same for non-cycle edges? Actually, we did not. For non-cycle edges, we did:

          We did a DFS that iterates the worker_list in the order of the list? We did not sort. So we might assign a low index worker to a non-cycle edge? That is acceptable.

        But for cycle edges, we want to assign the highest index worker first? Why? To leave the lower index workers idle? Then when we output, the lower index workers that are not assigned become 0 0 and the higher ones get the roads? But the problem requires output in the order of the workers: first worker, second, ... 

        Actually, we don't care which worker is idle? We only care that we output for the i-th worker (in order) the road they build? And if we assign a worker to a road, we output the road? If not, we output 0 0.

        Therefore, we can assign arbitrarily? The problem does not require that we assign the first available worker? 

        But to get the sample output, we need to assign the fifth worker to (4,2) and not the fourth? 

        How? We can avoid assigning worker3? Why? Because the edge (2,4) can be built by either worker3 or worker4? So we can choose to assign worker4? Then we leave worker3 idle? 

        How? In the DFS for cycle edges, we can try workers in descending order? Then we assign the highest available worker? Then the lower ones are left? Then the output for worker3 will be 0 0 and for worker4 the road.

        Therefore, we do:

          For each edge (both non-cycle and cycle) we sort the worker_list in descending order? 

          But for non-cycle edges, we did a DFS that uses the order? It might affect the matching? But we only need to know if we can match all non-cycle edges. The order might affect the matching? But we can use any matching? So we can sort in descending order for non-cycle too? Then we assign the highest available worker to non-cycle edges? Then the lower index workers are left for cycle edges? 

          Then in the cycle edges, we assign the highest available worker? Then the idle workers would be the lower index ones? Then we output:

            The first few workers (low index) might be assigned to non-cycle? Then the next to cycle? Then the last ones to cycle? But the idle workers would be the ones that are not assigned? They could be anywhere? 

        Actually, we don't care? The problem does not require that the idle workers are the last? The sample output has the idle worker in the middle? 

        Therefore, we change:

          After building worker_list for an edge, sort it in descending order? 

        But note: the list might be long? But the total sum of M_i is 10000? Then the total length of all worker_lists is at most 10000? So sorting each list? The worst-case: one edge has 10000 workers? Then sorting is O(10000 log(10000)) which is acceptable? But note: the total length of all worker_lists is 10000? Actually, the problem says the sum of M_i is 10000? Then the total number of material numbers in all B_i is 10000? Then the total length of the worker_lists (across all edges) is at most 10000? Because each material number appears in an edge and we look it up in material_to_workers? Then we are concatenating the lists? The total length is the sum over edges of (number of workers that can build that edge) = sum_{edge} (number of materials in the edge that appear in material_to_workers) * (frequency of that material in workers).

        But note: the same material might appear in multiple edges? And the material_to_workers for a material might be a long list? Then the total length of worker_lists might be large? 

        Actually, the total length of worker_lists is bounded by: for each material, the number of edges that have that material multiplied by the number of workers for that material. And the sum over materials? 

        But the problem says: the sum of M_i (the total number of material numbers in all the arrays) is 10000. So there are at most 10000 distinct (edge, material) pairs? Then for each such pair, we add the entire list of workers for that material? And the total number of workers is k (<=2000). Then the total length of worker_lists is at most 10000 * (max frequency of a material)? But worst-case: one material might appear in 10000 edges? Then we add the entire worker list for that material (which is at most 2000) for each edge? Then total length = 10000 * 2000 = 20e6? Which is acceptable? But worst-case 20e6 integers? That is 80MB? And we have to sort each list? The worst-case: one edge has 2000 workers? Then sorting one edge: 2000*log(2000) ~ 2000*11 = 22000 operations? And we have at most 10000 edges? Then worst-case 10000 * 22000 = 220e6 operations? That might be borderline in C++? But note: the total length of worker_lists is bounded by the total (edge, material) pairs (10000) times the maximum number of workers for a material? Actually, worst-case: if one material appears in all edges? Then we have one material that appears in 10000 edges? Then the list for each edge for that material is the entire list of workers for that material? And if there are many workers for that material? The total length would be 10000 * (number of workers for that material). And the number of workers for that material is at most 2000? Then 10000*2000=20e6? Then we have 20e6 integers in total? Then we don't have 10000 edges? We have n edges? n<=2000? Then worst-case: 2000 * 2000 = 4e6? Then we can do.

        Actually, the graph has n edges? n<=2000. Then the total length of worker_lists is bounded by: for each edge, the number of workers that can build it? The worst-case: one edge has up to 2000 workers? Then total length is 2000 * 2000 = 4e6? Then we can sort each list? But 2000 lists? Each of size up to 2000? Then the total cost is 2000 * (2000 log(2000))? 2000 * (2000 * 11) = 2000 * 22000 = 44e6? Which is acceptable in C++? 

        But note: the problem says the sum of M_i is 10000? So the total number of distinct materials in all edges is 10000? But we are building the worker_list for an edge by:

          for each material m in the edge's material list:
            if m in material_to_workers, then append the entire list of workers for m.

          Then the length of the worker_list for an edge is: sum_{m in the edge} |material_to_workers[m]|.

          The worst-case: an edge has 10000 materials? Then we append for each material the list of workers? Then the list for that edge could be 10000 * (average number of workers per material)? And the total over all edges: 10000 (the total M_i) * (average) -> worst-case total length: 10000 * 2000 = 20e6? Then we have to sort 2000 lists? Each list might be long? The worst-case one edge has 10000 materials? Then the worker_list for that edge has length: 10000 * (average) -> worst-case 10000 * 2000 = 20e6? Then we cannot sort that one list? 20e6 * log(20e6) is too high.

        Therefore, we must avoid building huge lists? 

        Alternate approach: Instead of building the entire list and then sorting, we can use a set? Or we can use a priority queue? 

        Actually, we don't need to sort the entire list? We only need to try workers in descending order? We can collect the workers for an edge and then without sorting the entire list, we can use a heap? Or we can do:

          We know that the workers are indexed from 0 to k-1. We can precompute an array for each edge: we want to try workers from k-1 down to 0? But we only want workers that are available? 

        Actually, in the DFS for matching, we are iterating the worker_list. We can build the list and then sort in descending order? But if the list is huge? Then we avoid building such a list? 

        But note: the total length of worker_lists is bounded by 10000? The sum of M_i is 10000, so the total length of worker_lists is at most 10000 * (max frequency of a material in workers). How to bound the max frequency? The workers are k=2000. The worst-case: one material appears in many workers? Actually, the same material can be assigned to many workers? Then the frequency of a material can be up to 2000? Then the total length of worker_lists is 10000 * 2000 = 20e6? Then we can build the lists? And then sort each list? The worst-case one edge has 10000 materials? Then the list for that edge is 10000 * (frequency of that material). But worst-case one material appears in 2000 workers? Then the list for that edge is 10000 * 2000 = 20e6? Then we cannot sort one list of 20e6 elements? 

        How to avoid? We can note: the same worker might appear multiple times? Because one worker can know one material, and an edge might have multiple materials? Then the same worker might appear multiple times? Then we should deduplicate? 

        Actually, we can use a set for each edge? Then the list of workers for an edge is the union over materials of the workers for that material? Then the size is at most the total number of workers that can build that edge? Which is <= k? <=2000. Then we can build a set? Then we have a list of at most 2000 workers per edge? Then the total length is 2000 * 2000 = 4e6? 

        How? 

          For an edge, we iterate over its materials. For each material m, we look up material_to_workers.get(m, []). Then we add the workers to a set? Then we convert to a list and sort in descending order.

        Then the cost per edge: O(M_i) for the edge plus O(union_size) for the set? And the total M_i is 10000? Then the total cost is 10000 + total_union_size? And the total_union_size is the total number of distinct (edge, worker) pairs? Which is at most 2000 * 2000 = 4e6? 

        Therefore, we do:

          worker_set = set()
          for m in materials:
              if m in material_to_workers:
                  for w in material_to_workers[m]:
                      worker_set.add(w)
          worker_list = sorted(worker_set, reverse=True)

        Then the list for each edge is the distinct workers that can build that edge, sorted in descending order.

        Then the total cost: O(10000) for iterating all materials, plus O(4e6) for building the sets and sorting? Because the total distinct pairs is 4e6? Actually, worst-case: each worker appears in many edges? The total distinct pairs: each worker is counted once per edge that has a material that the worker knows? The total over workers: the sum over workers of the number of edges that have a material that the worker knows? The total is bounded by: for each worker, the number of edges that have the worker's material? But the worker's material is a single number? Then the worker appears in an edge if the edge's material list contains that material. The total over workers: the sum_{worker} (number of edges that have the material of the worker) = the sum_{edge} (number of workers that can build that edge) = the total_union_size? Then we are building the set for each edge, so we do:

          For each edge: we iterate over its materials, and for each material we iterate over the workers for that material? Then the total cost is the total length of the worker_lists without deduplication? Which is bounded by 10000 * (max frequency of a material in workers) = 10000 * 2000 = 20e6? 

        But with deduplication by a set per edge, the cost per edge is O(M_i) + O(|worker_list_after_set|). Then the total cost is O(10000 + 4e6) = 4.01e6? 

        Actually, the total cost for building the sets: for each edge, we do:

          set operations: adding workers. The number of workers we add is the number of (material, worker) pairs for that edge? Then the total is 20e6? 

        Alternatively, we can do without deduplication in the DFS? The DFS might visit the same worker twice? Then we mark seen per worker? 

        Actually, we can avoid building a huge list by not adding duplicates? We can use a set per edge? Then convert to a list? 

        Given constraints, we do:

          worker_set = set()
          for m in materials:
              if m in material_to_workers:
                  worker_set |= set(material_to_workers[m])
          worker_list = sorted(worker_set, reverse=True)

        But building a set from a list of up to 2000 workers per material? And the edge has up to 10000 materials? Then worst-case, the set is built from 10000 * 2000 = 20e6 elements? Then the set building is O(20e6) per edge? That is too high.

        How to deduplicate without building a huge list? 

          We can use a boolean array for workers? But k=2000? Then we can do:

            worker_arr = [False] * (k+1)
            for m in materials:
                if m in material_to_workers:
                    for w in material_to_workers[m]:
                        if not worker_arr[w]:
                            worker_arr[w] = True
                            # and then add w to a list?
            Then we have a list of workers that are True? Then sort that list in descending order.

        Then the cost per edge: O(M_i * (frequency of the material in workers) )? But worst-case total cost is 20e6? Then we do that for each edge? Then total cost 20e6? 

        But the total over all edges: the total cost is the sum_{edge} ( sum_{m in edge} |material_to_workers[m]| ) = the total length without deduplication? Which is 20e6? 

        Therefore, we can do:

          for each edge:
              create an array of booleans of size k, or use a vector to mark? Actually, we can use a vector<bool> of size k, and then clear it? But we are doing for each edge? Then total cost 20e6? 

        Steps:

          Precompute material_to_workers: a dictionary mapping material to list of worker indices.

          Then for each edge (represented by key) with materials = mat_list:

              use a vector<bool> mark (of size k, initialized to false) and a list worker_list_temp.
              for each material m in mat_list:
                  if m in material_to_workers:
                      for each worker_id in material_to_workers[m]:
                          if not mark[worker_id]:
                              mark[worker_id] = true
                              worker_list_temp.push_back(worker_id)
              then sort worker_list_temp in descending order? 

          Then store worker_list_by_key[key] = worker_list_temp.

        Then the total cost is O(total_occurrence) = 20e6? And then we sort each worker_list_temp: the total cost of sorting is O( sum_{edge} (d_i * log(d_i)) ) where d_i is the degree of the edge (number of distinct workers that can build it). The worst-case d_i <= k=2000? Then for one edge: 2000*log(2000) ~ 22000? For 2000 edges: 2000 * 22000 = 44e6? Which is acceptable in C++.

        But note: the total_occurrence is 20e6? Then we can do.

        However, worst-case 20e6 iterations might be borderline in C++? 20e6 is acceptable.

        Therefore, we do:

          // Precompute material_to_workers: 
          vector<vector<int>> material_to_workers_map; // but materials up to 10^9? We use unordered_map?
          Actually, we can do:

            unordered_map<long, vector<int>> mat_map;
            for (int i=0; i<k; i++) {
                long c = workers[i];
                mat_map[c].push_back(i);
            }

          Then for each edge (each city i from 1 to n):

            vector<bool> mark(k, false);
            vector<int> worker_list_temp;
            for each material in the list for the edge:
                if (mat_map.find(material) != mat_map.end()) {
                    for (int w : mat_map[material]) {
                        if (!mark[w]) {
                            mark[w] = true;
                            worker_list_temp.push_back(w);
                        }
                    }
                }
            }
            sort(worker_list_temp.rbegin(), worker_list_temp.rend()); // descending order
            worker_list_by_key[key] = worker_list_temp;

        Then we use these lists in the DFS.

 Implementation:

   Steps:

     Read n, k.

     For i from 1 to n:
         read A_i, M_i, and the list of M_i materials.

     Read the list of k worker materials.

     Build graph: n nodes, edges: for i, edge (i, A_i) -> undirected.

     Compute degrees for each node.

     Leaf removal: 
        queue for nodes with degree 1.
        non_cycle_edges_set: set of edges (min(u,v), max(u,v)) that are removed.
        Then the remaining edges (that form the cycle) are the ones not in non_cycle_edges_set.

     Precompute:

        original_rep: map from edge key (min, max) to the representation (i, A_i) from the city i that proposed it. But note: the same edge is proposed by two cities? Actually, no: the problem says no two cities like to connect with each other. So each edge is proposed by exactly one city? 

        Actually, the input: for city i, we have an edge (i, A_i). And it is guaranteed that there is no pair (i,j) with A_i=j and A_j=i. Therefore, each edge (i, A_i) is directed? But we store as undirected. And we know that the same undirected edge is proposed by exactly one city? Because if an edge (u,v) is proposed by u, then it is not proposed by v? Because if v were to propose to u, then we would have a mutual pair? 

        Therefore, each edge is proposed by exactly one city. So we can store for an edge (min(u,v), max(u,v)) the representation (u, v) from the city u? Actually, we store when we iterate.

        So in the loop for i=1 to n:
            u = i, v = A_i
            key = make_pair(min(u,v), max(u,v))
            original_rep[key] = make_pair(u, v)   // we store the representation from city i: (i, A_i)

        Also, store the materials for the edge: materials_dict[key] = B_i (the list of materials for this edge).

     Precompute material_to_workers: as an unordered_map from material to vector of worker indices.

     Precompute worker_list for each edge (both non-cycle and cycle) as described.

     Then:

        non_cycle_edges_list = vector of keys for non-cycle edges (from non_cycle_edges_set)
        cycle_edges_list = vector of keys for cycle edges (from cycle_edges_set)

        Let L = cycle_edges_list.size()

        Check: if k < n-1 -> output -1.

        Then do matching for non-cycle edges:

            match_non: array of size = non_cycle_edges_list.size(), initialized to -1. // match_non[i] = worker id assigned to non-cycle edge i, or -1 if not assigned.
            match_worker: array of size k, initialized to -1. // match_worker[j] = the non-cycle edge index that worker j is assigned to, or -1.

            For each non-cycle edge index i in [0, non_cycle_edges_list.size()):
                Do DFS/BFS for bipartite matching? Or we can try a DFS for matching? We do:

                  seen: a boolean vector of size k, for the current DFS? 
                  Then call a DFS function that tries to find an augmenting path for edge i.

            But we can use a simple for loop and for each edge, iterate over the worker_list and try to assign? We can do a greedy matching? 

            Actually, we use a DFS for matching? 

        Then for cycle edges:

            match_cycle: array of size = cycle_edges_list.size(), initialized to -1.
            // We do a new matching for cycle edges, but we skip workers that are already assigned to non-cycle edges.

            We can do:

                For each cycle edge index i, we have a worker_list. We try to match with a worker that is not taken (match_worker[j] == -1) and also in the DFS we mark temporarily the workers we try? 

            We do DFS for cycle edges similarly? But we only consider workers that are not taken by non-cycle edges.

        Then:

            Let M_cycle = number of cycle edges that are matched.

            If M_cycle < L-1, then output -1.

        Then we decide: 

            If we want to build all cycle edges? Only if M_cycle == L and k>=n? Then we build all.

            But note: we built non_cycle_edges: n-L edges, and cycle edges: M_cycle. Total = n-L + M_cycle.

            We require at least n-1: which is satisfied because M_cycle>=L-1 -> n-L + L-1 = n-1.

            But if M_cycle == L, then we built n edges? Then we require k>=n? Actually, we have assigned n-L + L = n workers? So we require k>=n? But if k>=n, then we built n edges? Then we don't skip any cycle edge.

            If M_cycle < L, then we skip one cycle edge: the one that is not matched? Actually, we skip the unmatched cycle edge? But note: there might be multiple unmatched? We only require to skip one? Actually, we skip by not building it? So we don't have to do anything? The unmatched cycle edges are not built? Then the graph we built is non_cycle_edges + the matched cycle edges? That is n-L + M_cycle, which is at least n-1? Because M_cycle>=L-1.

            But wait: if we built L-1 cycle edges, then we skipped one cycle edge? Then the graph is a spanning tree? It is connected.

            Therefore, we don't need to explicitly skip an edge? We just output the assignments we have.

        Then we output:

            Create an array res of k strings, each initially "0 0".

            For each non-cycle edge i:
                if match_non[i] != -1, then worker_id = match_non[i]
                then res[worker_id] = format the road: use original_rep[key] -> (u, v) -> then output "u v"

            For each cycle edge i:
                if match_cycle[i] != -1, then worker_id = match_cycle[i]
                then res[worker_id] = format the road: original_rep[key] -> (u, v) -> "u v"

            Then for each worker in order from 0 to k-1, output res[i]

        But note: one worker might be matched to both non-cycle and cycle? No, because we did:

            In non-cycle matching: we set match_worker[worker_id] = i (non-cycle edge index) for that worker.

            In cycle matching: we only consider workers with match_worker[worker_id] == -1? Then the same worker is not assigned twice.

        Therefore, we output.

        However, what if the same worker appears in the worker_list for a non-cycle edge and a cycle edge? We assign it to the non-cycle edge first? Then the cycle edge matching won't use it.

        So it is safe.

  But note: the sample input2:

        4 5
        2 2 10 20
        3 2 2 3
        4 2 3 4
        2 2 4 5
        1 2 3 4 5

        Here, the first city: A_1=2, materials [10,20]. Then the road (1,2) requires material 10 or 20.

        The workers: [1,2,3,4,5] -> materials 1,2,3,4,5.

        Then no worker can build road (1,2). So we fail in non-cycle matching? Then output -1.

        Therefore, we output -1.

  Code structure:

    We'll do:

      if (k < n-1) { cout << -1 << endl; return; }

      // Build graph, leaf removal -> get non_cycle_edges_set and cycle_edges_set.

      // Precompute material_to_workers_map: unordered_map<long, vector<int>>.

      // Precompute worker_list for each edge (by key) with deduplication and sorted in descending order.

      // non_cycle_edges_list: list of keys for non-cycle edges.
      // cycle_edges_list: list of keys for cycle edges.

      // match_non: vector<int> of size = non_cycle_edges_list.size(), -1.
      // match_worker: vector<int> of size k, -1.

      // Bipartite matching for non_cycle_edges_list:

          for i from 0 to non_cycle_edges_list.size()-1:
              create a visited array for workers (for this DFS) of size k, false.
              if (dfs_non(i, visited) == false) then we fail: output -1 and return.

          The DFS for non-cycle:

            bool dfs_non(int i, vector<bool>& visited) {
                key = non_cycle_edges_list[i];
                vector<int>& worker_list = worker_list_by_key[key];
                for each worker_id in worker_list:
                    if (visited[worker_id]) continue;
                    visited[worker_id] = true;
                    // if this worker is not assigned or we can reassign the non-cycle edge that the worker is currently assigned to?
                    // Actually, we are matching non-cycle edges to workers: we do classical matching.
                    if (match_worker[worker_id] == -1 || dfs_non(match_worker[worker_id], visited)) {
                        // But note: in the recursion, we pass a new visited? Actually, we use the same visited? 
                        // We should use a local visited per call? But we do. Actually, we pass by reference and then mark for this DFS tree.
                        // But classical: we do:
                        //   we try to reassign the edge that the worker is currently assigned to? 
                        //   We need to change: we set match_worker[worker_id] = i, and match_non[i] = worker_id.
                        // But note: we are matching edges to workers? It's a left (edges) to right (workers) bipartite matching.

                        // Actually, we store:
                        //   match_worker[worker_id] = i? Then we set:
                        match_worker[worker_id] = i;
                        match_non[i] = worker_id;
                        return true;
                    }
                }
                return false;
            }

          But wait: the classical DFS for bipartite matching: we do:

            for each worker_id in the list for edge i:
                if not visited[worker_id]:
                    visited[worker_id] = true
                    if the worker_id is free OR if the edge that the worker_id is currently assigned to (say j = match_worker[worker_id]) can be reassigned to another worker (by calling dfs_non(j, visited)), then we assign worker_id to edge i.

          However, note: we have a fixed set of workers? And we are matching one worker to one edge.

          But our match_worker[worker_id] is the non-cycle edge index that the worker is currently assigned to? Then we can try to reassign that edge j? Then we call dfs_non(j, visited) to find an alternative worker for edge j? 

          Therefore, we do:

            bool dfs_non(int i, vector<bool>& visited) {
                for each worker_id in worker_list for edge i:
                    if (visited[worker_id]) continue;
                    visited[worker_id] = true;
                    int j = match_worker[worker_id];
                    if (j == -1 || dfs_non(j, visited)) {
                        match_worker[worker_id] = i;
                        match_non[i] = worker_id;
                        return true;
                    }
                }
                return false;
            }

          However, note: the worker_list is sorted in descending order? Then we try highest worker first.

      Similarly for cycle edges:

          We create:

            match_cycle: vector<int> of size = cycle_edges_list.size(), -1.
            // We do not need a separate match_worker_cycle? Because we will use the same match_worker array? Actually, no: we want to avoid workers that are taken by non-cycle edges? And we only consider workers that are free (match_worker[worker_id]==-1) OR we can reassign? But note: we are not going to reassign non-cycle edges? They are fixed.

          Actually, we cannot reassign non-cycle edges? They are mandatory and already matched. Therefore, for cycle edges, we can only use workers that are currently free? And we cannot reassign non-cycle edges.

          Therefore, the matching for cycle edges is a simple matching: we try to match each cycle edge to a free worker? Then we don't need DFS? We can do greedy? But we want to maximize the matching? Then we do DFS? But since we cannot reassign, we can do:

            We have a list of free workers? Then we can do a DFS that only considers free workers? 

          But we can do:

            // We'll create a separate DFS for cycle edges? But we cannot reassign? Then it is a simple assignment: we do a DFS that only checks if a worker is free? 

            Actually, we can do:

              for each cycle edge i:
                  for each worker_id in worker_list (in descending order) for edge i:
                      if match_worker[worker_id] == -1: // free worker
                          then we assign worker_id to edge i: 
                              match_cycle[i] = worker_id;
                              // and we mark that worker_id is now taken? But we have match_worker? We don't use match_worker for cycle? We use a separate array? 

                  But note: we want to use the same match_worker array to mark that the worker is taken? Actually, we can set match_worker[worker_id] to a special value? Or we can have a separate taken array? 

          Actually, we did not use the entire match_worker array for cycle? We only used it for non-cycle. For cycle, we are going to use the same match_worker array to mark that the worker is taken? We can set match_worker[worker_id] = some value that indicates cycle? But we don't need to. We only care that we know the worker is taken.

          We can do:

            Let free_worker = vector<bool>(k, false) initially? Actually, we have match_worker: if match_worker[j]!=-1, then the worker is taken by non-cycle.

            Then for cycle edges, we can only use workers with match_worker[j]==-1.

            Then we do:

                for each cycle edge i:
                    for each worker_id in worker_list (descending order) for edge i:
                        if match_worker[worker_id] == -1 and the worker is not taken by a cycle edge? How do we mark? 

          Alternatively, we do a DFS for bipartite matching for cycle edges? But without reassignment? Then it reduces to greedy? But we want to maximize the matching? We can do:

            We'll create an array taken_worker = match_worker (we don't want to change match_worker) for non-cycle? Actually, we can have a separate array for cycle assignment? 

            We can do:

                match_worker_cycle: vector<int> of size k, -1. // for worker j, the cycle edge index assigned, or -1.

                Then we do:

                    for i from 0 to cycle_edges_list.size()-1:
                        create a visited array (for workers) for the current DFS? 
                        then do a DFS that tries to match cycle edge i:

                    bool dfs_cycle(int i, vector<bool>& visited) {
                         for each worker_id in worker_list for edge i:
                             if (visited[worker_id]) continue;
                             visited[worker_id] = true;
                             // we require that the worker is free from non-cycle? Actually, we require match_worker[worker_id] == -1? And also we haven't assigned it to a cycle edge? Actually, we are building match_worker_cycle: we don't care about non-cycle in the assignment? But we require the worker to be free for assignment? So condition: if match_worker[worker_id] == -1 and (match_worker_cycle[worker_id] == -1 || we can reassign the cycle edge that the worker is assigned to? 

                         But note: we want to maximize the matching? And we can reassign cycle edges arbitrarily? Then we do:

                             if (match_worker_cycle[worker_id] == -1 || dfs_cycle(match_worker_cycle[worker_id], visited)) {
                                 match_worker_cycle[worker_id] = i;
                                 match_cycle[i] = worker_id;
                                 return true;
                             }
                         return false;
                    }

          But wait: we are matching cycle edges? And we can reassign the workers among cycle edges? That is classical matching? But we don't have a bound on recursion depth? The number of cycle edges is L (<=n<=2000). Then worst-case DFS recursion depth L? Then total cost L * (worker_list length) = 2000 * 2000 = 4e6? 

          However, we are doing for each edge i: we do a DFS? Then we do L times DFS? Then worst-case total cost L * (4e6) = 2000 * 4e6 = 8e9? Too high.

        Alternatively, we do a classical matching algorithm: we can do a for loop for each edge and do a DFS? The total complexity is O(n * (size of worker_list))? Worst-case 2000 * 2000 = 4e6 per DFS? Then total 2000 * 4e6 = 8e9? 

        We need a better way? Or we note: the worker_list per edge is at most 2000? Then 2000*2000=4e6 per DFS? Then 2000 * 4e6 = 8e9? Which is too high in C++.

        Therefore, we do a greedy matching? We cannot reassign? Then it is a matching in a bipartite graph without reassignment? Then we can do:

          We want to assign each cycle edge to a worker? But we can assign at most one per worker? Then we can iterate over cycle edges and assign the first available worker? But that might not maximize matching? 

        Actually, we don't need DFS if we don't allow reassignment? Then we can do:

          We have a bipartite graph: left side = cycle edges, right side = workers (only the free workers: match_worker[j]==-1).

          We can try to assign for each cycle edge i: we try the workers in descending order? and take the first free worker? Then we assign and mark the worker as taken? 

          But that might not maximize matching? Actually, it does: because we are matching one edge to one worker? And we are not reassigning? Then the greedy will work? 

          However, it might not get the maximum matching? But we don't need maximum? We need at least L-1? But we want to match as many as possible? 

          Actually, we want the maximum matching? Then we need DFS? 

        But note: the graph is bipartite? Then we can do Hopcroft-Karp? But that is O(sqrt(n)*E) and E=4e6? Then sqrt(2000)~45, then 45 * 4e6 = 180e6? Which is acceptable? But we are not going to implement Hopcroft-Karp.

        Alternatively, we do DFS for each edge? But we use recursion? We can use iterative DFS? Or we can hope that the worst-case recursion depth is 1? 

        Actually, we can do a BFS? 

        Given time constraints, we do DFS but we hope that the worst-case total cost is not too high? 

        Or we note: the graph is not too big? The total number of edges in the bipartite graph: the total_occurrence for cycle edges? The total length of worker_lists for cycle edges is at most 4e6? Then we can do a DFS for each cycle edge? The total cost is O(total_occurrence) = 4e6? 

        How? 

          We do:

            vector<int> match_cycle(L, -1);
            vector<int> match_worker_cycle(k, -1);   // for worker j, the cycle edge index assigned, or -1.

            vector<bool> visited;
            for (int i=0; i<L; i++) {
                visited.assign(k, false);
                dfs_cycle(i, visited, ...);
            }

          The DFS for cycle edge i:

            bool dfs_cycle(int i, vector<bool>& visited) {
                for each worker_id in worker_list for cycle_edges_list[i]:
                    if (visited[worker_id]) continue;
                    visited[worker_id] = true;
                    // if the worker is free from non-cycle and free from cycle? Actually, we only consider workers that are free from non-cycle? But we already have match_worker? We require match_worker[worker_id]==-1? And then we are free to assign it to cycle? But also, if it is already assigned to a cycle edge, we can try to reassign that cycle edge? 
                    // Condition: we can use the worker if it is free? Or if we can reassign the cycle edge that the worker is currently assigned to?

                    if (match_worker[worker_id] != -1) 
                        continue;   // skip if taken by non-cycle

                    if (match_worker_cycle[worker_id] == -1 || dfs_cycle(match_worker_cycle[worker_id], visited)) {
                        match_worker_cycle[worker_id] = i;
                        match_cycle[i] = worker_id;
                        return true;
                    }
                }
                return false;
            }

          Then the total cost: each worker_id is visited at most once per DFS? And we do L DFS? Then worst-case total cost = L * (length of the worker_list for the edge) = L * (max_worker_list_length) = 2000 * 2000 = 4e6? Then total 4e6? 

        But note: the DFS recursion might call recursively? Then the total work might be more? 

        Actually, the worst-case: the DFS for one edge might traverse the entire bipartite graph? Then the total cost over all DFS calls is O(L * (total number of edges in the bipartite graph))? Which is 2000 * (2000*2000) = 8e9? 

        We must avoid.

        Instead, we do a BFS? Or we use a global visited? 

        Alternatively, we do:

          We know that we are only allowed to reassign cycle edges? Then the DFS for cycle edge i will only traverse cycle edges? Then the depth is at most L? And the worker_list for one edge is at most 2000? Then the DFS for one edge: O(L * 2000) = 2000*2000=4e6? Then total for L edges: L * 4e6 = 8e9? 

        Therefore, we need a better algorithm? 

        We can do a BFS for augmenting path for the entire bipartite graph? But we want to do it per edge? 

        Alternatively, we do a classical matching algorithm: we iterate over edges and do a DFS for an augmenting path? The total cost is O(|E|) in the bipartite graph? Because each time we find an augmenting path, we increase the matching. And the total number of edges in the bipartite graph is the total_occurrence for cycle edges? Which is at most 4e6? Then the total cost is O(4e6)? 

        But how? 

          We do:

            // We'll do:
            for each cycle edge i in range(L):
                visited.assign(k, false);
                if (dfs_cycle(i, visited)) then matching_count++

          And the DFS_cycle:

            bool dfs_cycle(int i, vector<bool>& visited) {
                for each worker_id in worker_list for edge i:
                    if (visited[worker_id]) continue;
                    visited[worker_id] = true;
                    int next_edge = match_worker_cycle[worker_id]; // if the worker is already assigned to a cycle edge, then next_edge is the edge index
                    if (next_edge == -1 || dfs_cycle(next_edge, visited)) {
                        match_worker_cycle[worker_id] = i;
                        match_cycle[i] = worker_id;
                        return true;
                    }
                }
                return false;
            }

          Then the worst-case: each edge we do a DFS that might iterate over many workers? But the total work over all DFS calls is O(total_occurrence) = 4e6? 

          Why? Because each edge-worker pair is considered at most once per DFS? But the same worker might be visited in multiple DFS? 

          Actually, the visited array is per DFS. Then the same worker might be visited in different DFS? Then the total cost is the sum over edges of the size of the worker_list? Which is 4e6? 

        Therefore, we do:

          total_work = 0;
          for (int i=0; i<L; i++) {
              vector<bool> visited(k, false);
              if (dfs_cycle(i, visited)) M_cycle++;
          }

        And then we check M_cycle.

        But note: the worker_list for an edge i is stored in worker_list_by_key, and we have the list for the edge? 

        We must be cautious: the worker_list for an edge might be long? But the total over all DFS calls: the sum of the sizes of the worker_list for each edge is the total_occurrence for cycle edges? Which is 4e6? 

        Then the total cost is O(4e6).

        Therefore, we do DFS_cycle as above.

  Summary:

    Steps in code:

        // ... (previous steps)

        // Non-cycle matching:
        vector<int> match_non(non_cycle_edges_list.size(), -1);
        vector<int> match_worker(k, -1);   // for worker j, the non-cycle edge index assigned, or -1.

        for (int i=0; i<non_cycle_edges_list.size(); i++) {
            vector<bool> visited_worker(k, false);
            if (!dfs_non(i, visited_worker, non_cycle_edges_list, worker_list_by_key, match_worker, match_non)) {
                cout << -1 << endl;
                return;
            }
        }

        // Cycle matching:
        vector<int> match_cycle(cycle_edges_list.size(), -1);
        vector<int> match_worker_cycle(k, -1);   // for worker j, the cycle edge index assigned, or -1.

        int M_cycle = 0;
        for (int i=0; i<cycle_edges_list.size(); i++) {
            vector<bool> visited_worker(k, false);
            if (dfs_cycle(i, visited_worker, cycle_edges_list, worker_list_by_key, match_worker, match_worker_cycle, match_cycle)) {
                M_cycle++;
            }
        }

        if (M_cycle < cycle_edges_list.size()-1) {
            cout << -1 << endl;
            return;
        }

        // Then output:

        vector<string> res(k, "0 0");
        for (int i=0; i<non_cycle_edges_list.size(); i++) {
            if (match_non[i] != -1) {
                int worker_id = match_non[i];
                pair<int,int> road = original_rep[ non_cycle_edges_list[i] ];
                res[worker_id] = to_string(road.first) + " " + to_string(road.second);
            }
        }

        for (int i=0; i<cycle_edges_list.size(); i++) {
            if (match_cycle[i] != -1) {
                int worker_id = match_cycle[i];
                pair<int,int> road = original_rep[ cycle_edges_list[i] ];
                res[worker_id] = to_string(road.first) + " " + to_string(road.second);
            }
        }

        for (int i=0; i<k; i++) {
            cout << res[i] << endl;
        }

    The DFS functions:

        bool dfs_non(int i, vector<bool>& visited, vector<Key>& non_cycle_edges_list, 
                     unordered_map<Key, vector<int>>& worker_list_by_key, 
                     vector<int>& match_worker, vector<int>& match_non) {

            Key key = non_cycle_edges_list[i];
            vector<int>& lst = worker_list_by_key[key];
            for (int idx=0; idx<lst.size(); idx++) {
                int worker_id = lst[idx];
                if (visited[worker_id]) continue;
                visited[worker_id] = true;
                int j = match_worker[worker_id];   // j: the non-cycle edge index that worker_id is currently assigned to, or -1.
                if (j == -1 || dfs_non(j, visited, non_cycle_edges_list, worker_list_by_key, match_worker, match_non)) {
                    match_worker[worker_id] = i;
                    match_non[i] = worker_id;
                    return true;
                }
            }
            return false;
        }

        bool dfs_cycle(int i, vector<bool>& visited, vector<Key>& cycle_edges_list, 
                       unordered_map<Key, vector<int>>& worker_list_by_key, 
                       vector<int>& match_worker, vector<int>& match_worker_cycle, vector<int>& match_cycle) {

            Key key = cycle_edges_list[i];
            vector<int>& lst = worker_list_by_key[key];
            for (int idx=0; idx<lst.size(); idx++) {
                int worker_id = lst[idx];
                if (visited[worker_id]) continue;
                visited[worker_id] = true;
                // Skip if the worker is taken by non-cycle?
                if (match_worker[worker_id] != -1) {
                    continue;
                }
                int j = match_worker_cycle[worker_id];   // the cycle edge index that the worker is currently assigned to, or -1.
                if (j == -1 || dfs_cycle(j, visited, cycle_edges_list, worker_list_by_key, match_worker, match_worker_cycle, match_cycle)) {
                    match_worker_cycle[worker_id] = i;
                    match_cycle[i] = worker_id;
                    return true;
                }
            }
            return false;
        }

  But note: in the cycle DFS, we skip workers that are taken by non-cycle? Then we don't consider them.

  However, what if a worker is taken by non-cycle? Then we skip? 

  Yes.

  Let me test with sample: 
        non_cycle_edges_list: one edge: (1,2) -> worker0 (material1) is assigned? Then for cycle edges, we skip worker0? 

  But the sample worker_list for (2,3): [worker1 (material2), worker2 (material3)] -> then we match worker1 to (2,3) and worker2 to (3,4) and worker3 to (2,4) -> then M_cycle=3.

  Then we output for worker0: "1 2", worker1: "2 3", worker2: "3 4", worker3: "4 2", worker4: "0 0"

  But the sample output for worker3 is 0 0 and worker4 is "4 2". How do we get that? 

        We sorted the worker_list for (2,4) in descending order? Then we try worker4 first? Then in the DFS for (2,4) (which edge index i=2 in cycle_edges_list):

            worker_list = [4,3]   // sorted descending: worker4, worker3.

            Then we try worker4: 
                if match_worker[4] == -1? -> yes, because worker4 is not assigned to non-cycle.
                and match_worker_cycle[4] is -1? -> then we assign worker4 to edge2.

            Then we don't try worker3.

        Then match_cycle[2]=4, and we output for worker4: "4 2".

        Then worker3 is not assigned? Then output "0 0" for worker3.

        That matches the sample output.

  Therefore, we are good.

  Note: We use a Key for the edges: we used a pair<int,int> (min, max).

  Implementation details:

    We assume the graph: 
        We have an array A of size n+1? 
        We build the graph: for i=1 to n: edge between i and A[i].

    Leaf removal: we have an array deg of size n+1.

    Steps for leaf removal:

        queue for deg=1.
        non_cycle_edges_set: set of edges that are removed.

        while (!q.empty()):
            u = q.front(); q.pop();
            for each neighbor v of u:
                if (deg[v] has become 0, skip) -> actually, we reduce deg[v] by 1.
                then we remove the edge (u,v): mark it as non-cycle? 
                then deg[u] becomes 0? Then we break.

        Actually, we do:

          deg: initially the degree.

          vector<vector<int>> graph(n+1);
          for (int i=1; i<=n; i++) {
              int u = i;
              int v = A[i];
              graph[u].push_back(v);
              graph[v].push_back(u);
          }

          deg[i] = graph[i].size();

          q: push all nodes with deg 1.

          while (!q.empty()) {
              int u = q.front(); q.pop();
              if (deg[u] == 0) continue;
              deg[u] = 0;   // mark as removed
              for (int v : graph[u]) {
                  if (deg[v] == 0) continue;
                  // This edge (u,v) is non-cycle? 
                  non_cycle_edges_set.insert( make_pair(min(u,v), max(u,v)) );
                  deg[v]--;
                  if (deg[v] == 1) {
                      q.push(v);
                  }
              }
          }

        Then the remaining edges: for i=1 to n: 
            int u = i, v = A[i];
            pair<int,int> key = make_pair(min(u,v), max(u,v));
            if (non_cycle_edges_set.find(key) == non_cycle_edges_set.end()) 
                then it is cycle.

        But note: an edge might be added twice? But we use set.

  However, the graph has n edges? Then we have exactly n edges? And we start with n edges? Then non_cycle_edges_set has size n - L, and cycle_edges_set has size L.

  We then build:

      original_rep: unordered_map< pair<int,int>, pair<int,int> > 
      materials_dict: unordered_map< pair<int,int>, vector<long> >   // but note: we stored the materials for the edge from the city that proposed it? Actually, we stored in the input: for city i, the materials are B_i.

      But we have to store for each edge? 

      We do:

          for i=1 to n:
              int u = i, v = A[i];
              auto key = make_pair(min(u,v), max(u,v));
              original_rep[key] = make_pair(u, v);
              materials_dict[key] = B_i;   // the list of materials for this edge.

  Then proceed.

  Note: The total_occurrence for workers in the bipartite graphs: we do deduplication per edge? 

  Finally, we output the assignment.

  But note: the problem may have k < n-1? We check at the beginning.

  We also note: the leaf removal might not remove all non-cycle edges? But the graph is connected and has n nodes and n edges? Then it has exactly one cycle? Then the leaf removal will remove all non-cycle edges.

  We'll code accordingly.

  Let's code accordingly.

  Note: The problem says: the sum of M_i is 10000. Then the total_occurrence (without deduplication) in the bipartite graph for workers is bounded by 10000 * (max frequency of a material in workers) = 10000 * 2000 = 20e6? But with deduplication per edge, the total_occurrence for the bipartite graph is the total number of distinct (edge, worker) pairs? Which is at most n * k = 4e6? Then we can do.

  We'll do deduplication per edge.

  Due to the complexity of the DFS for non-cycle matching? The worst-case total work is the total_occurrence for non-cycle edges? Which is at most 4e6? 

  Similarly for cycle: 4e6? 

  Then total 8e6? 

  We'll code in C++.

  Let's code accordingly.

  Note: We use an unordered_map for the worker_list_by_key? But the key is a pair<int,int>? We can define a hash for pair? Or we can use map.

  Since n is 2000, we can use map.

  We'll do.

  Steps:

    Read n, k.

    vector<int> A(n+1);
    vector<vector<long>> B(n+1);   // B[1] to B[n]

    for i=1 to n:
        read A[i]
        read M_i
        read M_i numbers -> store in B[i]

    Read the list of k workers: vector<long> workers(k);

    Build graph: 
        vector<vector<int>> graph(n+1);
        for i=1 to n: 
            u = i, v = A[i]
            graph[u].push_back(v);
            graph[v].push_back(u);

    Compute deg: 
        vector<int> deg(n+1);
        for i=1 to n: deg[i]=graph[i].size();

    Leaf removal:

        queue<int> q;
        set<pair<int,int>> non_cycle_edges_set;

        for (int i=1; i<=n; i++) {
            if (deg[i] == 1) {
                q.push(i);
            }
        }

        while (!q.empty()) {
            int u = q.front(); q.pop();
            if (deg[u] == 0) continue;
            deg[u] = 0;
            for (int v : graph[u]) {
                if (deg[v] == 0) continue;
                auto key = make_pair(min(u,v), max(u,v));
                non_cycle_edges_set.insert(key);
                deg[v]--;
                if (deg[v] == 1) {
                    q.push(v);
                }
            }
        }

    Then, the cycle_edges_set: 
        set<pair<int,int>> cycle_edges_set;
        map<pair<int,int>, pair<int,int>> original_rep;
        map<pair<int,int>, vector<long>> materials_dict;

        for (int i=1; i<=n; i++) {
            int u = i, v = A[i];
            auto key = make_pair(min(u,v), max(u,v));
            if (non_cycle_edges_set.find(key) == non_cycle_edges_set.end()) {
                cycle_edges_set.insert(key);
            }
            original_rep[key] = make_pair(u, v);
            materials_dict[key] = B[i];
        }

    Then, non_cycle_edges_list = vector of keys in non_cycle_edges_set.
        cycle_edges_list = vector of keys in cycle_edges_set.

    Precompute material_to_workers_map: 

        unordered_map<long, vector<int>> mat_map;
        for (int i=0; i<k; i++) {
            long c = workers[i];
            mat_map[c].push_back(i);
        }

    Precompute worker_list_by_key: 
        map<pair<int,int>, vector<int>> worker_list_by_key;

        // For non_cycle_edges_list and cycle_edges_list, we do:
        vector<set<pair<int,int>>> edges_by_type = { non_cycle_edges_set, cycle_edges_set };
        // But easier: we do for all edges: we have a set of all edges? 

        // Actually, we can iterate over the entire edge set: non_cycle_edges_set and cycle_edges_set are disjoint? 
        // We do:

        for (auto key : non_cycle_edges_set) {
            vector<bool> mark(k, false);
            vector<int> worker_list_temp;
            vector<long>& materials = materials_dict[key];
            for (long m : materials) {
                if (mat_map.count(m)) {
                    for (int w : mat_map[m]) {
                        if (!mark[w]) {
                            mark[w] = true;
                            worker_list_temp.push_back(w);
                        }
                    }
                }
            }
            sort(worker_list_temp.begin(), worker_list_temp.end(), greater<int>());
            worker_list_by_key[key] = worker_list_temp;
        }

        for (auto key : cycle_edges_set) {
            // same as above
        }

    Then, non_cycle_edges_list = vector of keys in non_cycle_edges_set? But we already have the set? We can convert to vector.

        vector<pair<int,int>> non_cycle_list, cycle_list;
        for (auto key: non_cycle_edges_set) non_cycle_list.push_back(key);
        for (auto key: cycle_edges_set) cycle_list.push_back(key);

    Then, we do the matching for non-cycle_list and cycle_list.

    Then output.

  Let's hope it passes.

  Note: k can be 0? but k>=1.

  Edge: if n=3, then L= the cycle length? In a triangle? Then L=3.

  But note: the leaf removal: 
        Initially, all nodes have degree 2? Then the queue is empty? Then non_cycle_edges_set is empty? Then cycle_edges_set has the entire graph.

  Then non_cycle_list = empty? Then we skip non-cycle matching.

  Then we match cycle edges: we require at least 2? Then we assign two workers? 

  Then we output.

  We'll run the sample input1.

  But note: the sample input1 has n=4, k=5.

  We have to be cautious: the DFS for non-cycle matching: for an edge, if we cannot find a worker, we fail.

  We'll code accordingly.

  Due to the complexity, we hope it runs in time.

  We'll write in C++.

  Note: The total_occurrence in the bipartite graphs is bounded by 4e6? So we hope.

  Let's code accordingly.

  Note: We have to be cautious: the materials can be as large as 10^9? We use long? Or we use unsigned? We use long.

  We'll use long for materials.

  Also, the worker materials: 0 to 10^9.

  We'll use:

      #include <bits/stdc++.h>
      using namespace std;

  And define:

      using Key = pair<int, int>;

  And hashing for unordered_map? Or we use map for Key.

  Since n is 2000, the number of edges is n=2000? Then we can use map for Key.

  We do.

  Code:

      // long long for materials? But the input says materials in [0,10^9] -> int can hold? 10^9 is 1e9 < 2^31? So int is enough? But the workers are also in [0,10^9]? Then we use int for materials? 

      But the problem: 0<= (B_i)_j <= 10^9 -> we use int.

  Let me code accordingly.

  Due to the problem constraints, we hope.

  Let's code.

  Note: The sample input1: 
        n=4, k=5
        A[1]=2, M1=2, [1,2]
        A[2]=3, M2=2, [2,3]
        A[3]=4, M3=2, [3,4]
        A[4]=2, M4=2, [4,5]
        workers: [1,2,3,4,5]

  We'll run and see.

  But note: we are using DFS for bipartite matching? We have to be cautious about recursion depth? The non-cycle matching: the non_cycle_list has size 1? Then the DFS for non-cycle edge0: it will try worker_list: [0,1] (for material1: worker0; for material2: worker1) -> then we have two workers? Then we try worker0? Then we assign? Then return true.

  Then for cycle_list: three edges.

  We'll run the DFS for each cycle edge? 

      Edge0: (2,3): worker_list = [1,0]? But wait, we deduplicated and sorted in descending: [1,0]? But note: we marked worker0 as taken? So in the cycle DFS, we skip worker0? Then we try worker1? Then we assign worker1 to edge0.

      Edge1: (3,4): worker_list = [2,1]? Then we try worker2? then assign.

      Edge2: (2,4): worker_list = [4,3]? Then we try worker4? then assign.

      Then M_cycle=3.

  Then we output: 
        worker0: non-cycle edge (1,2) -> "1 2"
        worker1: cycle edge0 (2,3) -> "2 3" (because original_rep for (2,3) is (2,3) from city2)
        worker2: cycle edge1 (3,4) -> "3 4"
        worker4: cycle edge2 (2,4) -> "4 2" (because original_rep for (2,4) is from city4: (4,2))
        worker3: not assigned -> "0 0"

      But the sample output has worker3 as the fourth worker? and worker4 as the fifth? 

        worker0: first worker -> "1 2"
        worker1: second worker -> "2 3"
        worker2: third worker -> "3 4"
        worker3: fourth worker -> "0 0"
        worker4: fifth worker -> "4 2"

      So we output:

        "1 2"
        "2 3"
        "3 4"
        "0 0"
        "4 2"

      But we stored the assignments in the res array by worker_id? 

        res[0] = "1 2"
        res[1] = "2 3"
        res[2] = "3 4"
        res[3] = "0 0"   // because worker3 is not assigned? 
        res[4] = "4 2"

      Then we output:

        for i=0 to k-1: 
            cout << res[i] << endl;

      That is:

        1 2
        2 3
        3 4
        0 0
        4 2

      Which matches.

  Therefore, we output.

  Let me test sample input2:

        n=4, k=5
        A[1]=2, M1=2, [10,20]
        ... same as sample1 for others.

        Then non_cycle_edges_set: only (1,2) -> but the materials [10,20] -> then we look for workers: the workers have materials [1,2,3,4,5] -> then no worker can build (1,2). Then the DFS for non-cycle edge0 fails? Then we output -1.

  So we output -1.

  Therefore, we are done.

  Note: We must be cautious: the non_cycle_edges_list is the list of keys? We use the same key as in the map? 

  Let me code accordingly.

  Due to the length, we hope.

  We'll write the code accordingly.

  Note: The DFS recursion might cause stack overflow? But the depth: non-cycle matching: the worst-case depth? The non-cycle_edges_list has size n-L (<=n) and the bipartite graph has many edges? But the DFS recursion depth is the length of the augmenting path? Which is at most the number of edges? But worst-case, the entire graph? But n<=2000? Then the recursion depth is at most 2000? Then it is safe.

  We'll write the DFS recursion.

  We'll submit the code.

  Note: We must use C++ and be efficient.

  Due to the constraints, we hope it runs in 2 seconds.

  Let me write the code.